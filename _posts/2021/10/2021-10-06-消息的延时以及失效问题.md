---
toc:
  beginning: true
giscus_comments: true
layout: post
title: "消息的延时以及失效问题"
date: "2021-10-06"
categories: 
  - "Backend MQ"
---

# 消息的延时以及失效问题

## 介绍
其实本质针对的场景，都是说，可能你的消费端出了问题，不消费了；或者消费的速度极其慢。接着就坑爹了，可能你的消息队列集群的磁盘都快写满了，都没人消费，这个时候怎么办？或者是这整个就积压了几个小时，你这个时候怎么办？或者是你积压的时间太长了，导致比如 RabbitMQ 设置了消息过期时间后就没了怎么办？

举个例子，消费端每次消费之后要写 mysql，结果 mysql 挂了，消费端 卡在 那儿了，不动了；或者是消费端出了个什么岔子，导致消费速度极其慢。

## 大量消息在mq里面积压了几个小时还没有解决

一般这个时候，只能临时紧急扩容，具体操作思路：
1. 先修复consumer问题，确保回复其消费速度，然后将现有的consumer停掉
2. 新建一个topic，partition是原来的10倍，临时建立好原先10倍的queue数量
3. 写一个临时分发数据的consumer程序，这个程序部署上去消费积压的数据，消费之后不做耗时处理，直接均匀轮训写入临时写入临时建立好的10倍数量的queue
4. 临时用10倍的机器来部署consumer，每一批consumer消费一个临时queue的数据。相当于临时将queue资源和consumer的资源扩大10倍，以正常的10倍速度消费数据。
5. 等快速消费完积压数据之后，恢复原先的部署架构，重写用原先的consumer机器来消费消息

## MQ中的消息过期失效了
假设使用的RabbitMQ，它是可以设置过期时间。如果消息在queue中积压超过一定时间就会被RabbitMQ给清理掉，这个数据就丢失了。

这个情况下，我们可以采用**批量重导**，打击了积压的时候，直接丢弃数据，等到高峰期过了之后，我们可以开始写程序，将丢失的那批数据，写个临时程序，一点点查询出来，重新灌入mq里面，把丢失的数据补回来。

## MQ都快写满了
如果消息积压到MQ里，如果很长时间没有处理掉，导致MQ快写满了。

**临时写程序，接入数据来消费，消费一个丢弃一个，快速消费完，然后到晚上再补回数据。**

