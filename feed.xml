<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><generator uri="https://jekyllrb.com/" version="4.3.3">Jekyll</generator><link href="https://zhengstar94.github.io//feed.xml" rel="self" type="application/atom+xml"/><link href="https://zhengstar94.github.io//" rel="alternate" type="text/html" hreflang="en"/><updated>2025-08-13T02:51:08+00:00</updated><id>https://zhengstar94.github.io//feed.xml</id><title type="html">zhengxingxing</title><subtitle>Welcome to Xingxing&apos;s blog, where I share my thoughts and experiences on various topics. </subtitle><entry><title type="html">Twitter Database Read and Write and Sharding System Design Detailed Guide</title><link href="https://zhengstar94.github.io//blog/2025/TwitterDatabaseReadAndWriteAndShardingSystemDesignDetailedGuide/" rel="alternate" type="text/html" title="Twitter Database Read and Write and Sharding System Design Detailed Guide"/><published>2025-08-01T00:00:00+00:00</published><updated>2025-08-01T00:00:00+00:00</updated><id>https://zhengstar94.github.io//blog/2025/TwitterDatabaseReadAndWriteAndShardingSystemDesignDetailedGuide</id><content type="html" xml:base="https://zhengstar94.github.io//blog/2025/TwitterDatabaseReadAndWriteAndShardingSystemDesignDetailedGuide/"><![CDATA[<h2 id="introduction">Introduction</h2> <p>The database is the foundational infrastructure of social platforms like Twitter/X, responsible for storing massive user data, tweets, and relationship graphs. Facing billions of DAU and hundreds of millions of daily tweets, the read/write operations are extremely unbalanced (read/write ratio 100:1), with data hotspots (e.g., celebrity tweets) and cross-query complexity becoming major bottlenecks. This article systematically introduces the architecture schemes for database read/write and sharding, trade-offs, engineering implementation details, and common interview follow-up questions, based on hybrid storage (SQL for users, NoSQL for tweets, Graph DB for relationships) and sharding strategies, aiming to achieve high throughput, low latency, and high availability.</p> <hr/> <h2 id="1-requirements-and-challenges">1. Requirements and Challenges</h2> <ul> <li><strong>Massive Data Scale</strong>: Daily writes of 24 TB+ (text, media), PB-level storage over 5 years; total accounts 15 billion, tweets in trillions.</li> <li><strong>Read/Write Imbalance</strong>: Read operations dominate (e.g., timeline aggregation requires cross-user queries), write operations require strong consistency (e.g., tweet posting).</li> <li><strong>Hotspot Issues</strong>: Celebrity user data concentration, single shard load &gt;80%; new data hotspots cause IO contention.</li> <li><strong>Low Latency and Consistency</strong>: Queries &lt;100 ms, strong consistency scenarios (e.g., authentication) allow no delay, eventual consistency (e.g., follower counts) can tolerate second-level delays.</li> <li><strong>Fault Tolerance</strong>: Continue operating during node failures or network partitions, with data replication across data centers.</li> </ul> <hr/> <h2 id="2-scheme-comparison-and-trade-offs">2. Scheme Comparison and Trade-offs</h2> <h3 id="21-sharding-by-creation-time">2.1 Sharding by Creation Time</h3> <ul> <li><strong>Principle</strong>: Distribute data to different shards based on tweet creation time (e.g., by day/week), similar to archiving file cabinets by date, facilitating time-range queries.</li> <li><strong>Advantages</strong>: Efficient time queries, only accessing a few shards; easy to archive historical data.</li> <li><strong>Disadvantages</strong>: Uneven hot/cold distribution, high write pressure on new shards (hotspots), resource waste on old shards.</li> </ul> <h3 id="22-sharding-by-user-id-hash">2.2 Sharding by User ID Hash</h3> <ul> <li><strong>Principle</strong>: Hash user ID (e.g., Murmur 3), store same-user data in the same shard, similar to classifying phone books by name initials.</li> <li><strong>Advantages</strong>: Localized user timeline queries, simple implementation.</li> <li><strong>Disadvantages</strong>: Homepage timeline requires cross-shard aggregation; hot users cause uneven shards, severe hotspots.</li> </ul> <h3 id="23-sharding-by-tweet-id-hash">2.3 Sharding by Tweet ID Hash</h3> <ul> <li><strong>Principle</strong>: Hash tweet ID to distribute data evenly, similar to randomly assigning lottery numbers to avoid concentration.</li> <li><strong>Advantages</strong>: Even data distribution, reduced hotspots; high availability, minimal fault impact.</li> <li><strong>Disadvantages</strong>: Timeline aggregation requires accessing multiple shards, high query cost (relies on caching).</li> </ul> <p>Comparison Table:</p> <table> <thead> <tr> <th>Sharding Scheme</th> <th>Advantages</th> <th>Disadvantages</th> <th>Applicable Scenario Comparison</th> </tr> </thead> <tbody> <tr> <td><strong>By Creation Time</strong></td> <td>- Efficient time queries<br/>- Easy historical data archiving</td> <td>- New shard hotspots, resource waste<br/>- Frequent creation for quick filling</td> <td>Suitable for historical data analysis, but poor for real-time read/write.</td> </tr> <tr> <td><strong>By User ID Hash</strong></td> <td>- Localized user timeline<br/>- Simple implementation</td> <td>- Many cross-shard homepage queries<br/>- Uneven hot users, severe hotspots</td> <td>Superior to time sharding in user queries, but poor large-scale scaling.</td> </tr> <tr> <td><strong>By Tweet ID Hash</strong></td> <td>- Even data distribution<br/>- Reduced hotspots, high availability</td> <td>- Complex timeline queries, requires strong caching support</td> <td>Best for large-scale: Balanced with caching for high read performance.</td> </tr> </tbody> </table> <hr/> <h2 id="3-recommended-architecture-sharding-by-tweet-id-hash--readwrite-separation">3. Recommended Architecture: Sharding by Tweet ID Hash + Read/Write Separation</h2> <h3 id="31-storage-selection">3.1 Storage Selection</h3> <ul> <li><strong>SQL (MySQL)</strong>: User profiles, authentication (strong consistency).</li> <li><strong>NoSQL (Cassandra)</strong>: Tweet storage (high throughput).</li> <li><strong>Graph DB (Neo 4 j)</strong>: Follow relationships (graph queries).</li> <li><strong>Object Storage (S 3)</strong>: Media files.</li> </ul> <h3 id="32-sharding-mechanism">3.2 Sharding Mechanism</h3> <ul> <li>Use consistent hash ring (1024 shards), with tweet ID as the key for even distribution.</li> <li>Tool: Vitess as the sharding routing layer, supporting automatic rebalancing.</li> </ul> <h3 id="33-readwrite-separation">3.3 Read/Write Separation</h3> <ul> <li>Master DB (Cassandra) dedicated to writes, consistency level QUORUM.</li> <li>Slave DB (MySQL replicas) for multiple reads, consistency level ONE; asynchronous replication tools like Debezium + Kafka to sync changes (latency &lt;1 s).</li> </ul> <h3 id="34-fault-tolerance-and-rebalancing">3.4 Fault Tolerance and Rebalancing</h3> <ul> <li>Multi-AZ deployment, Vitess automatic failover (&lt;10 s).</li> <li>Rebalancing script monitors load hourly (&gt;70% triggers), gradual data migration.</li> </ul> <p>The following is a simplified architecture diagram of the recommended architecture (Mermaid syntax):</p> <pre><code class="language-mermaid">graph TD
    A["Client Request"] --&gt; B["API Gateway"]
    B --&gt; C["Timeline/Tweet Service"]
    C --&gt; D{"Read/Write?"}
    D --&gt;|"Write"| E["Master DB: Cassandra (QUORUM Consistency)"]
    D --&gt;|"Read"| F["Slave DB: MySQL Replica (ONE Consistency)"]
    E --&gt; G["Kafka: Asynchronous Replication Changes"]
    G --&gt; F
    H["Vitess: Sharding Routing + Rebalancing"] -.-&gt; E
    H -.-&gt; F
    I["S3: Media Storage"] -.-&gt; C
    J["Neo4j: Relationship Graph"] -.-&gt; C
    K["Prometheus: Monitoring Load"] -.-&gt; H
</code></pre> <p>This diagram shows the overall process of read/write separation and sharding routing.</p> <hr/> <h2 id="4-key-data-structures-and-processes">4. Key Data Structures and Processes</h2> <h3 id="41-table-design">4.1 Table Design</h3> <ul> <li> <p><strong>User Table (MySQL)</strong>: | Field | Type | Description | |————–|————–|——————————| | userId | BIGINT | User ID (Primary Key) | | name | VARCHAR (100)| Username | | email | VARCHAR (100)| Email | | creationTime | DATETIME | Creation Time | | lastLogin | DATETIME | Last Login | | isHotUser | BOOLEAN | Whether Hot User |</p> </li> <li> <p><strong>Tweet Table (Cassandra)</strong>: | Field | Type | Description | |————–|————–|——————————| | tweetId | BIGINT | Tweet ID (Partition Key) | | userId | BIGINT | Author ID | | content | VARCHAR (280)| Content | | creationTime | TIMESTAMP | Creation Time (Clustering Key) |</p> </li> <li> <p><strong>Follow Table (Neo 4 j)</strong>: Nodes as User, relationships as FOLLOWS.</p> </li> </ul> <h3 id="42-tweet-write-and-read-process">4.2 Tweet Write and Read Process</h3> <p>The following is the process sequence diagram (Mermaid syntax):</p> <pre><code class="language-mermaid">sequenceDiagram
    participant Client as Client
    participant Service as Tweet Service
    participant Vitess as Vitess Routing
    participant MainDB as Master DB (Cassandra)
    participant SlaveDB as Slave DB (MySQL)
    participant Kafka as Kafka Replication

    Client-&gt;&gt;Service: Post Tweet
    Service-&gt;&gt;Vitess: Calculate Shard (Tweet ID Hash)
    Vitess-&gt;&gt;MainDB: Write to Master DB
    MainDB--&gt;&gt;Vitess: Confirm
    Vitess-&gt;&gt;Kafka: Send Change Event
    Kafka-&gt;&gt;SlaveDB: Asynchronous Replication to Slave DB

    Client-&gt;&gt;Service: Query Timeline
    Service-&gt;&gt;Vitess: Route to Shards
    Vitess-&gt;&gt;SlaveDB: Read from Slave DB
    SlaveDB--&gt;&gt;Vitess: Return Data
    Vitess--&gt;&gt;Service: Aggregate Results
    Service--&gt;&gt;Client: Return
</code></pre> <h4 id="java-code-example-writing-tweet">Java Code Example (Writing Tweet)</h4> <div class="language-java highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">// Handle write in tweet service (sharding by tweet ID hash)</span>
<span class="kd">public</span> <span class="kt">void</span> <span class="nf">insertTweet</span><span class="o">(</span><span class="kt">long</span> <span class="n">tweetId</span><span class="o">,</span> <span class="kt">long</span> <span class="n">userId</span><span class="o">,</span> <span class="nc">String</span> <span class="n">content</span><span class="o">,</span> <span class="nc">Timestamp</span> <span class="n">creationTime</span><span class="o">)</span> <span class="o">{</span>
    <span class="c1">// Calculate hash shard</span>
    <span class="kt">long</span> <span class="n">hash</span> <span class="o">=</span> <span class="nc">MurmurHash3</span><span class="o">.</span><span class="na">hash</span><span class="o">(</span><span class="n">tweetId</span><span class="o">);</span>
    <span class="kt">int</span> <span class="n">shard</span> <span class="o">=</span> <span class="o">(</span><span class="kt">int</span><span class="o">)</span> <span class="o">(</span><span class="n">hash</span> <span class="o">%</span> <span class="n">numShards</span><span class="o">);</span>

    <span class="c1">// Insert using Vitess or Cassandra client</span>
    <span class="nc">PreparedStatement</span> <span class="n">stmt</span> <span class="o">=</span> <span class="n">session</span><span class="o">.</span><span class="na">prepare</span><span class="o">(</span><span class="s">"INSERT INTO tweets (tweetId, userId, content, creationTime) VALUES (?, ?, ?, ?)"</span><span class="o">);</span>
    <span class="nc">BoundStatement</span> <span class="n">bound</span> <span class="o">=</span> <span class="n">stmt</span><span class="o">.</span><span class="na">bind</span><span class="o">(</span><span class="n">tweetId</span><span class="o">,</span> <span class="n">userId</span><span class="o">,</span> <span class="n">content</span><span class="o">,</span> <span class="n">creationTime</span><span class="o">);</span>
    <span class="n">session</span><span class="o">.</span><span class="na">execute</span><span class="o">(</span><span class="n">bound</span><span class="o">);</span>  <span class="c1">// QUORUM consistency</span>

    <span class="c1">// Asynchronously deliver to Kafka for replication</span>
    <span class="n">kafkaProducer</span><span class="o">.</span><span class="na">send</span><span class="o">(</span><span class="k">new</span> <span class="nc">ProducerRecord</span><span class="o">&lt;&gt;(</span><span class="s">"tweet_changes"</span><span class="o">,</span> <span class="nc">String</span><span class="o">.</span><span class="na">valueOf</span><span class="o">(</span><span class="n">tweetId</span><span class="o">),</span> <span class="n">serializeTweet</span><span class="o">(</span><span class="n">tweetId</span><span class="o">,</span> <span class="n">userId</span><span class="o">,</span> <span class="n">content</span><span class="o">)));</span>
<span class="o">}</span>
</code></pre></div></div> <h4 id="java-code-example-reading-tweet">Java Code Example (Reading Tweet)</h4> <div class="language-java highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">// Handle read in timeline service (from slave DB)</span>
<span class="kd">public</span> <span class="nc">List</span><span class="o">&lt;</span><span class="nc">Tweet</span><span class="o">&gt;</span> <span class="nf">queryTweetsByUser</span><span class="o">(</span><span class="kt">long</span> <span class="n">userId</span><span class="o">,</span> <span class="kt">long</span> <span class="n">sinceTime</span><span class="o">)</span> <span class="o">{</span>
    <span class="c1">// Vitess routes to relevant shards</span>
    <span class="nc">QueryBuilder</span> <span class="n">qb</span> <span class="o">=</span> <span class="nc">QueryBuilder</span><span class="o">.</span><span class="na">select</span><span class="o">().</span><span class="na">from</span><span class="o">(</span><span class="s">"tweets"</span><span class="o">);</span>
    <span class="n">qb</span><span class="o">.</span><span class="na">where</span><span class="o">(</span><span class="n">eq</span><span class="o">(</span><span class="s">"userId"</span><span class="o">,</span> <span class="n">userId</span><span class="o">)).</span><span class="na">and</span><span class="o">(</span><span class="n">gt</span><span class="o">(</span><span class="s">"creationTime"</span><span class="o">,</span> <span class="n">sinceTime</span><span class="o">));</span>
    <span class="nc">ResultSet</span> <span class="n">results</span> <span class="o">=</span> <span class="n">vitessSession</span><span class="o">.</span><span class="na">execute</span><span class="o">(</span><span class="n">qb</span><span class="o">.</span><span class="na">build</span><span class="o">());</span>

    <span class="c1">// Convert to Tweet list</span>
    <span class="nc">List</span><span class="o">&lt;</span><span class="nc">Tweet</span><span class="o">&gt;</span> <span class="n">tweets</span> <span class="o">=</span> <span class="k">new</span> <span class="nc">ArrayList</span><span class="o">&lt;&gt;();</span>
    <span class="k">for</span> <span class="o">(</span><span class="nc">Row</span> <span class="n">row</span> <span class="o">:</span> <span class="n">results</span><span class="o">)</span> <span class="o">{</span>
        <span class="n">tweets</span><span class="o">.</span><span class="na">add</span><span class="o">(</span><span class="k">new</span> <span class="nc">Tweet</span><span class="o">(</span><span class="n">row</span><span class="o">.</span><span class="na">getLong</span><span class="o">(</span><span class="s">"tweetId"</span><span class="o">),</span> <span class="n">row</span><span class="o">.</span><span class="na">getString</span><span class="o">(</span><span class="s">"content"</span><span class="o">),</span> <span class="n">row</span><span class="o">.</span><span class="na">getTimestamp</span><span class="o">(</span><span class="s">"creationTime"</span><span class="o">)));</span>
    <span class="o">}</span>
    <span class="k">return</span> <span class="n">tweets</span><span class="o">;</span>
<span class="o">}</span>
</code></pre></div></div> <hr/> <h2 id="5-performance-optimization-and-engineering-details">5. Performance Optimization and Engineering Details</h2> <ul> <li><strong>Index Optimization</strong>: Cassandra secondary indexes (creationTime + userId), reducing scans.</li> <li><strong>Asynchronous Replication</strong>: Debezium captures changes, Kafka buffering, latency &lt;1 s.</li> <li><strong>Rebalancing</strong>: Vitess moveTables for gradual migration, rate-limited &lt;1 GB/min to avoid interruptions.</li> <li><strong>Media Processing</strong>: Asynchronous upload to S 3, CDN pre-warming for hot files.</li> <li><strong>Monitoring</strong>: Grafana tracks IO/CPU, shard load, alerts &gt;80% to trigger autoscaling.</li> </ul> <hr/> <h2 id="6-high-frequency-interview-follow-ups-and-real-engineering-pitfalls">6. High-Frequency Interview Follow-Ups and Real Engineering Pitfalls</h2> <h3 id="high-frequency-follow-ups">High-Frequency Follow-Ups</h3> <ul> <li>How to detect and migrate hotspot shards? (Monitor load, Vitess automatic rebalancing)</li> <li>How to ensure consistency under read/write separation? (QUORUM writes, ONE reads + asynchronous replication)</li> <li>How to dynamically adjust shard count with data growth? (Consistent hash ring expansion, virtual nodes for evenness)</li> </ul> <h3 id="engineering-pitfalls">Engineering Pitfalls</h3> <ul> <li>Replication latency peaks &gt;5 s, causing dirty reads; solution: Prioritize high-priority changes, monitor lag.</li> <li>Rebalancing interrupts service; solution: Dual-write synchronization, test with Chaos Engineering.</li> <li>High index maintenance overhead; solution: Periodic rebuilds, test query plans.</li> </ul> <h3 id="common-misconceptions">Common Misconceptions</h3> <ul> <li>Using only user ID sharding, ignoring hotspots leading to single-shard crashes.</li> <li>No read/write separation, writes drag down read performance.</li> <li>Ignoring cross-data center replication, data loss during network partitions.</li> </ul> <hr/> <h2 id="7-summary">7. Summary</h2> <p>Twitter database read/write and sharding are key to handling massive data. Through sharding by tweet ID hash + read/write separation + asynchronous replication architecture, balanced load, low latency, and high availability can be achieved. Engineering focuses on sharding routing (Vitess), consistency management (QUORUM/ONE), and monitoring degradation to avoid hotspots and fault risks. In practice, combine with caching (e.g., Redis) and message queues (e.g., Kafka) to support overall system scaling.</p>]]></content><author><name></name></author><category term="System Design Other"/><summary type="html"><![CDATA[Introduction]]></summary></entry><entry><title type="html">Twitter Notification and Real-Time Push System Design Detailed Guide</title><link href="https://zhengstar94.github.io//blog/2025/TwitterNotificationAndReal-TimePushSystemDesignDetailedGuide/" rel="alternate" type="text/html" title="Twitter Notification and Real-Time Push System Design Detailed Guide"/><published>2025-08-01T00:00:00+00:00</published><updated>2025-08-01T00:00:00+00:00</updated><id>https://zhengstar94.github.io//blog/2025/TwitterNotificationAndReal-TimePushSystemDesignDetailedGuide</id><content type="html" xml:base="https://zhengstar94.github.io//blog/2025/TwitterNotificationAndReal-TimePushSystemDesignDetailedGuide/"><![CDATA[<h2 id="introduction">Introduction</h2> <p>Notifications and real-time pushes are key interactive mechanisms in Twitter/X social platforms, used to handle events such as likes, @mentions, and replies, ensuring users receive updates promptly. Facing billions of DAU and daily billions of interactions, the system must support high-concurrency pushes, low-latency delivery, and high availability. This article systematically introduces the architecture schemes for notification pushes, trade-offs, engineering implementation details, and common interview follow-up questions, based on asynchronous decoupling (Kafka) and real-time communication (WebSocket), aiming to balance resource consumption and user experience.</p> <hr/> <h2 id="1-requirements-and-challenges">1. Requirements and Challenges</h2> <ul> <li> <p><strong>High-Frequency Interactions</strong>: Billions of notifications daily (such as likes/@), with peak TPS in the tens of thousands; hot events can trigger millions of pushes instantly.</p> </li> <li> <p><strong>Real-Time Performance</strong>: Delivery latency &lt;1 s, with frequent mobile reconnections (&gt;10% users).</p> </li> <li> <p><strong>Resource Contention</strong>: Long connections consume memory (each &gt;1 KB), peak CPU &gt;80%; queue backlogs lead to losses.</p> </li> <li> <p><strong>Consistency and Filtering</strong>: Eventual consistency can tolerate second-level delays, but active users must be distinguished to avoid invalid pushes.</p> </li> <li> <p><strong>Fault Tolerance</strong>: Limit rates and degrade during DDoS attacks or network partitions; support multi-channels (Web/mobile).</p> </li> </ul> <hr/> <h2 id="2-scheme-comparison-and-trade-offs">2. Scheme Comparison and Trade-offs</h2> <h3 id="21-websocket-push-mode">2.1 WebSocket (Push Mode)</h3> <ul> <li> <p><strong>Principle</strong>: Establish a persistent bidirectional connection where the server actively pushes notifications, similar to a real-time phone call: once there’s a message, the system directly “calls” the user’s connection.</p> </li> <li> <p><strong>Advantages</strong>: Real-time low latency (&lt;1 s), efficient bandwidth usage.</p> </li> <li> <p><strong>Disadvantages</strong>: Complex connection management, high memory/CPU under high concurrency; high reconnection overhead on disconnections.</p> </li> </ul> <h3 id="22-polling-pull-mode">2.2 Polling (Pull Mode)</h3> <ul> <li> <p><strong>Principle</strong>: The client periodically polls the server for new notifications, similar to checking a mailbox: the user asks “Any new messages?” every few seconds.</p> </li> <li> <p><strong>Advantages</strong>: Simple implementation, no need for long connections.</p> </li> <li> <p><strong>Disadvantages</strong>: High latency (average &gt; interval time), bandwidth waste (many empty polls); unsuitable for real-time scenarios.</p> </li> </ul> <h3 id="23-hybrid-mode-push--pull">2.3 Hybrid Mode (Push + Pull)</h3> <ul> <li> <p><strong>Principle</strong>: Use push (WebSocket) for online users, and pull (FCM/APNS fallback) for offline/mobile, similar to smart mail: instant notifications when online, batch delivery when offline.</p> </li> <li> <p><strong>Advantages</strong>: Balances real-time and resources, reduces invalid pushes.</p> </li> <li> <p><strong>Disadvantages</strong>: Complex multi-channel management, consistency challenges.</p> </li> </ul> <p>Comparison Table:</p> <table> <thead> <tr> <th>Scheme</th> <th>Advantages</th> <th>Disadvantages</th> <th>Applicable Scenario Comparison</th> </tr> </thead> <tbody> <tr> <td><strong>WebSocket</strong></td> <td>- Real-time delivery &lt;1 s<br/>- Low bandwidth consumption</td> <td>- High connection memory<br/>- High DDoS risk</td> <td>Superior to Polling in interaction-intensive scenarios, but requires rate limiting for high-concurrency scaling.</td> </tr> <tr> <td><strong>Polling</strong></td> <td>- Simple implementation, stateless<br/>- Easy fault tolerance</td> <td>- High latency (&gt; a few seconds)<br/>- High bandwidth/server pressure</td> <td>Suitable for low-frequency notifications, but poor real-time performance, not recommended as primary.</td> </tr> <tr> <td><strong>Hybrid Mode</strong></td> <td>- Balances online/offline<br/>- Resource optimization, delivery &gt;99%</td> <td>- Complex implementation, multi-channel synchronization<br/>- Filtering logic overhead</td> <td>Best for large-scale: Reduces pressure by 50% compared to pure push, high real-time performance.</td> </tr> </tbody> </table> <hr/> <h2 id="3-recommended-architecture-websocket-combined-with-kafka-asynchronous-push">3. Recommended Architecture: WebSocket Combined with Kafka Asynchronous Push</h2> <h3 id="31-notification-type-classification">3.1 Notification Type Classification</h3> <ul> <li> <p>Distinguish high-priority (@mentions/replies) and low-priority (likes), prioritize hot notifications.</p> </li> <li> <p>Prioritize pushes for active users (Redis online status, TTL=5 min).</p> </li> </ul> <h3 id="32-asynchronous-push">3.2 Asynchronous Push</h3> <ul> <li> <p>After interaction triggers, deliver to Kafka queue; consumers filter and batch push.</p> </li> <li> <p>Merge notifications (e.g., “5 people liked”) to reduce frequency.</p> </li> </ul> <h3 id="33-multi-channel-delivery">3.3 Multi-Channel Delivery</h3> <ul> <li> <p>Web/App: WebSocket as the main channel.</p> </li> <li> <p>Mobile: Fallback to FCM/APNS.</p> </li> </ul> <h3 id="34-rate-limiting-and-degradation">3.4 Rate Limiting and Degradation</h3> <ul> <li> <p>Redis token bucket rate limiting (1000/min/user).</p> </li> <li> <p>Batch merge pushes every 5 s during high load.</p> </li> </ul> <p>The following is a simplified architecture diagram of the recommended architecture (Mermaid syntax):</p> <pre><code class="language-mermaid">graph TD
    A["Interaction Event (Like/@)"] --&gt; B["Notification Service"]
    B --&gt; C["Kafka: Asynchronous Queue"]
    C --&gt; D["Consumer: Filter Active Users + Merge Notifications"]
    D --&gt; E{"Online?"}
    E --&gt;|"Yes"| F["WebSocket: Real-time Push"]
    E --&gt;|"No"| G["FCM/APNS: Mobile Push"]
    H["Redis: Online Status + Rate Limiting"] -.-&gt; D
    H -.-&gt; F
    I["Prometheus: Monitoring Delivery Rate"] -.-&gt; G
    I -.-&gt; F
</code></pre> <p>This diagram shows the overall process from event triggering to delivery.</p> <hr/> <h2 id="4-key-data-structures-and-processes">4. Key Data Structures and Processes</h2> <h3 id="41-redis-structure">4.1 Redis Structure</h3> <ul> <li> <p><code class="language-plaintext highlighter-rouge">online:{userId}</code>: Online status, value “1”, TTL=5 min.</p> </li> <li> <p><code class="language-plaintext highlighter-rouge">rate:{userId}</code>: Push rate limiting count, EX=60 s.</p> </li> <li> <p><code class="language-plaintext highlighter-rouge">notification:{userId}</code>: Temporary storage for merged notifications (HashMap).</p> </li> </ul> <h3 id="42-notification-push-process">4.2 Notification Push Process</h3> <p>The following is the process sequence diagram (Mermaid syntax):</p> <pre><code class="language-mermaid">sequenceDiagram
    participant Client as Client
    participant Service as Interaction Service
    participant Kafka as Kafka Queue
    participant Consumer as Consumer
    participant Redis as Redis (Online/Rate Limiting)
    participant WS as WebSocket
    Client-&gt;&gt;Service: Trigger Interaction (e.g., Like)
    Service-&gt;&gt;Kafka: Deliver Notification Event
    Kafka-&gt;&gt;Consumer: Consume Batch
    Consumer-&gt;&gt;Redis: Check Active + Rate Limiting
    Redis--&gt;&gt;Consumer: Return Status
    Consumer-&gt;&gt;Consumer: Merge Notifications
    Consumer-&gt;&gt;WS: Push Merged Notifications
    WS--&gt;&gt;Client: Deliver
    Note over Consumer, WS: Offline fallback to FCM/APNS
</code></pre> <h4 id="java-code-example-delivering-notifications">Java Code Example (Delivering Notifications)</h4> <div class="language-java highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">// Deliver notifications to Kafka in the interaction service</span>
<span class="kd">public</span> <span class="kt">void</span> <span class="nf">sendNotification</span><span class="o">(</span><span class="kt">long</span> <span class="n">fromUserId</span><span class="o">,</span> <span class="kt">long</span> <span class="n">toUserId</span><span class="o">,</span> <span class="nc">String</span> <span class="n">type</span><span class="o">,</span> <span class="kt">long</span> <span class="n">tweetId</span><span class="o">)</span> <span class="o">{</span>
    <span class="c1">// Serialize notification data</span>
    <span class="nc">String</span> <span class="n">notificationJson</span> <span class="o">=</span> <span class="n">serializeNotification</span><span class="o">(</span><span class="n">fromUserId</span><span class="o">,</span> <span class="n">toUserId</span><span class="o">,</span> <span class="n">type</span><span class="o">,</span> <span class="n">tweetId</span><span class="o">);</span>
    <span class="c1">// Configure Producer and send</span>
    <span class="n">kafkaProducer</span><span class="o">.</span><span class="na">send</span><span class="o">(</span><span class="k">new</span> <span class="nc">ProducerRecord</span><span class="o">&lt;&gt;(</span><span class="s">"notification-queue"</span><span class="o">,</span> <span class="nc">String</span><span class="o">.</span><span class="na">valueOf</span><span class="o">(</span><span class="n">toUserId</span><span class="o">),</span> <span class="n">notificationJson</span><span class="o">));</span>
<span class="o">}</span>
</code></pre></div></div> <h4 id="java-code-example-consumer-processing-and-pushing">Java Code Example (Consumer Processing and Pushing)</h4> <div class="language-java highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">// Kafka consumer processing logic</span>
<span class="kd">public</span> <span class="kt">void</span> <span class="nf">processNotifications</span><span class="o">()</span> <span class="o">{</span>
    <span class="nc">KafkaConsumer</span><span class="o">&lt;</span><span class="nc">String</span><span class="o">,</span> <span class="nc">String</span><span class="o">&gt;</span> <span class="n">consumer</span> <span class="o">=</span> <span class="k">new</span> <span class="nc">KafkaConsumer</span><span class="o">&lt;&gt;(</span><span class="n">props</span><span class="o">);</span>
    <span class="n">consumer</span><span class="o">.</span><span class="na">subscribe</span><span class="o">(</span><span class="nc">Collections</span><span class="o">.</span><span class="na">singleton</span><span class="o">(</span><span class="s">"notification-queue"</span><span class="o">));</span>
    <span class="k">while</span> <span class="o">(</span><span class="kc">true</span><span class="o">)</span> <span class="o">{</span>
        <span class="nc">ConsumerRecords</span><span class="o">&lt;</span><span class="nc">String</span><span class="o">,</span> <span class="nc">String</span><span class="o">&gt;</span> <span class="n">records</span> <span class="o">=</span> <span class="n">consumer</span><span class="o">.</span><span class="na">poll</span><span class="o">(</span><span class="nc">Duration</span><span class="o">.</span><span class="na">ofMillis</span><span class="o">(</span><span class="mi">100</span><span class="o">));</span>
        <span class="nc">Map</span><span class="o">&lt;</span><span class="nc">String</span><span class="o">,</span> <span class="nc">List</span><span class="o">&lt;</span><span class="nc">Notification</span><span class="o">&gt;&gt;</span> <span class="n">batchMap</span> <span class="o">=</span> <span class="n">groupByUser</span><span class="o">(</span><span class="n">records</span><span class="o">);</span> <span class="c1">// Aggregate by user</span>
        <span class="k">for</span> <span class="o">(</span><span class="nc">Map</span><span class="o">.</span><span class="na">Entry</span><span class="o">&lt;</span><span class="nc">String</span><span class="o">,</span> <span class="nc">List</span><span class="o">&lt;</span><span class="nc">Notification</span><span class="o">&gt;&gt;</span> <span class="n">entry</span> <span class="o">:</span> <span class="n">batchMap</span><span class="o">.</span><span class="na">entrySet</span><span class="o">())</span> <span class="o">{</span>
            <span class="nc">String</span> <span class="n">userId</span> <span class="o">=</span> <span class="n">entry</span><span class="o">.</span><span class="na">getKey</span><span class="o">();</span>
            <span class="nc">List</span><span class="o">&lt;</span><span class="nc">Notification</span><span class="o">&gt;</span> <span class="n">notifications</span> <span class="o">=</span> <span class="n">entry</span><span class="o">.</span><span class="na">getValue</span><span class="o">();</span>
            <span class="c1">// Check online and rate limiting</span>
            <span class="k">if</span> <span class="o">(</span><span class="s">"1"</span><span class="o">.</span><span class="na">equals</span><span class="o">(</span><span class="n">redis</span><span class="o">.</span><span class="na">get</span><span class="o">(</span><span class="s">"online:"</span> <span class="o">+</span> <span class="n">userId</span><span class="o">))</span> <span class="o">&amp;&amp;</span> <span class="n">redis</span><span class="o">.</span><span class="na">incr</span><span class="o">(</span><span class="s">"rate:"</span> <span class="o">+</span> <span class="n">userId</span><span class="o">)</span> <span class="o">&lt;=</span> <span class="mi">1000</span><span class="o">)</span> <span class="o">{</span>
                <span class="c1">// Merge notifications</span>
                <span class="nc">Map</span><span class="o">&lt;</span><span class="nc">String</span><span class="o">,</span> <span class="nc">Integer</span><span class="o">&gt;</span> <span class="n">merged</span> <span class="o">=</span> <span class="n">aggregateNotifications</span><span class="o">(</span><span class="n">notifications</span><span class="o">);</span>
                <span class="c1">// Push</span>
                <span class="nc">Session</span> <span class="n">ws</span> <span class="o">=</span> <span class="n">connections</span><span class="o">.</span><span class="na">get</span><span class="o">(</span><span class="n">userId</span><span class="o">);</span>
                <span class="k">if</span> <span class="o">(</span><span class="n">ws</span> <span class="o">!=</span> <span class="kc">null</span> <span class="o">&amp;&amp;</span> <span class="n">ws</span><span class="o">.</span><span class="na">isOpen</span><span class="o">())</span> <span class="o">{</span>
                    <span class="n">ws</span><span class="o">.</span><span class="na">getAsyncRemote</span><span class="o">().</span><span class="na">sendText</span><span class="o">(</span><span class="no">JSON</span><span class="o">.</span><span class="na">toString</span><span class="o">(</span><span class="n">merged</span><span class="o">));</span>
                <span class="o">}</span> <span class="k">else</span> <span class="o">{</span>
                    <span class="c1">// Fallback to mobile push</span>
                    <span class="n">fcm</span><span class="o">.</span><span class="na">sendToDevice</span><span class="o">(</span><span class="n">getDeviceToken</span><span class="o">(</span><span class="n">userId</span><span class="o">),</span> <span class="n">merged</span><span class="o">);</span>
                <span class="o">}</span>
            <span class="o">}</span>
            <span class="n">redis</span><span class="o">.</span><span class="na">expire</span><span class="o">(</span><span class="s">"rate:"</span> <span class="o">+</span> <span class="n">userId</span><span class="o">,</span> <span class="mi">60</span><span class="o">);</span>
        <span class="o">}</span>
    <span class="o">}</span>
<span class="o">}</span>
</code></pre></div></div> <hr/> <h2 id="5-performance-optimization-and-engineering-details">5. Performance Optimization and Engineering Details</h2> <ul> <li> <p><strong>Batch Processing</strong>: Consumers process 500 notifications per batch, Redis MGET for batch online checks.</p> </li> <li> <p><strong>Heartbeat Detection</strong>: WebSocket ping/pong every 30 s to update online status.</p> </li> <li> <p><strong>Security Protection</strong>: IP rate limiting, encrypted pushes to prevent DDoS.</p> </li> <li> <p><strong>Scaling</strong>: Kafka partitions=100, WebSocket nodes autoscaling (&gt;80% CPU).</p> </li> <li> <p><strong>Monitoring</strong>: Grafana tracks delivery rate/latency, alerts for losses &gt;1%.</p> </li> </ul> <hr/> <h2 id="6-high-frequency-interview-follow-ups-and-real-engineering-pitfalls">6. High-Frequency Interview Follow-Ups and Real Engineering Pitfalls</h2> <h3 id="high-frequency-follow-ups">High-Frequency Follow-Ups</h3> <ul> <li> <p>How to prevent queue backlogs under high concurrency? (Dynamic consumer scaling, priority queues)</p> </li> <li> <p>How to handle consistency losses? (Kafka persistence, retry mechanisms)</p> </li> <li> <p>How to ensure multi-channel synchronization? (Unified JSON format, Redis temporary storage)</p> </li> </ul> <h3 id="engineering-pitfalls">Engineering Pitfalls</h3> <ul> <li> <p>Connection memory overflow; solution: Horizontal scaling, limit connections/node &lt;100 k.</p> </li> <li> <p>DDoS amplification; solution: Token bucket + Captcha.</p> </li> <li> <p>Merge logic bugs leading to duplicate notifications; solution: HashMap aggregation + test scripts.</p> </li> </ul> <h3 id="common-misconceptions">Common Misconceptions</h3> <ul> <li> <p>Using only Polling, poor real-time performance leading to user churn.</p> </li> <li> <p>Unlimited flows, peak crashes the system.</p> </li> <li> <p>Ignoring offline pushes, poor mobile user experience.</p> </li> </ul> <hr/> <h2 id="7-summary">7. Summary</h2> <p>Twitter notifications and real-time pushes are core to enhancing user stickiness. Through WebSocket + Kafka asynchronous + multi-channel architecture, efficient delivery and resource optimization can be achieved. Engineering focuses on filtering merges, rate limiting degradation, and monitoring to ensure &gt;99% delivery rate. Combined with upstream (such as timeline events), avoid high-frequency bottlenecks, and emphasize trade-offs in interviews (such as real-time vs. Resources). Actual deployment requires testing billions-scale loads to support platform growth.</p>]]></content><author><name></name></author><category term="System Design Other"/><summary type="html"><![CDATA[Introduction]]></summary></entry><entry><title type="html">Detailed System Design of Twitter Timeline Generation</title><link href="https://zhengstar94.github.io//blog/2025/DetailedSystemDesignOfTwitterTimelineGeneration/" rel="alternate" type="text/html" title="Detailed System Design of Twitter Timeline Generation"/><published>2025-07-31T00:00:00+00:00</published><updated>2025-07-31T00:00:00+00:00</updated><id>https://zhengstar94.github.io//blog/2025/DetailedSystemDesignOfTwitterTimelineGeneration</id><content type="html" xml:base="https://zhengstar94.github.io//blog/2025/DetailedSystemDesignOfTwitterTimelineGeneration/"><![CDATA[<h2 id="introduction">Introduction</h2> <p>The timeline is a core feature of social platforms like Twitter/X. The home timeline must aggregate the latest posts from hundreds to millions of followed users in real-time, demanding high concurrency handling, low latency, and high availability. This article systematically introduces mainstream architectural approaches for timeline generation, trade-offs, engineering implementation details, and common interview follow-up questions.</p> <hr/> <h2 id="1-requirements-and-challenges">1. Requirements and Challenges</h2> <ul> <li><strong>High Concurrency</strong>: Billions of DAU, with home refresh peaks reaching tens of thousands of TPS.</li> <li><strong>Extreme Read-Write Imbalance</strong>: Read-write ratio up to 100:1, with the majority of requests being home timeline reads.</li> <li><strong>Celebrity Effect</strong>: Posts from popular users must impact millions of followers, easily creating hotspots.</li> <li><strong>Low Latency</strong>: Home refresh &lt;200 ms, post publishing &lt;100 ms.</li> <li><strong>Consistency</strong>: Eventual consistency is acceptable, with some scenarios tolerating a few seconds of delay.</li> </ul> <hr/> <h2 id="2-scheme-comparison-and-trade-offs">2. Scheme Comparison and Trade-offs</h2> <h3 id="21-fan-out-on-write-push-model">2.1 Fan-out on Write (Push Model)</h3> <ul> <li><strong>Principle</strong>: When a user publishes a post, the system immediately “pushes” (writes) the post ID to the home timeline caches of all followers. This is like an express delivery system: the poster prepares the package, and the system automatically distributes it to each follower’s “mailbox” (cache), so followers can directly retrieve it from their mailbox upon refresh. In simple terms, it’s “preparing everything in advance” to ensure efficient reads, but it assumes the follower list isn’t too large.</li> <li><strong>Advantages</strong>: Extremely fast reads, O (1) cache hits, suitable for high-read scenarios.</li> <li><strong>Disadvantages</strong>: High write pressure; a celebrity post requires millions of write operations, prone to write avalanches.</li> </ul> <h3 id="22-fan-out-on-read-pull-model">2.2 Fan-out on Read (Pull Model)</h3> <ul> <li><strong>Principle</strong>: When a user refreshes their home timeline, the system dynamically “pulls” (queries) the latest posts from all followed users’ timelines and aggregates/sorts them. This is similar to shopping at a supermarket: each refresh, the follower goes to each followed user’s “shelf” (cache or database) to pick the latest items and combines them into their shopping cart. In simple terms, it’s “on-demand fetching,” with simple writes but real-time computation during reads, prone to lag during peaks.</li> <li><strong>Advantages</strong>: Easy writes; a celebrity post only needs one write.</li> <li><strong>Disadvantages</strong>: Slow reads, requiring cross-shard/cross-service aggregation, high latency, poor scalability.</li> </ul> <h3 id="23-hybrid-fan-out">2.3 Hybrid Fan-out</h3> <ul> <li><strong>Principle</strong>: Combines the above two, differentiating by user type—ordinary users use fan-out on write (pre-push), while popular users use fan-out on read (on-demand pull). This is like a hybrid delivery model: direct door delivery for ordinary friends’ packages, but fans self-pickup for celebrities’ to avoid overwhelming the delivery staff. In simple terms, it’s a “tailored” intelligent strategy that balances read-write loads but requires extra logic for type judgment and data merging.</li> <li><strong>Advantages</strong>: Balances read-write efficiency; popular users don’t overwhelm writes, ordinary users get fast reads.</li> <li><strong>Disadvantages</strong>: Complex implementation, needing dynamic user type judgment and some computational overhead for merging.</li> </ul> <hr/> <h2 id="3-recommended-architecture-hybrid-fan-out--caching">3. Recommended Architecture: Hybrid Fan-out + Caching</h2> <h3 id="31-user-classification">3.1 User Classification</h3> <ul> <li>Set a threshold (e.g., followers &gt;10,000 for popular users); ordinary users use fan-out on write, popular users use fan-out on read.</li> <li>Cache user type results in Redis (TTL=1 hour) to reduce frequent database queries.</li> </ul> <h3 id="32-fan-out-on-write-ordinary-users">3.2 Fan-out on Write (Ordinary Users)</h3> <ul> <li>After a user posts, the post ID is asynchronously batched via Kafka and pushed to all active followers’ home timeline caches (Redis List/ZSet).</li> <li>Inactive followers are not pushed to save resources.</li> </ul> <p>The following is the sequence diagram for fan-out on write (ordinary users) (Mermaid syntax):</p> <pre><code class="language-mermaid">sequenceDiagram
    participant User as Ordinary User
    participant TimelineService as Timeline Service
    participant Kafka as Kafka Queue
    participant Redis as Redis Cache (Follower Home)

    User-&gt;&gt;TimelineService: Publish Post
    TimelineService-&gt;&gt;Kafka: Asynchronously Batch Push Post ID to Followers
    Kafka-&gt;&gt;Redis: Write to Each Active Follower's Home Timeline Cache
    Redis--&gt;&gt;Kafka: Confirm Write
    Note over TimelineService, Redis: Followers Read Directly from Cache on Refresh
</code></pre> <h4 id="java-code-example-fan-out-on-write-handling-during-posting">Java Code Example: Fan-out on Write Handling (During Posting)</h4> <div class="language-java highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">// In TimelineService, handle ordinary user posting with fan-out on write (simplified; actual should be async via Kafka)</span>
<span class="kd">public</span> <span class="kt">void</span> <span class="nf">fanOutOnWrite</span><span class="o">(</span><span class="kt">long</span> <span class="n">userId</span><span class="o">,</span> <span class="kt">long</span> <span class="n">tweetId</span><span class="o">)</span> <span class="o">{</span>
    <span class="c1">// Fetch active followers list (assume from DB or cache)</span>
    <span class="nc">List</span><span class="o">&lt;</span><span class="nc">Long</span><span class="o">&gt;</span> <span class="n">activeFollowers</span> <span class="o">=</span> <span class="n">getActiveFollowers</span><span class="o">(</span><span class="n">userId</span><span class="o">);</span>
    
    <span class="c1">// Use Redis Pipeline for batch writes to optimize performance</span>
    <span class="nc">Pipeline</span> <span class="n">pipeline</span> <span class="o">=</span> <span class="n">redis</span><span class="o">.</span><span class="na">pipelined</span><span class="o">();</span>
    <span class="k">for</span> <span class="o">(</span><span class="kt">long</span> <span class="n">followerId</span> <span class="o">:</span> <span class="n">activeFollowers</span><span class="o">)</span> <span class="o">{</span>
        <span class="c1">// Push post ID to follower's home timeline (use LPUSH to keep newest on top)</span>
        <span class="n">pipeline</span><span class="o">.</span><span class="na">lpush</span><span class="o">(</span><span class="s">"home_timeline:"</span> <span class="o">+</span> <span class="n">followerId</span><span class="o">,</span> <span class="n">tweetId</span><span class="o">);</span>
    <span class="o">}</span>
    <span class="n">pipeline</span><span class="o">.</span><span class="na">sync</span><span class="o">();</span>  <span class="c1">// Execute batch operations</span>
<span class="o">}</span>
</code></pre></div></div> <h3 id="33-fan-out-on-read-popular-users">3.3 Fan-out on Read (Popular Users)</h3> <ul> <li>Popular users’ posts are only written to their own user timeline cache.</li> <li>When followers refresh home, the timeline service dynamically pulls these popular users’ latest posts and merges/sorts them with ordinary users’ posts (using a priority queue).</li> </ul> <p>The following is the sequence diagram for fan-out on read (popular users) (Mermaid syntax, focusing on write phase; read phase in home generation flow):</p> <pre><code class="language-mermaid">sequenceDiagram
    participant User as Popular User
    participant TimelineService as Timeline Service
    participant Redis as Redis Cache (User Timeline)

    User-&gt;&gt;TimelineService: Publish Post
    TimelineService-&gt;&gt;Redis: Write Only to Popular User's User Timeline Cache
    Redis--&gt;&gt;TimelineService: Confirm Write
    Note over TimelineService, Redis: Followers Dynamically Pull and Merge on Refresh
</code></pre> <h4 id="java-code-example-fan-out-on-read-handling-during-posting-write-to-own-timeline-only">Java Code Example: Fan-out on Read Handling (During Posting, Write to Own Timeline Only)</h4> <div class="language-java highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">// In TimelineService, handle popular user posting with fan-out on read (write to own timeline only)</span>
<span class="kd">public</span> <span class="kt">void</span> <span class="nf">writeToUserTimeline</span><span class="o">(</span><span class="kt">long</span> <span class="n">userId</span><span class="o">,</span> <span class="kt">long</span> <span class="n">tweetId</span><span class="o">)</span> <span class="o">{</span>
    <span class="c1">// Push post ID to user's personal timeline (use LPUSH to keep newest on top)</span>
    <span class="n">redis</span><span class="o">.</span><span class="na">lpush</span><span class="o">(</span><span class="s">"user_timeline:"</span> <span class="o">+</span> <span class="n">userId</span><span class="o">,</span> <span class="n">tweetId</span><span class="o">);</span>
<span class="o">}</span>
</code></pre></div></div> <h3 id="34-caching-and-pre-warming">3.4 Caching and Pre-warming</h3> <ul> <li>Home timelines, user timelines, and post contents use sharded Redis caches; regularly pre-warm for popular/active users.</li> <li>Combine TTL and LRU to ensure hot data resides in memory.</li> </ul> <h3 id="35-monitoring-and-degradation">3.5 Monitoring and Degradation</h3> <ul> <li>Use Prometheus to monitor fan-out latency, cache hit rates, etc.</li> <li>Under high load, automatically degrade to return cached data only, prompting users to “refresh for latest.”</li> </ul> <h3 id="36-architecture-diagram">3.6 Architecture Diagram</h3> <p>The following is a simplified architecture diagram of the recommended approach (Mermaid syntax, viewable in Mermaid-supported Markdown renderers):</p> <pre><code class="language-mermaid">graph TD
    A[User Posts] --&gt; B{User Type?}
    B --&gt;|Ordinary User| C[Fan-out on Write: Kafka Async Push Post ID to Followers' Home Cache]
    B --&gt;|Popular User| D[Fan-out on Read: Write Only to User Timeline Cache]
    E[Follower Refreshes Home] --&gt; F[Pull Ordinary Users' Posts from Cache]
    E --&gt; G[Dynamically Pull Popular Users' Posts from Cache]
    F --&gt; H[Merge &amp; Sort: Priority Queue]
    G --&gt; H
    H --&gt; I[Return Timeline]
    J[Redis Sharded Cache] -.-&gt; C
    J -.-&gt; D
    J -.-&gt; F
    J -.-&gt; G
    K[Kafka Queue] -.-&gt; C
    L[Prometheus Monitoring] -.-&gt; I
</code></pre> <p>This diagram illustrates the overall flow for posting and home refresh, highlighting the hybrid fan-out branching logic.</p> <hr/> <h2 id="4-key-data-structures-and-flows">4. Key Data Structures and Flows</h2> <h3 id="41-redis-cache-structures">4.1 Redis Cache Structures</h3> <ul> <li><code class="language-plaintext highlighter-rouge">home_timeline:{user_id}</code>: Home timeline cache, stores post IDs, TTL=1 hour.</li> <li><code class="language-plaintext highlighter-rouge">user_timeline:{user_id}</code>: User timeline cache, stores post IDs, TTL=1 hour.</li> <li><code class="language-plaintext highlighter-rouge">tweet:{tweet_id}</code>: Post content cache.</li> </ul> <h3 id="42-home-timeline-generation-flow">4.2 Home Timeline Generation Flow</h3> <p>The following is the sequence diagram for the flow (Mermaid syntax):</p> <pre><code class="language-mermaid">sequenceDiagram
    participant User as User
    participant TimelineService as Timeline Service
    participant Redis as Redis Cache
    participant Kafka as Kafka Queue

    User-&gt;&gt;TimelineService: Refresh Home
    TimelineService-&gt;&gt;Redis: Pull Ordinary Followed Users' Posts (Fan-out on Write Cache)
    Redis--&gt;&gt;TimelineService: Return Post List
    TimelineService-&gt;&gt;Redis: Pull Popular Followed Users' Latest Posts (Fan-out on Read)
    Redis--&gt;&gt;TimelineService: Return Post List
    TimelineService-&gt;&gt;TimelineService: Merge &amp; Sort (Priority Queue)
    TimelineService--&gt;&gt;User: Return Merged Timeline

    Note over TimelineService, Kafka: During Posting: Ordinary Users Async Fan-out via Kafka to Followers' Cache
</code></pre> <h4 id="java-code-example-merge--sort-during-home-refresh">Java Code Example (Merge &amp; Sort During Home Refresh)</h4> <div class="language-java highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">// 1. Pull ordinary followed users' posts from Redis (pre-pushed via fan-out on write)</span>
<span class="c1">// Assume nonHotKey is the current user's home cache key, limit is posts per page (e.g., 20)</span>
<span class="nc">List</span><span class="o">&lt;</span><span class="nc">Tweet</span><span class="o">&gt;</span> <span class="n">nonHotTweets</span> <span class="o">=</span> <span class="n">redis</span><span class="o">.</span><span class="na">lrange</span><span class="o">(</span><span class="n">nonHotKey</span><span class="o">,</span> <span class="mi">0</span><span class="o">,</span> <span class="n">limit</span><span class="o">);</span>

<span class="c1">// 2. Pull all popular users' (celebrities) latest posts from Redis</span>
<span class="c1">// hotKey is the popular user's user timeline cache key, pull up to 500 to prevent overload</span>
<span class="nc">List</span><span class="o">&lt;</span><span class="nc">Tweet</span><span class="o">&gt;</span> <span class="n">hotTweets</span> <span class="o">=</span> <span class="n">redis</span><span class="o">.</span><span class="na">lrange</span><span class="o">(</span><span class="n">hotKey</span><span class="o">,</span> <span class="mi">0</span><span class="o">,</span> <span class="mi">500</span><span class="o">);</span>

<span class="c1">// 3. Create a priority queue (max-heap) for merging posts in descending timestamp order</span>
<span class="c1">// This ensures the final home timeline has newest posts first</span>
<span class="nc">PriorityQueue</span><span class="o">&lt;</span><span class="nc">Tweet</span><span class="o">&gt;</span> <span class="n">pq</span> <span class="o">=</span> <span class="k">new</span> <span class="nc">PriorityQueue</span><span class="o">&lt;&gt;(</span>
    <span class="o">(</span><span class="n">a</span><span class="o">,</span> <span class="n">b</span><span class="o">)</span> <span class="o">-&gt;</span> <span class="nc">Long</span><span class="o">.</span><span class="na">compare</span><span class="o">(-</span><span class="n">a</span><span class="o">.</span><span class="na">timestamp</span><span class="o">,</span> <span class="o">-</span><span class="n">b</span><span class="o">.</span><span class="na">timestamp</span><span class="o">)</span> <span class="c1">// Larger timestamps rank first</span>
<span class="o">);</span>

<span class="c1">// 4. Add ordinary and popular users' posts to the priority queue</span>
<span class="n">pq</span><span class="o">.</span><span class="na">addAll</span><span class="o">(</span><span class="n">nonHotTweets</span><span class="o">);</span>
<span class="n">pq</span><span class="o">.</span><span class="na">addAll</span><span class="o">(</span><span class="n">hotTweets</span><span class="o">);</span>

<span class="c1">// 5. Pop newest posts from the queue sequentially until reaching the page limit (e.g., 20)</span>
<span class="nc">List</span><span class="o">&lt;</span><span class="nc">Tweet</span><span class="o">&gt;</span> <span class="n">merged</span> <span class="o">=</span> <span class="k">new</span> <span class="nc">ArrayList</span><span class="o">&lt;&gt;();</span>
<span class="k">while</span> <span class="o">(!</span><span class="n">pq</span><span class="o">.</span><span class="na">isEmpty</span><span class="o">()</span> <span class="o">&amp;&amp;</span> <span class="n">merged</span><span class="o">.</span><span class="na">size</span><span class="o">()</span> <span class="o">&lt;</span> <span class="n">limit</span><span class="o">)</span> <span class="o">{</span>
    <span class="n">merged</span><span class="o">.</span><span class="na">add</span><span class="o">(</span><span class="n">pq</span><span class="o">.</span><span class="na">poll</span><span class="o">());</span>
<span class="o">}</span>

<span class="c1">// 6. Return the merged home timeline post list</span>
<span class="k">return</span> <span class="n">merged</span><span class="o">;</span>
</code></pre></div></div> <hr/> <h2 id="5-performance-optimizations-and-engineering-details">5. Performance Optimizations and Engineering Details</h2> <ul> <li><strong>Batch Operations</strong>: Kafka messages and Redis Pipeline for batch writes to reduce network IO.</li> <li><strong>Async Decoupling</strong>: All fan-out on write operations handled asynchronously via Kafka to avoid blocking main flows.</li> <li><strong>Merge &amp; Sort</strong>: Use efficient heap sort for merging popular and ordinary posts, with memory pre-allocation to prevent GC jitter.</li> <li><strong>Sharding &amp; Scaling</strong>: Shard Redis, Kafka, and timeline services for horizontal scaling to support DAU growth.</li> <li><strong>Pagination Support</strong>: Support page_token for users to pull more historical posts on scroll.</li> </ul> <hr/> <h2 id="6-common-interview-follow-ups-and-real-engineering-pitfalls">6. Common Interview Follow-ups and Real Engineering Pitfalls</h2> <h3 id="high-frequency-follow-ups">High-Frequency Follow-ups</h3> <ul> <li>How to handle write pressure for celebrity posts? (Hybrid fan-out, async batching, push only to active followers)</li> <li>How to self-protect during cache avalanches? (Pre-warming, rate limiting, degradation)</li> <li>How to ensure no interruptions during shard migrations? (Dual-write sync, throttled migration, graceful degradation)</li> </ul> <h3 id="engineering-pitfalls">Engineering Pitfalls</h3> <ul> <li>Kafka queue backlogs causing post delays, requiring dynamic consumer scaling.</li> <li>Unsynchronized cache invalidations leading to stale data, needing dual-write consistency or Pub/Sub.</li> <li>Untimely hotspot shard migrations causing single-point bottlenecks affecting the whole system.</li> </ul> <h3 id="common-misconceptions">Common Misconceptions</h3> <ul> <li>Using fan-out on write for all users, leading to system crashes under celebrity effects.</li> <li>Relying only on TTL without pre-warming, high risk of cache avalanches.</li> <li>No load balancing after sharding, with hot shards dragging down the system.</li> </ul> <hr/> <h2 id="7-summary">7. Summary</h2> <p>Home timeline generation is a core challenge in social platform system design. Adopting a hybrid fan-out + caching + async decoupling + monitoring/degradation architecture balances high concurrency, low latency, and high availability, handling celebrity effects and sudden hotspots while ensuring smooth experiences for most users. Engineering implementations must focus on batching, async, sharding, cache consistency, and degradation strategies to avoid common misconceptions and pitfalls.</p>]]></content><author><name></name></author><category term="System Design Other"/><summary type="html"><![CDATA[Introduction]]></summary></entry><entry><title type="html">Technical Guide to Distributed Unique IDs</title><link href="https://zhengstar94.github.io//blog/2025/TechnicalGuideToDistributedUniqueIDs/" rel="alternate" type="text/html" title="Technical Guide to Distributed Unique IDs"/><published>2025-07-06T00:00:00+00:00</published><updated>2025-07-06T00:00:00+00:00</updated><id>https://zhengstar94.github.io//blog/2025/TechnicalGuideToDistributedUniqueIDs</id><content type="html" xml:base="https://zhengstar94.github.io//blog/2025/TechnicalGuideToDistributedUniqueIDs/"><![CDATA[<h2 id="1-the-need-for-distributed-globally-unique-ids">1. The Need for Distributed, Globally Unique IDs</h2> <p>In traditional monolithic architectures, systems typically rely on a single database. The primary keys for business tables are often generated using the database’s <code class="language-plaintext highlighter-rouge">AUTO_INCREMENT</code> feature. This method is simple, reliable, and guarantees uniqueness within that single database.</p> <p>However, in modern distributed and microservices architectures, systems are often partitioned to handle high concurrency and massive data volumes. This means that data for a single business entity, such as “orders,” is spread across multiple database instances or tables. In such a scenario, if each shard independently uses its own <code class="language-plaintext highlighter-rouge">AUTO_INCREMENT</code> mechanism, ID collisions become inevitable, as illustrated below:</p> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2025/07/6-480.webp 480w,/assets/img/2025/07/6-800.webp 800w,/assets/img/2025/07/6-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/2025/07/6.png" class="img-fluid rounded z-depth-1" width="50%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <p>Although the system architecture is distributed, at the business logic and user level, an order ID must be globally unique. Duplicate primary keys are unacceptable.</p> <p>Therefore, designing a high-performance, highly available, and globally unique ID generation scheme is a foundational requirement for any distributed system. This document provides an in-depth analysis of common distributed ID generation solutions.</p> <h2 id="2-common-distributed-id-generation-schemes">2. Common Distributed ID Generation Schemes</h2> <h3 id="21-uuid-universally-unique-identifier">2.1. UUID (Universally Unique Identifier)</h3> <p>A UUID is a 128-bit number used to identify information in computer systems. The theoretical number of possible UUIDs is <code class="language-plaintext highlighter-rouge">2^128</code>, making collisions practically impossible for the foreseeable future. The standard format is <code class="language-plaintext highlighter-rouge">8-4-4-4-12</code>, though hyphens are often removed in practice.</p> <p><strong>Key UUID Versions:</strong></p> <ul> <li><strong>Version 1 (Time-based):</strong> Generated from a timestamp, a random number, and the local MAC address. While unique, it can expose the MAC address, posing a security risk.</li> <li><strong>Version 2 (DCE Security):</strong> Similar to Version 1, but replaces parts of the timestamp with POSIX UID/GID. It is rarely used.</li> <li><strong>Version 3 (Name-based, MD 5):</strong> Generated from the MD 5 hash of a namespace and a name. It is deterministic: the same input produces the same UUID.</li> <li><strong>Version 4 (Random):</strong> Generated from random or pseudo-random numbers. This is the most common version, and it’s what <code class="language-plaintext highlighter-rouge">UUID.randomUUID()</code> in Java generates.</li> <li><strong>Version 5 (Name-based, SHA-1):</strong> Similar to Version 3 but uses the SHA-1 hashing algorithm.</li> </ul> <p><strong>Java Code Example:</strong></p> <div class="language-java highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">java.util.UUID</span><span class="o">;</span>

<span class="kd">public</span> <span class="kd">class</span> <span class="nc">UuidExample</span> <span class="o">{</span>
    <span class="kd">public</span> <span class="kd">static</span> <span class="kt">void</span> <span class="nf">main</span><span class="o">(</span><span class="nc">String</span><span class="o">[]</span> <span class="n">args</span><span class="o">)</span> <span class="o">{</span>
        <span class="c1">// Version 4: Random UUID</span>
        <span class="no">UUID</span> <span class="n">randomUuid</span> <span class="o">=</span> <span class="no">UUID</span><span class="o">.</span><span class="na">randomUUID</span><span class="o">();</span>
        <span class="nc">System</span><span class="o">.</span><span class="na">out</span><span class="o">.</span><span class="na">println</span><span class="o">(</span><span class="s">"Random UUID: "</span> <span class="o">+</span> <span class="n">randomUuid</span><span class="o">.</span><span class="na">toString</span><span class="o">().</span><span class="na">replaceAll</span><span class="o">(</span><span class="s">"-"</span><span class="o">,</span> <span class="s">""</span><span class="o">));</span>

        <span class="c1">// Version 3: Name-based UUID</span>
        <span class="kt">byte</span><span class="o">[]</span> <span class="n">nameBytes</span> <span class="o">=</span> <span class="s">"hello-world"</span><span class="o">.</span><span class="na">getBytes</span><span class="o">();</span>
        <span class="no">UUID</span> <span class="n">nameUuid</span> <span class="o">=</span> <span class="no">UUID</span><span class="o">.</span><span class="na">nameUUIDFromBytes</span><span class="o">(</span><span class="n">nameBytes</span><span class="o">);</span>
        <span class="nc">System</span><span class="o">.</span><span class="na">out</span><span class="o">.</span><span class="na">println</span><span class="o">(</span><span class="s">"Name-based UUID: "</span> <span class="o">+</span> <span class="n">nameUuid</span><span class="o">.</span><span class="na">toString</span><span class="o">().</span><span class="na">replaceAll</span><span class="o">(</span><span class="s">"-"</span><span class="o">,</span> <span class="s">""</span><span class="o">));</span>
    <span class="o">}</span>
<span class="o">}</span>
</code></pre></div></div> <p><strong>Analysis:</strong></p> <ul> <li><strong>Pros:</strong></li> <li><strong>Local Generation:</strong> Extremely high performance as no network requests are needed.</li> <li><strong>Global Uniqueness:</strong> The probability of collision is infinitesimally small.</li> <li><strong>Simplicity:</strong> Natively supported in most languages, often requiring just a single line of code.</li> <li><strong>Cons:</strong></li> <li><strong>Storage Inefficiency:</strong> UUIDs are long strings (36 characters with hyphens), consuming more storage space than numerical IDs.</li> <li><strong>Poor Indexing Performance:</strong> UUIDs are non-sequential. Using them as primary keys in database engines like InnoDB (which uses B+ trees) leads to frequent index page splits and random data inserts, severely degrading write performance.</li> <li><strong>Lack of Readability:</strong> The ID itself is opaque and carries no discernible information.</li> </ul> <h3 id="22-database-auto-increment-scheme">2.2. Database Auto-Increment Scheme</h3> <p>This scheme extends the single-database auto-increment concept to a distributed environment through careful configuration.</p> <p><strong>Core Idea:</strong> Configure each database instance with a different <strong>starting value (offset)</strong> and a common <strong>step (increment)</strong>.</p> <p>For example, with three MySQL servers, the configuration could be:</p> <ul> <li><strong>DB 1:</strong> <code class="language-plaintext highlighter-rouge">auto_increment_offset=1</code>, <code class="language-plaintext highlighter-rouge">auto_increment_increment=3</code> → Generated IDs: 1, 4, 7, 10, …</li> <li><strong>DB 2:</strong> <code class="language-plaintext highlighter-rouge">auto_increment_offset=2</code>, <code class="language-plaintext highlighter-rouge">auto_increment_increment=3</code> → Generated IDs: 2, 5, 8, 11, …</li> <li><strong>DB 3:</strong> <code class="language-plaintext highlighter-rouge">auto_increment_offset=3</code>, <code class="language-plaintext highlighter-rouge">auto_increment_increment=3</code> → Generated IDs: 3, 6, 9, 12, …</li> </ul> <p><strong>Analysis:</strong></p> <ul> <li><strong>Pros:</strong></li> <li><strong>Simple Implementation:</strong> Requires only database configuration, no extra components.</li> <li><strong>Ordered IDs:</strong> Generates numeric, incrementally ordered IDs, which are friendly to database indexes.</li> <li><strong>Cons:</strong></li> <li><strong>Strong Database Dependency:</strong> The database becomes a performance bottleneck and a single point of failure for ID generation.</li> <li><strong>Poor Scalability:</strong> Adding or removing database instances is a high-risk operation, requiring recalculation and reconfiguration across all instances.</li> <li><strong>Consistency Risks:</strong> In scenarios like master-slave failover, there’s a risk of data inconsistency that could lead to duplicate IDs.</li> </ul> <h3 id="23-redis-atomic-increment-scheme">2.3. Redis Atomic Increment Scheme</h3> <p>Redis provides atomic commands like <code class="language-plaintext highlighter-rouge">INCR</code> and <code class="language-plaintext highlighter-rouge">INCRBY</code>. Because Redis executes commands in a single-threaded manner, it naturally guarantees the uniqueness and order of generated IDs.</p> <p><strong>Core Idea:</strong> Use Redis’s atomic operations to generate a globally unique sequence.</p> <p><strong>Implementation:</strong> For each ID request, a client sends an <code class="language-plaintext highlighter-rouge">INCR a_unique_key</code> command to Redis. To prevent the ID from growing indefinitely, it’s often combined with a business prefix or a timestamp.</p> <p><strong>Analysis:</strong></p> <ul> <li><strong>Pros:</strong></li> <li><strong>High Performance:</strong> Operations are in-memory and significantly faster than a database.</li> <li><strong>Ordered IDs:</strong> The generated IDs are strictly increasing.</li> <li><strong>Cons:</strong></li> <li><strong>Introduces a New Component:</strong> Requires the introduction and maintenance of Redis, increasing architectural complexity.</li> <li><strong>Strong Redis Dependency:</strong> The availability of the ID service is tied to Redis. A highly available Redis cluster (e.g., Sentinel or Cluster mode) is necessary to mitigate this.</li> <li><strong>Network Overhead:</strong> Every ID generation requires a network round-trip, which can be a significant cost under high concurrency.</li> </ul> <h2 id="3-a-milestone-twitters-snowflake-algorithm">3. A Milestone: Twitter’s Snowflake Algorithm</h2> <p>The previous solutions all have significant drawbacks. In 2010, Twitter open-sourced its Snowflake algorithm, an elegant solution for generating IDs locally in a distributed environment. It has since become the foundational model for many modern distributed ID schemes.</p> <h3 id="31-core-idea-and-id-structure">3.1. Core Idea and ID Structure</h3> <p>Snowflake’s core idea is to <strong>partition a 64-bit long integer into several sections at the binary level, with each section having a specific meaning</strong>. This allows each node to generate globally unique IDs locally, without communicating with other nodes.</p> <p>A standard Snowflake ID is structured as follows:</p> <table> <thead> <tr> <th style="text-align: left">Section</th> <th style="text-align: center">Sign Bit</th> <th style="text-align: center">Timestamp</th> <th style="text-align: center">Datacenter ID</th> <th style="text-align: center">Worker ID</th> <th style="text-align: center">Sequence</th> </tr> </thead> <tbody> <tr> <td style="text-align: left"><strong>Bits</strong></td> <td style="text-align: center">1 bit</td> <td style="text-align: center">41 bits</td> <td style="text-align: center">5 bits</td> <td style="text-align: center">5 bits</td> <td style="text-align: center">12 bits</td> </tr> <tr> <td style="text-align: left"><strong>Meaning</strong></td> <td style="text-align: center">Fixed to 0 (for positive IDs)</td> <td style="text-align: center">Millisecond timestamp offset</td> <td style="text-align: center">Identifies the datacenter</td> <td style="text-align: center">Identifies the node/machine</td> <td style="text-align: center">Intra-millisecond counter</td> </tr> </tbody> </table> <blockquote> <p><strong>Conceptual Analogy:</strong></p> <p>Think of the Snowflake algorithm as a system for <strong>minting highly precise, unique identification cards</strong>.</p> <ul> <li><strong>The 64-bit ID</strong> is the blank ID card.</li> <li><strong>The Timestamp (41 bits)</strong> is the <strong>“Date of Issue,”</strong> precise to the millisecond. It defines the “era” of the ID and is its most significant part.</li> <li><strong>The Datacenter ID (5 bits)</strong> is the <strong>“Issuing Province.”</strong></li> <li><strong>The Worker ID (5 bits)</strong> is the specific <strong>“Issuing City Office”</strong> within that province.</li> <li><strong>The Sequence (12 bits)</strong> is the <strong>“Serial Number”</strong> issued by that specific office within the same millisecond.</li> </ul> <p>By combining the <strong>time of issue + location of issue (province + city) + local serial number</strong>, this system guarantees that every ID card produced is globally unique.</p> </blockquote> <h3 id="32-detailed-breakdown-of-each-section">3.2. Detailed Breakdown of Each Section</h3> <h4 id="321-sign-bit-1-bit">3.2.1. Sign Bit (1 bit)</h4> <p>The most significant bit of a <code class="language-plaintext highlighter-rouge">long</code> in Java is the sign bit. It is fixed to <code class="language-plaintext highlighter-rouge">0</code> to ensure all generated IDs are positive and to simplify cross-language compatibility.</p> <h4 id="322-timestamp-41-bits">3.2.2. Timestamp (41 bits)</h4> <ul> <li><strong>Content:</strong> This section stores the difference between the <code class="language-plaintext highlighter-rouge">current timestamp (in milliseconds)</code> and a <code class="language-plaintext highlighter-rouge">custom epoch timestamp</code>.</li> <li><strong>The <code class="language-plaintext highlighter-rouge">twepoch</code>:</strong> In Twitter’s official implementation, this epoch is set to <code class="language-plaintext highlighter-rouge">1288834974657L</code>, which corresponds to <strong>Nov 04, 2010 01:42:54 UTC</strong>.</li> <li><strong>Why a Custom Epoch?</strong> 41 bits cannot store the full number of milliseconds since the Unix epoch (Jan 1, 1970). By using a more recent starting point, a large absolute timestamp is converted into a smaller relative one. This allows 41 bits to cover a span of approximately <strong>69 years</strong> ($2^{41} / (1000 \cdot 60 \cdot 60 \cdot 24 \cdot 365) \approx 69$ years). The algorithm can thus be used until around the year 2079.</li> </ul> <h4 id="323-datacenter-id-5-bits--worker-id-5-bits--10-bits">3.2.3. Datacenter ID (5 bits) + Worker ID (5 bits) = 10 bits</h4> <p>These 10 bits collectively form the <strong>worker node ID</strong>, distinguishing different ID generation nodes.</p> <ul> <li><strong>Capacity:</strong></li> <li>Datacenter ID (5 bits): Supports $2^5 = 32$ datacenters.</li> <li>Worker ID (5 bits): Supports $2^5 = 32$ machines per datacenter.</li> <li>This allows for a total of $32 \times 32 = 1024$ nodes.</li> <li><strong>Allocation Mechanism:</strong> Manually configuring worker IDs in a dynamic cloud environment is infeasible. The standard practice is to <strong>rely on a coordination service like ZooKeeper for automatic allocation</strong>.</li> <li><strong>Process:</strong> On startup, a service instance creates an <strong>ephemeral sequential node</strong> in a designated ZooKeeper path. ZooKeeper assigns a globally unique sequence number to this node, which is then used as the <code class="language-plaintext highlighter-rouge">workerId</code>.</li> <li><strong>Automatic Reclamation:</strong> Because the node is ephemeral, it is automatically deleted if the service instance crashes or loses its connection to ZooKeeper. This allows the <code class="language-plaintext highlighter-rouge">workerId</code> to be reused by a new instance, preventing ID waste.</li> </ul> <h4 id="324-sequence-12-bits">3.2.4. Sequence (12 bits)</h4> <ul> <li><strong>Purpose:</strong> Resolves collisions when multiple IDs are generated on the <strong>same node within the same millisecond</strong>.</li> <li><strong>Capacity:</strong> 12 bits can represent $2^{12} = 4096$ values (0-4095).</li> <li><strong>Mechanism:</strong></li> <li>The sequence number is incremented for each ID generated within the same millisecond.</li> <li><strong>What if the sequence is exhausted (reaches 4095)?</strong> The original Snowflake implementation performs a <strong>spin-wait</strong>, pausing the thread until the next millisecond arrives.</li> <li>Once the clock ticks to the next millisecond, the sequence number is reset to <code class="language-plaintext highlighter-rouge">0</code>.</li> <li><strong>Performance Limit:</strong> This design sets the theoretical performance ceiling for a single Snowflake node at <strong>4095 IDs/millisecond</strong>, or approximately <strong>4.09 million IDs/second</strong>, which is more than sufficient for most use cases.</li> </ul> <h3 id="33-the-core-challenge-clock-skew">3.3. The Core Challenge: Clock Skew</h3> <p>This is Snowflake’s most famous “Achilles’ heel.” Server clocks can drift backwards due to NTP synchronization or other reasons.</p> <ul> <li><strong>Critical Impact:</strong> If the clock moves backward, the <code class="language-plaintext highlighter-rouge">current timestamp</code> could be less than the <code class="language-plaintext highlighter-rouge">last recorded timestamp</code>, potentially leading to duplicate IDs and breaking the algorithm’s time-ordered nature.</li> <li><strong>Twitter’s Original Solution:</strong> A <strong>Fail-Fast</strong> strategy.</li> <li>The code detects if the current time is earlier than the last recorded time and <strong>immediately throws an exception</strong>.</li> <li>This means the node becomes <strong>unavailable</strong> for ID generation until the clock issue is resolved.</li> <li>This strategy prioritizes data correctness over availability (“better to be down than to be wrong”).</li> </ul> <h3 id="34-snowflake-summary">3.4. Snowflake Summary</h3> <table> <thead> <tr> <th style="text-align: left">Pros</th> <th style="text-align: left">Cons</th> </tr> </thead> <tbody> <tr> <td style="text-align: left"><strong>High Performance:</strong> Local generation with low latency.</td> <td style="text-align: left"><strong>Strong Clock Dependency:</strong> Clock skew is a critical issue.</td> </tr> <tr> <td style="text-align: left"><strong>Time-Ordered IDs:</strong> IDs are roughly sortable by time.</td> <td style="text-align: left"><strong>Requires Coordination Service:</strong> Worker ID allocation depends on components like ZooKeeper.</td> </tr> <tr> <td style="text-align: left"><strong>Embedded Information:</strong> IDs contain timestamp and node data.</td> <td style="text-align: left"><strong>Fixed Bit Allocation:</strong> The 1024-node limit can be a constraint in large-scale deployments.</td> </tr> <tr> <td style="text-align: left"><strong>Numeric Type:</strong> Efficient storage and querying as a 64-bit long.</td> <td style="text-align: left"><strong>Frontend Overflow Risk:</strong> JavaScript cannot precisely handle 64-bit integers.</td> </tr> </tbody> </table> <h2 id="4-industry-evolutions-and-variants">4. Industry Evolutions and Variants</h2> <p>While Snowflake’s design is brilliant, its complexity in worker ID allocation and its vulnerability to clock skew left room for improvement. Major tech companies like Baidu and Meituan have developed and open-sourced their own enhanced solutions.</p> <h3 id="41-baidus-uidgenerator-engineered-for-performance-and-ease-of-use">4.1. Baidu’s UidGenerator: Engineered for Performance and Ease of Use</h3> <p>UidGenerator is an open-source ID generator from Baidu that improves upon Snowflake with a focus on <strong>usability</strong> and <strong>concurrent performance</strong>.</p> <h4 id="411-core-design-a-restructured-id-1-28-22-13">4.1.1. Core Design: A Restructured ID (1-28-22-13)</h4> <p>UidGenerator significantly alters the 64-bit structure, changing the time unit from milliseconds to seconds.</p> <table> <thead> <tr> <th style="text-align: left">Section</th> <th style="text-align: center">Sign Bit</th> <th style="text-align: center">Delta Seconds</th> <th style="text-align: center">Worker ID</th> <th style="text-align: center">Sequence</th> </tr> </thead> <tbody> <tr> <td style="text-align: left"><strong>Bits</strong></td> <td style="text-align: center">1 bit</td> <td style="text-align: center">28 bits</td> <td style="text-align: center">22 bits</td> <td style="text-align: center">13 bits</td> </tr> </tbody> </table> <ul> <li><strong>Timestamp (28 bits, seconds):</strong></li> <li><strong>Sacrifice:</strong> The usable lifespan is reduced from 69 years to approximately <strong>8.5 years</strong> ($2^{28}$ seconds). This is a major trade-off that requires careful system lifecycle planning.</li> <li><strong>Gain:</strong> Frees up <code class="language-plaintext highlighter-rouge">41 - 28 = 13</code> bits for other sections.</li> <li><strong>Worker ID (22 bits):</strong></li> <li><strong>Pain Point Solved:</strong> Supports $2^{22}$ (over <strong>4 million</strong>) nodes. This completely resolves the <code class="language-plaintext highlighter-rouge">workerId</code> limitation of classic Snowflake, making it highly suitable for containerized cloud environments with frequent instance churn.</li> <li><strong>Sequence (13 bits):</strong></li> <li><strong>Capacity:</strong> Supports $2^{13} = 8192$.</li> <li><strong>Meaning:</strong> Allows for 8192 unique IDs to be generated <strong>per second</strong> on a single node.</li> </ul> <h4 id="412-worker-id-allocation-from-zookeeper-to-the-database">4.1.2. Worker ID Allocation: From ZooKeeper to the Database</h4> <p>UidGenerator replaces the ZooKeeper dependency with a component that nearly every project already has: a <strong>database</strong>.</p> <ul> <li><strong>Implementation:</strong> On startup, the service inserts a record into a <code class="language-plaintext highlighter-rouge">WORKER_NODE</code> table containing its host and port. The <strong>auto-incremented primary key</strong> generated by the database for this record is used as the <code class="language-plaintext highlighter-rouge">workerId</code>.</li> <li><strong>Advantage:</strong> <strong>Drastically reduces operational overhead and technology stack complexity</strong>, as there is no need to maintain a ZK cluster.</li> <li><strong>Disadvantages:</strong></li> <li><strong>Startup Dependency on DB:</strong> New instances cannot start if the database is down.</li> <li><strong>ID Waste:</strong> The default strategy consumes a new <code class="language-plaintext highlighter-rouge">workerId</code> on every restart.</li> </ul> <h4 id="413-the-performance-weapon-cacheduidgenerator-and-the-ringbuffer">4.1.3. The Performance Weapon: CachedUidGenerator and the RingBuffer</h4> <p>This is the core of UidGenerator and its recommended mode of operation. It uses a <strong>“space-for-time”</strong> trade-off to deliver extreme performance.</p> <ul> <li><strong>Core Idea:</strong> <strong>Pre-generation and caching of IDs.</strong> This decouples the “production” of IDs from their “consumption.”</li> <li><strong>The RingBuffer:</strong></li> <li><strong>Producer:</strong> A <strong>background thread</strong> asynchronously generates IDs in batches and populates a RingBuffer (a circular array).</li> <li><strong>Consumer:</strong> When a business thread requests an ID, it does not compute it on the spot. Instead, it retrieves one from the RingBuffer <strong>lock-free (via CAS atomic operations)</strong>.</li> </ul> <blockquote> <p><strong>Conceptual Analogy:</strong></p> <p><code class="language-plaintext highlighter-rouge">CachedUidGenerator</code> operates like a <strong>highly efficient, modern coffee shop</strong>.</p> <ul> <li><strong>Business Requests</strong> are the customers.</li> <li><strong>The RingBuffer</strong> is a <strong>large, pre-filled dispenser of freshly brewed coffee</strong>.</li> <li><strong>Getting an ID (Consumption):</strong> A customer orders, and the barista <strong>instantly</strong> dispenses a cup from the machine. The process is immediate, with no waiting.</li> <li><strong>The Background Thread (Production):</strong> A staff member in the back is constantly monitoring the coffee level in the dispenser. When it drops below a certain threshold (e.g., 50%), they <strong>brew a large new batch</strong> and quickly refill the machine.</li> </ul> <p>Through this “front-of-house for sales, back-of-house for preparation” model, the customer (the business logic) experiences lightning-fast service, completely unaware of the “time-consuming” brewing process. This is the secret to <code class="language-plaintext highlighter-rouge">CachedUidGenerator</code> ‘s high performance.</p> </blockquote> <ul> <li><strong>Benefits:</strong></li> <li><strong>Extreme Performance:</strong> The business thread’s action is reduced to a memory access operation with virtually no lock contention, resulting in massive throughput.</li> <li><strong>Eliminates Jitter:</strong> It smooths out the performance “hiccups” that can occur at time boundaries (e.g., the start of a new second) in other implementations.</li> <li>It also employs advanced techniques like <strong>Cache-Line Padding</strong> to avoid “False Sharing” on multi-core CPUs, demonstrating a commitment to squeezing out every last drop of performance.</li> </ul> <h4 id="414-the-unresolved-challenge-clock-skew">4.1.4. The Unresolved Challenge: Clock Skew</h4> <p>On this issue, UidGenerator still adheres to the original <strong>“Fail-Fast”</strong> strategy, throwing an exception upon detecting clock skew.</p> <h4 id="415-uidgenerator-summary">4.1.5. UidGenerator Summary</h4> <table> <thead> <tr> <th style="text-align: left">Pros</th> <th style="text-align: left">Cons</th> </tr> </thead> <tbody> <tr> <td style="text-align: left"><strong>Exceptional Performance:</strong> Cached mode offers lock-free retrieval.</td> <td style="text-align: left"><strong>Shorter ID Lifespan:</strong> ~8.5 years by default, requires planning.</td> </tr> <tr> <td style="text-align: left"><strong>High Usability:</strong> Worker ID allocation depends only on a database.</td> <td style="text-align: left"><strong>Clock Skew Unresolved:</strong> Still uses the fail-fast approach.</td> </tr> <tr> <td style="text-align: left"><strong>Massive Worker ID Space:</strong> 22 bits support over 4 M nodes.</td> <td style="text-align: left"><strong>Potential Worker ID Waste:</strong> Restarts consume new IDs by default.</td> </tr> </tbody> </table> <h3 id="42-meituans-leaf-engineered-for-robustness-and-high-availability">4.2. Meituan’s Leaf: Engineered for Robustness and High Availability</h3> <p>Leaf is Meituan’s open-source ID service, offering two distinct solutions to cater to different needs: <strong><code class="language-plaintext highlighter-rouge">Leaf-segment</code></strong> and <strong><code class="language-plaintext highlighter-rouge">Leaf-snowflake</code></strong>.</p> <h4 id="421-leaf-segment-the-ultimate-optimization-of-segment-mode">4.2.1. Leaf-segment: The Ultimate Optimization of Segment Mode</h4> <p>This solution takes a completely different approach from Snowflake, focusing on optimizing the database-based model.</p> <ul> <li><strong>Core Idea:</strong> <strong>Database Segment Mode.</strong> Instead of fetching one ID at a time, Leaf fetches a large “segment” (or batch) of IDs from the database into memory.</li> <li>For example, it might fetch the range <code class="language-plaintext highlighter-rouge">[1, 1000]</code> in a single database transaction. For the next 1000 requests, Leaf serves IDs from memory by simply incrementing a counter, with zero database interaction.</li> <li><strong>Dual Buffer Mechanism:</strong></li> <li><strong>Pain Point Solved:</strong> In a simple segment model, there’s a performance jitter when one segment is exhausted and the next one needs to be fetched from the database.</li> <li><strong>Leaf’s Solution:</strong> It maintains two buffers. While one buffer is actively serving IDs, an <strong>asynchronous thread</strong> pre-fetches the next segment into the second (standby) buffer once the active buffer’s usage crosses a threshold (e.g., 10%). When the active buffer is depleted, the system <strong>instantly and seamlessly</strong> switches to the standby buffer.</li> </ul> <blockquote> <p><strong>Conceptual Analogy:</strong></p> <p><code class="language-plaintext highlighter-rouge">Leaf-segment</code> is like the <strong>ticketing machine at a bank or hospital</strong>.</p> <ul> <li><strong>Getting an ID</strong> is a customer pressing a button and taking a ticket.</li> <li><strong>A Segment</strong> is an entire <strong>roll of ticket paper</strong> inside the machine (e.g., 1000 tickets).</li> <li><strong>Fetching from DB</strong> is the lobby manager noticing the paper is low and getting a new roll from the storeroom.</li> <li><strong>The Dual Buffer Mechanism</strong> means this is an advanced machine with <strong>two cartridge slots</strong>. While cartridge 1 is in use, the manager is prompted to load a new roll into cartridge 2. When cartridge 1 runs out, the machine instantly switches to cartridge 2, ensuring uninterrupted service.</li> </ul> </blockquote> <ul> <li><strong>High Availability Design:</strong> Leaf recommends setting the segment <code class="language-plaintext highlighter-rouge">step</code> to a multiple of the peak QPS (e.g., enough for 10 minutes). This means that even if the database goes down, Leaf can continue to serve IDs from its in-memory buffers for 10-20 minutes, buying valuable time for database recovery.</li> </ul> <h4 id="422-leaf-snowflake-a-hardened-snowflake">4.2.2. Leaf-snowflake: A Hardened Snowflake</h4> <p>This solution enhances the classic Snowflake algorithm, specifically addressing its two major pain points.</p> <ul> <li><strong>Worker ID Allocation (ZK + Local Cache):</strong></li> <li><strong>Still Uses ZooKeeper:</strong> Leaf acknowledges ZK’s strengths for initial, unique <code class="language-plaintext highlighter-rouge">workerId</code> allocation via persistent sequential nodes.</li> <li><strong>Introduces a Local File Cache:</strong> After obtaining a <code class="language-plaintext highlighter-rouge">workerId</code> from ZK, Leaf <strong>caches it in a local disk file</strong>.</li> <li><strong>High Availability Impact:</strong> On subsequent restarts, Leaf <strong>first reads the local file</strong> to get its <code class="language-plaintext highlighter-rouge">workerId</code>. It only contacts ZK if the file doesn’t exist. This dramatically reduces its dependency on ZK; a service can restart successfully even if the ZK cluster is down.</li> <li><strong>Clock Skew Handling (ZK + Proactive Shutdown):</strong></li> <li>This is Leaf-snowflake’s most significant contribution. It uses ZK as a <strong>“third-party time authority.”</strong></li> <li><strong>Detection:</strong> Each node periodically reports its timestamp to its ZK node. If it detects its local clock is earlier than the last timestamp it reported, it knows a clock skew has occurred.</li> <li><strong>Handling Strategy:</strong> The recommended best practice is <strong>automatic node removal</strong>. * Upon detecting clock skew, the node proactively changes its status to “unavailable” and removes itself from the load balancer’s pool. * Traffic is automatically routed to healthy nodes, ensuring the overall cluster remains available. * Simultaneously, it raises a high-priority alert for operators to investigate the “sick” machine.</li> </ul> <blockquote> <p><strong>Conceptual Analogy:</strong></p> <p><code class="language-plaintext highlighter-rouge">Leaf-snowflake</code> is like a <strong>highly responsible, experienced chain store manager</strong>.</p> <ul> <li><strong>Worker ID Allocation:</strong> <blockquote> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>*   When opening a new store, the manager calls headquarters (ZooKeeper) to get a permanent **store ID**.
</code></pre></div> </div> </blockquote> <ul> <li>He immediately makes a copy of the ID and <strong>locks it in the store’s safe</strong> (local file cache).</li> <li>For all future re-openings (restarts), he checks the safe first and <strong>doesn’t need to call headquarters</strong>, ensuring he can open even if HQ’s phone lines are down.</li> </ul> </li> <li><strong>Clock Skew Handling:</strong> <blockquote> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>*   The manager notices the clock on his wall is wrong (clock skew).
</code></pre></div> </div> </blockquote> <ul> <li>Instead of shutting down chaotically (throwing an exception), he quietly flips the “Open” sign to “Under Maintenance” and <strong>proactively informs</strong> the central delivery platform (load balancer): “Stop sending me orders for now; I have an equipment issue.”</li> <li>Customer orders are automatically routed to other stores, and the <strong>brand’s overall service is unaffected</strong>. Meanwhile, he has already sent a maintenance request to headquarters. This is a model of professional fault handling.</li> </ul> </li> </ul> </blockquote> <h4 id="423-leaf-summary">4.2.3. Leaf Summary</h4> <p>Leaf provides two excellent, distinct solutions:</p> <ul> <li><strong>Leaf-segment:</strong> Ideal for scenarios requiring <strong>strictly ordered, purely numeric</strong> IDs. It offers exceptional performance and availability.</li> <li><strong>Leaf-snowflake:</strong> A <strong>hardened version of Snowflake</strong>. It masterfully solves the critical issues of ZK dependency and clock skew, offering extreme robustness.</li> </ul> <h3 id="43-the-mist-algorithm-a-timestamp-less-approach">4.3. The Mist Algorithm: A Timestamp-less Approach</h3> <p>This algorithm takes a radical approach, positing that the dependency on time is the root of all evil. Therefore, it <strong>eliminates the timestamp entirely</strong>.</p> <ul> <li><strong>Core Design:</strong> <strong>Complete decoupling from time.</strong></li> <li><strong>Advantage:</strong> <strong>Completely immune to clock skew.</strong> Server time fluctuations have no impact on ID generation, making the system incredibly robust.</li> <li><strong>Trade-off:</strong> It must rely on an <strong>external, centralized service (like Redis)</strong> to provide a globally unique, incrementing sequence.</li> <li><strong>ID Structure (1-47-8-8):</strong></li> <li><code class="language-plaintext highlighter-rouge">1</code> Sign Bit</li> <li><code class="language-plaintext highlighter-rouge">47</code> bits for an incrementing number (from Redis <code class="language-plaintext highlighter-rouge">INCR</code>). This guarantees strict ordering and a very long lifespan.</li> <li><code class="language-plaintext highlighter-rouge">16</code> bits for random factors. This makes the final ID <strong>unpredictable</strong>, protecting business data (like order volume) from being easily estimated.</li> </ul> <blockquote> <p><strong>Conceptual Analogy:</strong></p> <p>The <strong>Mist Algorithm</strong> is like a <strong>central bank issuing currency</strong>.</p> <ul> <li><strong>The ID</strong> is a unique banknote.</li> <li><strong>The centralized Redis</strong> is the <strong>one and only national mint</strong>. All ID generation instances must request “batch numbers” from it.</li> <li><strong>The 47-bit incrementing number</strong> is the <strong>unique, strictly increasing serial number</strong> on each banknote.</li> <li><strong>The 16-bit random factor</strong> represents the banknote’s <strong>security features, like watermarks and security threads</strong>. It makes two consecutive serial numbers look completely different, preventing counterfeiting and analysis.</li> </ul> <p>The advantage of this model is absolute authority, security, and immunity to local “clock” inaccuracies. The disadvantage is that if the mint shuts down, the entire nation’s money supply is halted.</p> </blockquote> <ul> <li><strong>Architectural Trade-off:</strong></li> <li><strong>Introduces a Central Bottleneck:</strong> The system’s overall performance is capped by the QPS and network latency of the central Redis instance.</li> <li><strong>Introduces a Single Point of Failure:</strong> If the Redis cluster fails, the entire ID generation service fails.</li> <li><strong>Use Cases:</strong></li> <li>Scenarios with <strong>zero tolerance for clock skew</strong>.</li> <li>Scenarios requiring <strong>unpredictable IDs</strong> for security (e.g., financial transactions, e-commerce orders).</li> <li>Scenarios where the business QPS is within the limits of a highly available Redis cluster.</li> </ul> <h2 id="5-solution-comparison-and-conclusion">5. Solution Comparison and Conclusion</h2> <table> <thead> <tr> <th style="text-align: left">Scheme</th> <th style="text-align: left">ID Trend</th> <th style="text-align: left">Performance</th> <th style="text-align: left">Core Dependency</th> <th style="text-align: left">WorkerID Allocation</th> <th style="text-align: left">Clock Skew Handling</th> <th style="text-align: left">Key Advantage</th> <th style="text-align: left">Core Drawback</th> </tr> </thead> <tbody> <tr> <td style="text-align: left"><strong>UUID</strong></td> <td style="text-align: left">Unordered</td> <td style="text-align: left">Extreme (Local)</td> <td style="text-align: left">None</td> <td style="text-align: left">N/A</td> <td style="text-align: left">Irrelevant</td> <td style="text-align: left">Simplicity, no network cost</td> <td style="text-align: left">String, unordered, poor index perf</td> </tr> <tr> <td style="text-align: left"><strong>DB Auto-Inc</strong></td> <td style="text-align: left">Strictly Inc</td> <td style="text-align: left">Low</td> <td style="text-align: left">Database</td> <td style="text-align: left">N/A</td> <td style="text-align: left">Irrelevant</td> <td style="text-align: left">Simplicity, ordered IDs</td> <td style="text-align: left">DB dependency, poor scalability</td> </tr> <tr> <td style="text-align: left"><strong>Redis Inc</strong></td> <td style="text-align: left">Strictly Inc</td> <td style="text-align: left">High</td> <td style="text-align: left">Redis</td> <td style="text-align: left">N/A</td> <td style="text-align: left">Irrelevant</td> <td style="text-align: left">Good performance, ordered IDs</td> <td style="text-align: left">Redis dependency, network cost</td> </tr> <tr> <td style="text-align: left"><strong>Snowflake</strong></td> <td style="text-align: left">Time-ordered</td> <td style="text-align: left">Extreme (Local)</td> <td style="text-align: left">ZooKeeper</td> <td style="text-align: left">ZK Ephemeral Node</td> <td style="text-align: left"><strong>Throws Exception</strong></td> <td style="text-align: left">Balanced performance, embedded info</td> <td style="text-align: left">Strong clock dependency, ZK complexity</td> </tr> <tr> <td style="text-align: left"><strong>UidGenerator</strong></td> <td style="text-align: left">Time-ordered</td> <td style="text-align: left">Ultimate (Local)</td> <td style="text-align: left">Database</td> <td style="text-align: left">DB Auto-Inc ID</td> <td style="text-align: left"><strong>Throws Exception</strong></td> <td style="text-align: left">Extreme performance, massive WorkerID space</td> <td style="text-align: left">Short lifespan (~8.5 yrs), clock skew unresolved</td> </tr> <tr> <td style="text-align: left"><strong>Leaf-segment</strong></td> <td style="text-align: left">Strictly Inc</td> <td style="text-align: left">Extreme (Mem)</td> <td style="text-align: left">Database</td> <td style="text-align: left">N/A</td> <td style="text-align: left">Irrelevant</td> <td style="text-align: left">Smooth perf, HA, sequential IDs</td> <td style="text-align: left">Predictable IDs, DB dependency</td> </tr> <tr> <td style="text-align: left"><strong>Leaf-snowflake</strong></td> <td style="text-align: left">Time-ordered</td> <td style="text-align: left">Extreme (Local)</td> <td style="text-align: left">ZooKeeper</td> <td style="text-align: left">ZK + Local Cache</td> <td style="text-align: left"><strong>Proactive Shutdown</strong></td> <td style="text-align: left"><strong>Extreme Robustness</strong>, solves clock skew</td> <td style="text-align: left">ZK dependency, slightly complex</td> </tr> <tr> <td style="text-align: left"><strong>Mist</strong></td> <td style="text-align: left">Strictly Inc</td> <td style="text-align: left">High (Limited)</td> <td style="text-align: left">Redis</td> <td style="text-align: left">N/A</td> <td style="text-align: left"><strong>Immune</strong></td> <td style="text-align: left"><strong>Clock immune, unpredictable IDs</strong></td> <td style="text-align: left">Centralized dependency &amp; bottleneck</td> </tr> </tbody> </table> <p><strong>Conclusion:</strong></p> <p>There is no “best” distributed ID solution, only the one that is “most suitable” for your specific context.</p> <ul> <li>For <strong>simplicity and rapid integration</strong> where ID order is not critical, <strong>UUID</strong> is an option.</li> <li>For a <strong>high-performance, time-ordered, and information-rich ID</strong>, <strong>Snowflake</strong> is the classic benchmark.</li> <li>To build on that with a focus on <strong>extreme ease-of-use and massive node support</strong> (while accepting a limited lifespan), <strong>Baidu’s UidGenerator</strong> is an excellent choice.</li> <li>For systems with the <strong>highest requirements for robustness and availability</strong>, especially for gracefully handling clock skew, <strong>Meituan’s Leaf-snowflake</strong> is arguably the most complete solution in the industry.</li> <li>If your business requires <strong>strictly sequential, purely numeric IDs</strong>, <strong>Meituan’s Leaf-segment</strong> offers unparalleled performance and smoothness.</li> <li>Finally, if <strong>clock safety and ID unpredictability</strong> are paramount, and you can accept the architectural cost of centralization, the <strong>Mist algorithm</strong> provides a novel and effective alternative.</li> </ul> <p>When making a selection, always consider your application’s QPS, requirements for ID format and order, your team’s operational capabilities, and the specific trade-offs you are willing to make between availability and data consistency.</p>]]></content><author><name></name></author><category term="System Design Other"/><summary type="html"><![CDATA[1. The Need for Distributed, Globally Unique IDs]]></summary></entry><entry><title type="html">Algorithm of Rate Limiter</title><link href="https://zhengstar94.github.io//blog/2025/AlgorithmOfRateLimiter/" rel="alternate" type="text/html" title="Algorithm of Rate Limiter"/><published>2025-07-01T00:00:00+00:00</published><updated>2025-07-01T00:00:00+00:00</updated><id>https://zhengstar94.github.io//blog/2025/AlgorithmOfRateLimiter</id><content type="html" xml:base="https://zhengstar94.github.io//blog/2025/AlgorithmOfRateLimiter/"><![CDATA[<h2 id="introduction-to-rate-limiting">Introduction to Rate Limiting</h2> <p>Rate limiting is a mechanism to control the rate of incoming requests to a system, preventing overload and ensuring stability. It acts as a traffic regulator for servers, with the primary objectives of:</p> <ul> <li><strong>System Protection</strong>: Mitigating the impact of traffic spikes, such as during e-commerce flash sales.</li> <li><strong>Abuse Prevention</strong>: Blocking malicious requests, such as crawlers or denial-of-service attacks.</li> <li><strong>Cost Management</strong>: Regulating usage of pay-per-request resources, such as cloud APIs.</li> </ul> <p>This document details five prevalent rate-limiting algorithms, providing accessible explanations, technical analyses of advantages and disadvantages, applicable scenarios, Java implementations with comprehensive comments, and Mermaid diagrams to aid understanding.</p> <h2 id="overview-of-rate-limiting-algorithms">Overview of Rate-Limiting Algorithms</h2> <p>The following table compares five rate-limiting algorithms based on their advantages, disadvantages, use cases, and computational complexity:</p> <table> <thead> <tr> <th>Algorithm</th> <th>Advantages</th> <th>Disadvantages</th> <th>Use Cases</th> <th>Complexity</th> </tr> </thead> <tbody> <tr> <td>Token Bucket</td> <td>✅ Simple Implementation <br/>✅ Supports Bursty Traffic</td> <td>❌ Complex Parameter Tuning <br/>❌ Risk of Short-Term Overload</td> <td>E-commerce flash sales (e.g., Alibaba Double 11), API requests (e.g., X post limits)</td> <td>O(1) Time <br/>O(1) Space</td> </tr> <tr> <td>Leaky Bucket</td> <td>✅ Stable Output <br/>✅ Memory Efficient</td> <td>❌ No Support for Bursty Traffic <br/>❌ Increased Request Latency</td> <td>E-commerce APIs (e.g., Shopify order requests), stable traffic services</td> <td>O(1) Time <br/>O(n) Space</td> </tr> <tr> <td>Fixed Window Counter</td> <td>✅ Simple Implementation <br/>✅ Memory Efficient</td> <td>❌ Window Boundary Overload</td> <td>Simple rate limiting (e.g., 5 login attempts per minute), quota reset scenarios</td> <td>O(1) Time <br/>O(1) Space</td> </tr> <tr> <td>Sliding Window Log</td> <td>✅ High Precision <br/>✅ No Boundary Issues</td> <td>❌ High Memory Usage <br/>❌ Complex Implementation</td> <td>Financial transactions (e.g., stock trading), ad bidding, high-frequency trading</td> <td>O(n) Time <br/>O(n) Space</td> </tr> <tr> <td>Sliding Window Counter</td> <td>✅ Memory Efficient <br/>✅ Smooths Traffic Peaks</td> <td>❌ Limited Precision</td> <td>E-commerce promotions (e.g., JD 618), social media surges (e.g., TikTok trending events)</td> <td>O(1) Time <br/>O(n) Space</td> </tr> </tbody> </table> <blockquote> <p><strong>Note</strong>: Complexity <code class="language-plaintext highlighter-rouge">n</code> refers to the number of requests or timestamps.</p> </blockquote> <h2 id="detailed-analysis-and-java-implementations">Detailed Analysis and Java Implementations</h2> <h3 id="1-token-bucket">1. Token Bucket</h3> <p><strong>Accessible Explanation</strong>:<br/> The token bucket is akin to a ticket dispenser that issues tickets (tokens) at a fixed rate. Each request requires a token to proceed; if none are available, the request is denied. Tokens can accumulate in the bucket, enabling the system to handle bursts of requests, much like a theater allowing a surge of ticketed patrons during a premiere.</p> <p><strong>Principle</strong>: The bucket replenishes tokens at a constant rate. Requests consume tokens, and if insufficient tokens are available, requests are rejected. This supports bursty traffic.</p> <p><strong>Mermaid Diagram</strong>:</p> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2025/07/1-480.webp 480w,/assets/img/2025/07/1-800.webp 800w,/assets/img/2025/07/1-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/2025/07/1.png" class="img-fluid rounded z-depth-1" width="50%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <p><strong>Advantages</strong>:</p> <ul> <li><strong>Simple Implementation</strong>: Straightforward logic and coding, addressing the challenge of complex rate-limiting designs.</li> <li><strong>Supports Bursty Traffic</strong>: Accumulated tokens allow handling short-term traffic spikes, ideal for scenarios like flash sales.</li> </ul> <p><strong>Disadvantages</strong>:</p> <ul> <li><strong>Complex Parameter Tuning</strong>: The token generation rate and bucket capacity require precise adjustment based on traffic patterns. Incorrect settings may lead to excessive request denials (if the rate is too low) or system overload (if capacity is too high). For example, an improperly tuned bucket in a flash sale may reject legitimate users or overwhelm servers.</li> <li><strong>Risk of Short-Term Overload</strong>: A burst consuming all tokens may allow subsequent requests to pass briefly, causing momentary traffic spikes beyond the intended rate. For instance, a target of 100 requests/sec might see 120 requests in a second during a burst.</li> </ul> <p><strong>Use Cases</strong>:</p> <ul> <li><strong>E-commerce Flash Sales</strong>: Limiting 1000 purchase requests per second during Alibaba’s Double 11.</li> <li><strong>API Requests</strong>: Restricting 100 post submissions per minute on X.</li> <li><strong>AI APIs</strong>: Capping 10 model invocations per second for OpenAI.</li> </ul> <p><strong>Java Implementation</strong>:</p> <div class="language-java highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kd">public</span> <span class="kd">class</span> <span class="nc">TokenBucket</span> <span class="o">{</span>
    <span class="kd">private</span> <span class="kd">final</span> <span class="kt">long</span> <span class="n">capacity</span><span class="o">;</span> <span class="c1">// Maximum number of tokens the bucket can hold</span>
    <span class="kd">private</span> <span class="kd">final</span> <span class="kt">double</span> <span class="n">rate</span><span class="o">;</span> <span class="c1">// Token generation rate (tokens per second)</span>
    <span class="kd">private</span> <span class="kt">double</span> <span class="n">tokens</span><span class="o">;</span> <span class="c1">// Current number of available tokens</span>
    <span class="kd">private</span> <span class="kt">long</span> <span class="n">lastRefillTimestamp</span><span class="o">;</span> <span class="c1">// Timestamp of last token refill</span>

    <span class="c1">// Initialize bucket with capacity and rate, starting with full tokens</span>
    <span class="kd">public</span> <span class="nf">TokenBucket</span><span class="o">(</span><span class="kt">long</span> <span class="n">capacity</span><span class="o">,</span> <span class="kt">double</span> <span class="n">rate</span><span class="o">)</span> <span class="o">{</span>
        <span class="k">this</span><span class="o">.</span><span class="na">capacity</span> <span class="o">=</span> <span class="n">capacity</span><span class="o">;</span>
        <span class="k">this</span><span class="o">.</span><span class="na">rate</span> <span class="o">=</span> <span class="n">rate</span><span class="o">;</span>
        <span class="k">this</span><span class="o">.</span><span class="na">tokens</span> <span class="o">=</span> <span class="n">capacity</span><span class="o">;</span>
        <span class="k">this</span><span class="o">.</span><span class="na">lastRefillTimestamp</span> <span class="o">=</span> <span class="nc">System</span><span class="o">.</span><span class="na">nanoTime</span><span class="o">();</span>
    <span class="o">}</span>

    <span class="c1">// Check if request is allowed, thread-safe</span>
    <span class="kd">public</span> <span class="kd">synchronized</span> <span class="kt">boolean</span> <span class="nf">allowRequest</span><span class="o">()</span> <span class="o">{</span>
        <span class="n">refill</span><span class="o">();</span> <span class="c1">// Replenish tokens based on elapsed time</span>
        <span class="k">if</span> <span class="o">(</span><span class="n">tokens</span> <span class="o">&gt;=</span> <span class="mi">1</span><span class="o">)</span> <span class="o">{</span> <span class="c1">// Sufficient tokens available</span>
            <span class="n">tokens</span> <span class="o">-=</span> <span class="mi">1</span><span class="o">;</span> <span class="c1">// Consume one token</span>
            <span class="k">return</span> <span class="kc">true</span><span class="o">;</span> <span class="c1">// Allow request</span>
        <span class="o">}</span>
        <span class="k">return</span> <span class="kc">false</span><span class="o">;</span> <span class="c1">// No tokens, deny request</span>
    <span class="o">}</span>

    <span class="c1">// Replenish tokens based on elapsed time</span>
    <span class="kd">private</span> <span class="kt">void</span> <span class="nf">refill</span><span class="o">()</span> <span class="o">{</span>
        <span class="kt">long</span> <span class="n">now</span> <span class="o">=</span> <span class="nc">System</span><span class="o">.</span><span class="na">nanoTime</span><span class="o">();</span>
        <span class="kt">double</span> <span class="n">elapsedSeconds</span> <span class="o">=</span> <span class="o">(</span><span class="n">now</span> <span class="o">-</span> <span class="n">lastRefillTimestamp</span><span class="o">)</span> <span class="o">/</span> <span class="mi">1</span><span class="n">e9</span><span class="o">;</span> <span class="c1">// Time elapsed in seconds</span>
        <span class="n">tokens</span> <span class="o">=</span> <span class="nc">Math</span><span class="o">.</span><span class="na">min</span><span class="o">(</span><span class="n">capacity</span><span class="o">,</span> <span class="n">tokens</span> <span class="o">+</span> <span class="n">elapsedSeconds</span> <span class="o">*</span> <span class="n">rate</span><span class="o">);</span> <span class="c1">// Add tokens, capped at capacity</span>
        <span class="n">lastRefillTimestamp</span> <span class="o">=</span> <span class="n">now</span><span class="o">;</span> <span class="c1">// Update refill timestamp</span>
    <span class="o">}</span>
<span class="o">}</span>
</code></pre></div></div> <p><strong>Usage Example</strong>:</p> <div class="language-java highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nc">TokenBucket</span> <span class="n">bucket</span> <span class="o">=</span> <span class="k">new</span> <span class="nc">TokenBucket</span><span class="o">(</span><span class="mi">100</span><span class="o">,</span> <span class="mi">10</span><span class="o">);</span> <span class="c1">// Capacity 100, 10 tokens/sec</span>
<span class="k">for</span> <span class="o">(</span><span class="kt">int</span> <span class="n">i</span> <span class="o">=</span> <span class="mi">0</span><span class="o">;</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="mi">150</span><span class="o">;</span> <span class="n">i</span><span class="o">++)</span> <span class="o">{</span>
    <span class="k">if</span> <span class="o">(</span><span class="n">bucket</span><span class="o">.</span><span class="na">allowRequest</span><span class="o">())</span> <span class="o">{</span>
        <span class="nc">System</span><span class="o">.</span><span class="na">out</span><span class="o">.</span><span class="na">println</span><span class="o">(</span><span class="s">"Request "</span> <span class="o">+</span> <span class="n">i</span> <span class="o">+</span> <span class="s">" allowed"</span><span class="o">);</span>
    <span class="o">}</span> <span class="k">else</span> <span class="o">{</span>
        <span class="nc">System</span><span class="o">.</span><span class="na">out</span><span class="o">.</span><span class="na">println</span><span class="o">(</span><span class="s">"Request "</span> <span class="o">+</span> <span class="n">i</span> <span class="o">+</span> <span class="s">" rejected"</span><span class="o">);</span>
    <span class="o">}</span>
<span class="o">}</span>
</code></pre></div></div> <p><strong>Parameter Tuning</strong>:</p> <ul> <li><strong>Rate</strong>: Set to the average request rate (e.g., 10 requests/sec).</li> <li><strong>Capacity</strong>: Set to the maximum burst size (e.g., 100 requests).</li> </ul> <h3 id="2-leaky-bucket">2. Leaky Bucket</h3> <p><strong>Accessible Explanation</strong>:<br/> The leaky bucket resembles a container with a fixed-size hole at the bottom. Requests flow into the bucket like water, but they can only exit (be processed) at a constant rate through the hole. If requests arrive too quickly, the bucket fills, and new requests are discarded, ensuring a steady processing rate.</p> <p><strong>Principle</strong>: Requests enter the bucket and are processed at a fixed rate. If the bucket is full, new requests are rejected. This is ideal for stable traffic scenarios.</p> <p><strong>Mermaid Diagram</strong>:</p> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2025/07/2-480.webp 480w,/assets/img/2025/07/2-800.webp 800w,/assets/img/2025/07/2-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/2025/07/2.png" class="img-fluid rounded z-depth-1" width="50%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <p><strong>Advantages</strong>:</p> <ul> <li><strong>Stable Output</strong>: Processes requests at a consistent rate, protecting downstream systems from traffic surges.</li> <li><strong>Memory Efficient</strong>: Requires only a queue to store requests, minimizing memory usage.</li> </ul> <p><strong>Disadvantages</strong>:</p> <ul> <li><strong>No Support for Bursty Traffic</strong>: The fixed outflow rate cannot accommodate sudden traffic spikes, leading to request rejections. For example, during a flash sale, high-concurrency requests may be denied, degrading user experience.</li> <li><strong>Increased Request Latency</strong>: Sustained high request rates cause requests to queue in the bucket, increasing processing delays. For instance, API requests may experience response times escalating from seconds to minutes due to queuing.</li> </ul> <p><strong>Use Cases</strong>:</p> <ul> <li><strong>E-commerce APIs</strong>: Limiting 50 order requests per second for Shopify.</li> <li><strong>Message Queues</strong>: Ensuring consistent message processing rates.</li> </ul> <p><strong>Java Implementation</strong>:</p> <div class="language-java highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">java.util.LinkedList</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">java.util.Queue</span><span class="o">;</span>

<span class="kd">public</span> <span class="kd">class</span> <span class="nc">LeakyBucket</span> <span class="o">{</span>
    <span class="kd">private</span> <span class="kd">final</span> <span class="kt">long</span> <span class="n">capacity</span><span class="o">;</span> <span class="c1">// Maximum number of requests the bucket can hold</span>
    <span class="kd">private</span> <span class="kd">final</span> <span class="kt">double</span> <span class="n">rate</span><span class="o">;</span> <span class="c1">// Outflow rate (requests processed per second)</span>
    <span class="kd">private</span> <span class="kd">final</span> <span class="nc">Queue</span><span class="o">&lt;</span><span class="nc">Long</span><span class="o">&gt;</span> <span class="n">queue</span><span class="o">;</span> <span class="c1">// Stores request arrival timestamps</span>
    <span class="kd">private</span> <span class="kt">long</span> <span class="n">lastLeakTimestamp</span><span class="o">;</span> <span class="c1">// Timestamp of last outflow</span>

    <span class="c1">// Initialize bucket with capacity and outflow rate</span>
    <span class="kd">public</span> <span class="nf">LeakyBucket</span><span class="o">(</span><span class="kt">long</span> <span class="n">capacity</span><span class="o">,</span> <span class="kt">double</span> <span class="n">rate</span><span class="o">)</span> <span class="o">{</span>
        <span class="k">this</span><span class="o">.</span><span class="na">capacity</span> <span class="o">=</span> <span class="n">capacity</span><span class="o">;</span>
        <span class="k">this</span><span class="o">.</span><span class="na">rate</span> <span class="o">=</span> <span class="n">rate</span><span class="o">;</span>
        <span class="k">this</span><span class="o">.</span><span class="na">queue</span> <span class="o">=</span> <span class="k">new</span> <span class="nc">LinkedList</span><span class="o">&lt;&gt;();</span>
        <span class="k">this</span><span class="o">.</span><span class="na">lastLeakTimestamp</span> <span class="o">=</span> <span class="nc">System</span><span class="o">.</span><span class="na">nanoTime</span><span class="o">();</span>
    <span class="o">}</span>

    <span class="c1">// Check if request is allowed, thread-safe</span>
    <span class="kd">public</span> <span class="kd">synchronized</span> <span class="kt">boolean</span> <span class="nf">allowRequest</span><span class="o">()</span> <span class="o">{</span>
        <span class="n">leak</span><span class="o">();</span> <span class="c1">// Perform outflow to process requests</span>
        <span class="k">if</span> <span class="o">(</span><span class="n">queue</span><span class="o">.</span><span class="na">size</span><span class="o">()</span> <span class="o">&lt;</span> <span class="n">capacity</span><span class="o">)</span> <span class="o">{</span> <span class="c1">// Bucket has space</span>
            <span class="n">queue</span><span class="o">.</span><span class="na">offer</span><span class="o">(</span><span class="nc">System</span><span class="o">.</span><span class="na">nanoTime</span><span class="o">());</span> <span class="c1">// Add request</span>
            <span class="k">return</span> <span class="kc">true</span><span class="o">;</span> <span class="c1">// Allow request</span>
        <span class="o">}</span>
        <span class="k">return</span> <span class="kc">false</span><span class="o">;</span> <span class="c1">// Bucket full, deny request</span>
    <span class="o">}</span>

    <span class="c1">// Process outflow based on elapsed time</span>
    <span class="kd">private</span> <span class="kt">void</span> <span class="nf">leak</span><span class="o">()</span> <span class="o">{</span>
        <span class="kt">long</span> <span class="n">now</span> <span class="o">=</span> <span class="nc">System</span><span class="o">.</span><span class="na">nanoTime</span><span class="o">();</span>
        <span class="kt">double</span> <span class="n">elapsedSeconds</span> <span class="o">=</span> <span class="o">(</span><span class="n">now</span> <span class="o">-</span> <span class="n">lastLeakTimestamp</span><span class="o">)</span> <span class="o">/</span> <span class="mi">1</span><span class="n">e9</span><span class="o">;</span> <span class="c1">// Time elapsed in seconds</span>
        <span class="kt">int</span> <span class="n">leaked</span> <span class="o">=</span> <span class="o">(</span><span class="kt">int</span><span class="o">)</span> <span class="o">(</span><span class="n">elapsedSeconds</span> <span class="o">*</span> <span class="n">rate</span><span class="o">);</span> <span class="c1">// Number of requests that can outflow</span>
        <span class="k">while</span> <span class="o">(</span><span class="n">leaked</span> <span class="o">&gt;</span> <span class="mi">0</span> <span class="o">&amp;&amp;</span> <span class="o">!</span><span class="n">queue</span><span class="o">.</span><span class="na">isEmpty</span><span class="o">())</span> <span class="o">{</span> <span class="c1">// Remove processed requests</span>
            <span class="n">queue</span><span class="o">.</span><span class="na">poll</span><span class="o">();</span>
            <span class="n">leaked</span><span class="o">--;</span>
        <span class="o">}</span>
        <span class="n">lastLeakTimestamp</span> <span class="o">=</span> <span class="n">now</span><span class="o">;</span> <span class="c1">// Update outflow timestamp</span>
    <span class="o">}</span>
<span class="o">}</span>
</code></pre></div></div> <p><strong>Usage Example</strong>:</p> <div class="language-java highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nc">LeakyBucket</span> <span class="n">bucket</span> <span class="o">=</span> <span class="k">new</span> <span class="nc">LeakyBucket</span><span class="o">(</span><span class="mi">50</span><span class="o">,</span> <span class="mi">5</span><span class="o">);</span> <span class="c1">// Capacity 50, 5 requests/sec</span>
<span class="k">for</span> <span class="o">(</span><span class="kt">int</span> <span class="n">i</span> <span class="o">=</span> <span class="mi">0</span><span class="o">;</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="mi">100</span><span class="o">;</span> <span class="n">i</span><span class="o">++)</span> <span class="o">{</span>
    <span class="k">if</span> <span class="o">(</span><span class="n">bucket</span><span class="o">.</span><span class="na">allowRequest</span><span class="o">())</span> <span class="o">{</span>
        <span class="nc">System</span><span class="o">.</span><span class="na">out</span><span class="o">.</span><span class="na">println</span><span class="o">(</span><span class="s">"Request "</span> <span class="o">+</span> <span class="n">i</span> <span class="o">+</span> <span class="s">" allowed"</span><span class="o">);</span>
    <span class="o">}</span> <span class="k">else</span> <span class="o">{</span>
        <span class="nc">System</span><span class="o">.</span><span class="na">out</span><span class="o">.</span><span class="na">println</span><span class="o">(</span><span class="s">"Request "</span> <span class="o">+</span> <span class="n">i</span> <span class="o">+</span> <span class="s">" rejected"</span><span class="o">);</span>
    <span class="o">}</span>
<span class="o">}</span>
</code></pre></div></div> <p><strong>Parameter Tuning</strong>:</p> <ul> <li><strong>Rate</strong>: Match the downstream processing capability (e.g., 5 requests/sec).</li> <li><strong>Capacity</strong>: Set based on acceptable latency (e.g., 50 requests).</li> </ul> <h3 id="3-fixed-window-counter">3. Fixed Window Counter</h3> <p><strong>Accessible Explanation</strong>:<br/> The fixed window counter is like a venue with a limited number of entry passes per hour. Once the passes are exhausted, new entrants must wait for the next hour. Its simplicity is effective, but pass distribution can cluster at window boundaries, causing short-term overloads.</p> <p><strong>Principle</strong>: Counts requests within a fixed time window, rejecting those exceeding the quota. The counter resets at the end of each window.</p> <p><strong>Mermaid Diagram</strong>:</p> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2025/07/3-480.webp 480w,/assets/img/2025/07/3-800.webp 800w,/assets/img/2025/07/3-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/2025/07/3.png" class="img-fluid rounded z-depth-1" width="50%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <p><strong>Advantages</strong>:</p> <ul> <li><strong>Simple Implementation</strong>: Requires only counting and comparison, enabling rapid development for basic rate limiting.</li> <li><strong>Memory Efficient</strong>: Stores a single counter, minimizing memory requirements.</li> </ul> <p><strong>Disadvantages</strong>:</p> <ul> <li><strong>Window Boundary Overload</strong>: At window transitions (e.g., 59s to 61s), requests may cluster, doubling the intended rate momentarily. For example, a limit of 100 requests per minute could see 99 requests at 59s and 99 at 61s, resulting in 198 requests in 2 seconds, overwhelming the system.</li> </ul> <p><strong>Use Cases</strong>:</p> <ul> <li><strong>Login Restrictions</strong>: Limiting 5 login attempts per minute.</li> <li><strong>Simple APIs</strong>: Restricting 1000 calls per hour for small-scale services.</li> </ul> <p><strong>Java Implementation</strong>:</p> <div class="language-java highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kd">public</span> <span class="kd">class</span> <span class="nc">FixedWindowCounter</span> <span class="o">{</span>
    <span class="kd">private</span> <span class="kd">final</span> <span class="kt">long</span> <span class="n">windowSize</span><span class="o">;</span> <span class="c1">// Window size in milliseconds</span>
    <span class="kd">private</span> <span class="kd">final</span> <span class="kt">long</span> <span class="n">limit</span><span class="o">;</span> <span class="c1">// Maximum requests allowed in window</span>
    <span class="kd">private</span> <span class="kt">long</span> <span class="n">windowStart</span><span class="o">;</span> <span class="c1">// Start time of current window</span>
    <span class="kd">private</span> <span class="kt">long</span> <span class="n">count</span><span class="o">;</span> <span class="c1">// Current request count in window</span>

    <span class="c1">// Initialize window with size and limit</span>
    <span class="kd">public</span> <span class="nf">FixedWindowCounter</span><span class="o">(</span><span class="kt">long</span> <span class="n">windowSizeSeconds</span><span class="o">,</span> <span class="kt">long</span> <span class="n">limit</span><span class="o">)</span> <span class="o">{</span>
        <span class="k">this</span><span class="o">.</span><span class="na">windowSize</span> <span class="o">=</span> <span class="n">windowSizeSeconds</span> <span class="o">*</span> <span class="mi">1000</span><span class="o">;</span>
        <span class="k">this</span><span class="o">.</span><span class="na">limit</span> <span class="o">=</span> <span class="n">limit</span><span class="o">;</span>
        <span class="k">this</span><span class="o">.</span><span class="na">windowStart</span> <span class="o">=</span> <span class="nc">System</span><span class="o">.</span><span class="na">currentTimeMillis</span><span class="o">();</span>
        <span class="k">this</span><span class="o">.</span><span class="na">count</span> <span class="o">=</span> <span class="mi">0</span><span class="o">;</span>
    <span class="o">}</span>

    <span class="c1">// Check if request is allowed, thread-safe</span>
    <span class="kd">public</span> <span class="kd">synchronized</span> <span class="kt">boolean</span> <span class="nf">allowRequest</span><span class="o">()</span> <span class="o">{</span>
        <span class="kt">long</span> <span class="n">now</span> <span class="o">=</span> <span class="nc">System</span><span class="o">.</span><span class="na">currentTimeMillis</span><span class="o">();</span>
        <span class="k">if</span> <span class="o">(</span><span class="n">now</span> <span class="o">&gt;</span> <span class="n">windowStart</span> <span class="o">+</span> <span class="n">windowSize</span><span class="o">)</span> <span class="o">{</span> <span class="c1">// Window has expired</span>
            <span class="n">windowStart</span> <span class="o">=</span> <span class="n">now</span><span class="o">;</span> <span class="c1">// Reset window</span>
            <span class="n">count</span> <span class="o">=</span> <span class="mi">0</span><span class="o">;</span> <span class="c1">// Reset counter</span>
        <span class="o">}</span>
        <span class="k">if</span> <span class="o">(</span><span class="n">count</span> <span class="o">&lt;</span> <span class="n">limit</span><span class="o">)</span> <span class="o">{</span> <span class="c1">// Within limit</span>
            <span class="n">count</span><span class="o">++;</span> <span class="c1">// Increment counter</span>
            <span class="k">return</span> <span class="kc">true</span><span class="o">;</span> <span class="c1">// Allow request</span>
        <span class="o">}</span>
        <span class="k">return</span> <span class="kc">false</span><span class="o">;</span> <span class="c1">// Exceeds limit, deny request</span>
    <span class="o">}</span>
<span class="o">}</span>
</code></pre></div></div> <p><strong>Usage Example</strong>:</p> <div class="language-java highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nc">FixedWindowCounter</span> <span class="n">counter</span> <span class="o">=</span> <span class="k">new</span> <span class="nc">FixedWindowCounter</span><span class="o">(</span><span class="mi">60</span><span class="o">,</span> <span class="mi">5</span><span class="o">);</span> <span class="c1">// 60 seconds, 5 requests</span>
<span class="k">for</span> <span class="o">(</span><span class="kt">int</span> <span class="n">i</span> <span class="o">=</span> <span class="mi">0</span><span class="o">;</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="mi">10</span><span class="o">;</span> <span class="n">i</span><span class="o">++)</span> <span class="o">{</span>
    <span class="k">if</span> <span class="o">(</span><span class="n">counter</span><span class="o">.</span><span class="na">allowRequest</span><span class="o">())</span> <span class="o">{</span>
        <span class="nc">System</span><span class="o">.</span><span class="na">out</span><span class="o">.</span><span class="na">println</span><span class="o">(</span><span class="s">"Request "</span> <span class="o">+</span> <span class="n">i</span> <span class="o">+</span> <span class="s">" allowed"</span><span class="o">);</span>
    <span class="o">}</span> <span class="k">else</span> <span class="o">{</span>
        <span class="nc">System</span><span class="o">.</span><span class="na">out</span><span class="o">.</span><span class="na">println</span><span class="o">(</span><span class="s">"Request "</span> <span class="o">+</span> <span class="n">i</span> <span class="o">+</span> <span class="s">" rejected"</span><span class="o">);</span>
    <span class="o">}</span>
<span class="o">}</span>
</code></pre></div></div> <p><strong>Parameter Tuning</strong>:</p> <ul> <li><strong>Window Size</strong>: Smaller windows (e.g., 10 seconds) reduce boundary issues.</li> <li><strong>Limit</strong>: Set based on business requirements (e.g., 5 requests/minute).</li> </ul> <h3 id="4-sliding-window-log">4. Sliding Window Log</h3> <p><strong>Accessible Explanation</strong>:<br/> The sliding window log is like a meticulous registrar, recording the exact timestamp of each request. When a new request arrives, it checks the number of requests within the recent time window, denying those exceeding the limit. Its precision is unparalleled, but it demands significant record-keeping.</p> <p><strong>Principle</strong>: Records timestamps of requests and checks the count within a sliding time window, offering high precision.</p> <p><strong>Mermaid Diagram</strong>:</p> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2025/07/4-480.webp 480w,/assets/img/2025/07/4-800.webp 800w,/assets/img/2025/07/4-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/2025/07/4.png" class="img-fluid rounded z-depth-1" width="50%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <p><strong>Advantages</strong>:</p> <ul> <li><strong>High Precision</strong>: Tracks exact request times, ideal for strict rate-limiting scenarios like financial transactions.</li> <li><strong>No Boundary Issues</strong>: Smooth sliding window avoids fixed window boundary overloads.</li> </ul> <p><strong>Disadvantages</strong>:</p> <ul> <li><strong>High Memory Usage</strong>: Each request’s timestamp is stored, leading to substantial memory consumption in high-concurrency scenarios. For example, 1000 requests per second in a 1-second window require storing 1000 timestamps.</li> <li><strong>Complex Implementation</strong>: Managing a timestamp queue and removing expired entries increases code complexity and performance overhead. For instance, frequent cleanup in high-traffic scenarios may degrade system performance.</li> </ul> <p><strong>Use Cases</strong>:</p> <ul> <li><strong>Financial Transactions</strong>: Limiting 1000 trading requests per second in stock exchanges.</li> <li><strong>Ad Bidding</strong>: Restricting 500 bids per second in real-time bidding platforms.</li> <li><strong>Web3</strong>: Controlling blockchain transaction rates.</li> </ul> <p><strong>Java Implementation</strong>:</p> <div class="language-java highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">java.util.LinkedList</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">java.util.Queue</span><span class="o">;</span>

<span class="kd">public</span> <span class="kd">class</span> <span class="nc">SlidingWindowLog</span> <span class="o">{</span>
    <span class="kd">private</span> <span class="kd">final</span> <span class="kt">long</span> <span class="n">windowSize</span><span class="o">;</span> <span class="c1">// Window size in milliseconds</span>
    <span class="kd">private</span> <span class="kd">final</span> <span class="kt">long</span> <span class="n">limit</span><span class="o">;</span> <span class="c1">// Maximum requests allowed in window</span>
    <span class="kd">private</span> <span class="kd">final</span> <span class="nc">Queue</span><span class="o">&lt;</span><span class="nc">Long</span><span class="o">&gt;</span> <span class="n">requests</span><span class="o">;</span> <span class="c1">// Stores request timestamps</span>

    <span class="c1">// Initialize window with size and limit</span>
    <span class="kd">public</span> <span class="nf">SlidingWindowLog</span><span class="o">(</span><span class="kt">long</span> <span class="n">windowSizeSeconds</span><span class="o">,</span> <span class="kt">long</span> <span class="n">limit</span><span class="o">)</span> <span class="o">{</span>
        <span class="k">this</span><span class="o">.</span><span class="na">windowSize</span> <span class="o">=</span> <span class="n">windowSizeSeconds</span> <span class="o">*</span> <span class="mi">1000</span><span class="o">;</span>
        <span class="k">this</span><span class="o">.</span><span class="na">limit</span> <span class="o">=</span> <span class="n">limit</span><span class="o">;</span>
        <span class="k">this</span><span class="o">.</span><span class="na">requests</span> <span class="o">=</span> <span class="k">new</span> <span class="nc">LinkedList</span><span class="o">&lt;&gt;();</span>
    <span class="o">}</span>

    <span class="c1">// Check if request is allowed, thread-safe</span>
    <span class="kd">public</span> <span class="kd">synchronized</span> <span class="kt">boolean</span> <span class="nf">allowRequest</span><span class="o">()</span> <span class="o">{</span>
        <span class="kt">long</span> <span class="n">now</span> <span class="o">=</span> <span class="nc">System</span><span class="o">.</span><span class="na">currentTimeMillis</span><span class="o">();</span>
        <span class="c1">// Remove timestamps outside the window</span>
        <span class="k">while</span> <span class="o">(!</span><span class="n">requests</span><span class="o">.</span><span class="na">isEmpty</span><span class="o">()</span> <span class="o">&amp;&amp;</span> <span class="n">now</span> <span class="o">-</span> <span class="n">requests</span><span class="o">.</span><span class="na">peek</span><span class="o">()</span> <span class="o">&gt;</span> <span class="n">windowSize</span><span class="o">)</span> <span class="o">{</span>
            <span class="n">requests</span><span class="o">.</span><span class="na">poll</span><span class="o">();</span>
        <span class="o">}</span>
        <span class="k">if</span> <span class="o">(</span><span class="n">requests</span><span class="o">.</span><span class="na">size</span><span class="o">()</span> <span class="o">&lt;</span> <span class="n">limit</span><span class="o">)</span> <span class="o">{</span> <span class="c1">// Within limit</span>
            <span class="n">requests</span><span class="o">.</span><span class="na">offer</span><span class="o">(</span><span class="n">now</span><span class="o">);</span> <span class="c1">// Record current request timestamp</span>
            <span class="k">return</span> <span class="kc">true</span><span class="o">;</span> <span class="c1">// Allow request</span>
        <span class="o">}</span>
        <span class="k">return</span> <span class="kc">false</span><span class="o">;</span> <span class="c1">// Exceeds limit, deny request</span>
    <span class="o">}</span>
<span class="o">}</span>
</code></pre></div></div> <p><strong>Usage Example</strong>:</p> <div class="language-java highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nc">SlidingWindowLog</span> <span class="n">log</span> <span class="o">=</span> <span class="k">new</span> <span class="nc">SlidingWindowLog</span><span class="o">(</span><span class="mi">1</span><span class="o">,</span> <span class="mi">10</span><span class="o">);</span> <span class="c1">// 1 second, 10 requests</span>
<span class="k">for</span> <span class="o">(</span><span class="kt">int</span> <span class="n">i</span> <span class="o">=</span> <span class="mi">0</span><span class="o">;</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="mi">15</span><span class="o">;</span> <span class="n">i</span><span class="o">++)</span> <span class="o">{</span>
    <span class="k">if</span> <span class="o">(</span><span class="n">log</span><span class="o">.</span><span class="na">allowRequest</span><span class="o">())</span> <span class="o">{</span>
        <span class="nc">System</span><span class="o">.</span><span class="na">out</span><span class="o">.</span><span class="na">println</span><span class="o">(</span><span class="s">"Request "</span> <span class="o">+</span> <span class="n">i</span> <span class="o">+</span> <span class="s">" allowed"</span><span class="o">);</span>
    <span class="o">}</span> <span class="k">else</span> <span class="o">{</span>
        <span class="nc">System</span><span class="o">.</span><span class="na">out</span><span class="o">.</span><span class="na">println</span><span class="o">(</span><span class="s">"Request "</span> <span class="o">+</span> <span class="n">i</span> <span class="o">+</span> <span class="s">" rejected"</span><span class="o">);</span>
    <span class="o">}</span>
<span class="o">}</span>
</code></pre></div></div> <p><strong>Parameter Tuning</strong>:</p> <ul> <li><strong>Window Size</strong>: Set based on precision needs (e.g., 1 second).</li> <li><strong>Limit</strong>: Set based on peak traffic (e.g., 1000 requests).</li> </ul> <h3 id="5-sliding-window-counter">5. Sliding Window Counter</h3> <p><strong>Accessible Explanation</strong>:<br/> The sliding window counter is like a theme park queue manager tasked with limiting a roller coaster to 10 riders per minute. Instead of recording each rider’s exact arrival time, the manager divides time into 10-second sub-windows (6 sub-windows covering 60 seconds) and tracks the number of riders in each. When a new rider arrives, the manager estimates the total number of riders in the past 60 seconds by weighting each sub-window’s count based on how much of it remains in the time window: older sub-windows contribute less (“discounted”), while newer ones contribute fully. If the estimated total is below 10, the rider is allowed to join the queue, and the current sub-window’s count is updated; otherwise, they are denied. This approach is memory-efficient and smooths traffic peaks but may introduce slight inaccuracies due to estimation.</p> <p><strong>Principle</strong>: Divides the time window (e.g., 60 seconds) into smaller sub-windows (e.g., 10 seconds each) and records request counts per sub-window. For a new request, it calculates the total requests in the sliding window using weighted estimation (based on the sub-window’s remaining time proportion). If the total is below the limit, the request is allowed, and the current sub-window’s count is incremented; otherwise, it is rejected. The weighting mechanism simulates a sliding window, avoiding the boundary issues of fixed windows.</p> <p><strong>Mermaid Diagram</strong>:</p> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2025/07/5-480.webp 480w,/assets/img/2025/07/5-800.webp 800w,/assets/img/2025/07/5-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/2025/07/5.png" class="img-fluid rounded z-depth-1" width="50%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <p><strong>Advantages</strong>:</p> <ul> <li> <p><strong>Memory Efficient</strong>: Stores only sub-window counts (e.g., 6 sub-windows), reducing memory usage compared to timestamp storage.</p> </li> <li> <p><strong>Smooths Traffic Peaks</strong>: Weighted estimation mitigates the boundary overload issues of fixed window counters.</p> </li> </ul> <p><strong>Disadvantages</strong>:</p> <ul> <li><strong>Limited Precision</strong>: Weighted estimation may introduce inaccuracies, leading to less strict rate limiting. For example, requests at sub-window boundaries may be partially counted, causing the actual traffic to slightly exceed or fall below the intended limit, impacting high-precision scenarios.</li> </ul> <p><strong>Use Cases</strong>:</p> <ul> <li> <p><strong>E-commerce Promotions</strong>: Limiting 2000 requests per second during JD 618 sales.</p> </li> <li> <p><strong>Social Media Surges</strong>: Restricting video uploads during TikTok trending events.</p> </li> </ul> <p><strong>Example: Roller Coaster Queue Limiting</strong><br/> Consider the current time as <strong>12:01:01.000</strong> (61 seconds into the event), with a 60-second window (12:00:01.000 to 12:01:01.000), limiting to 10 riders per minute, and sub-windows of 10 seconds (6 sub-windows). A new rider (Rider 10) arrives, and the manager decides whether to allow them to queue.<br/> <strong>Historical Records</strong>:</p> <ul> <li> <p>12:00:10.000-12:00:20.000: 2 riders.</p> </li> <li> <p>12:00:20.000-12:00:30.000: 1 rider.</p> </li> <li> <p>12:00:30.000-12:00:40.000: 2 riders.</p> </li> <li> <p>12:00:40.000-12:00:50.000: 1 rider.</p> </li> <li> <p>12:00:50.000-12:01:00.000: 0 riders.</p> </li> <li> <p>Current Sub-Window (12:01:00.000-12:01:10.000): 1 rider (initial).</p> </li> </ul> <p><strong>Estimation Process</strong>:<br/> The manager estimates the total riders in the past 60 seconds by weighting each sub-window’s count based on its remaining time proportion in the window:</p> <table> <thead> <tr> <th> </th> <th> </th> <th> </th> <th> </th> <th> </th> </tr> </thead> <tbody> <tr> <td>Sub-Window Time</td> <td>Riders</td> <td>Window Proportion (Weight)</td> <td>Weighted Riders (Riders × Weight)</td> <td>Notes</td> </tr> <tr> <td>12:00:10.000-12:00:20.000</td> <td>2</td> <td>10/60 ≈ 0.167</td> <td>2 × 0.167 ≈ 0.33</td> <td>10 seconds remain in window, small weight, 2 riders contribute 0.33.</td> </tr> <tr> <td>12:00:20.000-12:00:30.000</td> <td>1</td> <td>20/60 ≈ 0.333</td> <td>1 × 0.333 ≈ 0.33</td> <td>20 seconds remain, moderate weight, 1 rider contributes 0.33.</td> </tr> <tr> <td>12:00:30.000-12:00:40.000</td> <td>2</td> <td>30/60 = 0.5</td> <td>2 × 0.5 = 1.0</td> <td>30 seconds remain, half weight, 2 riders contribute 1.0.</td> </tr> <tr> <td>12:00:40.000-12:00:50.000</td> <td>1</td> <td>40/60 ≈ 0.667</td> <td>1 × 0.667 ≈ 0.67</td> <td>40 seconds remain, larger weight, 1 rider contributes 0.67.</td> </tr> <tr> <td>12:00:50.000-12:01:00.000</td> <td>0</td> <td>50/60 ≈ 0.833</td> <td>0 × 0.833 = 0</td> <td>50 seconds remain, no riders, contributes 0.</td> </tr> <tr> <td>Current (12:01:00.000-10.000)</td> <td>1</td> <td>60/60 = 1.0</td> <td>1 × 1.0 = 1.0</td> <td>Fully in window, full weight, 1 rider contributes 1.0.</td> </tr> <tr> <td><strong>Total</strong></td> <td> </td> <td> </td> <td><strong>3.33 ≈ 3 riders</strong></td> <td>Estimated 3 riders &lt; 10, allow Rider 10 to queue.</td> </tr> </tbody> </table> <p><strong>Role of Weights</strong>:<br/> The weight (remaining time proportion) simulates a sliding window: older sub-windows (e.g., 10-20 seconds) contribute less (0.167) as they are nearly out of the window, while newer sub-windows (current) contribute fully (1.0). This smooths traffic peaks, avoiding the abrupt resets of fixed window counters (e.g., 10 riders at 59s + 10 at 61s). The estimation may introduce slight inaccuracies (e.g., 3.33 vs. actual 3.5 riders), suitable for scenarios tolerating minor deviations.</p> <p><strong>Java Implementation</strong>:</p> <div class="language-java highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">java.util.HashMap</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">java.util.Map</span><span class="o">;</span>

<span class="kd">public</span> <span class="kd">class</span> <span class="nc">SlidingWindowCounter</span> <span class="o">{</span>
    <span class="kd">private</span> <span class="kd">final</span> <span class="kt">long</span> <span class="n">windowSize</span><span class="o">;</span> <span class="c1">// Window size in milliseconds</span>
    <span class="kd">private</span> <span class="kd">final</span> <span class="kt">long</span> <span class="n">limit</span><span class="o">;</span> <span class="c1">// Maximum requests allowed in window</span>
    <span class="kd">private</span> <span class="kd">final</span> <span class="kt">long</span> <span class="n">subWindowSize</span><span class="o">;</span> <span class="c1">// Sub-window size in milliseconds</span>
    <span class="kd">private</span> <span class="kd">final</span> <span class="nc">Map</span><span class="o">&lt;</span><span class="nc">Long</span><span class="o">,</span> <span class="nc">Long</span><span class="o">&gt;</span> <span class="n">windows</span><span class="o">;</span> <span class="c1">// Sub-window counts (timestamp -&gt; count)</span>

    <span class="c1">// Initialize window with size, limit, and sub-window granularity</span>
    <span class="kd">public</span> <span class="nf">SlidingWindowCounter</span><span class="o">(</span><span class="kt">long</span> <span class="n">windowSizeSeconds</span><span class="o">,</span> <span class="kt">long</span> <span class="n">limit</span><span class="o">,</span> <span class="kt">int</span> <span class="n">granularity</span><span class="o">)</span> <span class="o">{</span>
        <span class="k">this</span><span class="o">.</span><span class="na">windowSize</span> <span class="o">=</span> <span class="n">windowSizeSeconds</span> <span class="o">*</span> <span class="mi">1000</span><span class="o">;</span>
        <span class="k">this</span><span class="o">.</span><span class="na">limit</span> <span class="o">=</span> <span class="n">limit</span><span class="o">;</span>
        <span class="k">this</span><span class="o">.</span><span class="na">subWindowSize</span> <span class="o">=</span> <span class="n">windowSize</span> <span class="o">/</span> <span class="n">granularity</span><span class="o">;</span>
        <span class="k">this</span><span class="o">.</span><span class="na">windows</span> <span class="o">=</span> <span class="k">new</span> <span class="nc">HashMap</span><span class="o">&lt;&gt;();</span>
    <span class="o">}</span>

    <span class="c1">// Check if request is allowed, thread-safe</span>
    <span class="kd">public</span> <span class="kd">synchronized</span> <span class="kt">boolean</span> <span class="nf">allowRequest</span><span class="o">()</span> <span class="o">{</span>
        <span class="kt">long</span> <span class="n">now</span> <span class="o">=</span> <span class="nc">System</span><span class="o">.</span><span class="na">currentTimeMillis</span><span class="o">();</span>
        <span class="c1">// Align current time to sub-window start</span>
        <span class="kt">long</span> <span class="n">gridNumber</span> <span class="o">=</span> <span class="n">now</span> <span class="o">/</span> <span class="n">subWindowSize</span><span class="o">;</span> <span class="c1">// Sub-window index</span>
        <span class="kt">long</span> <span class="n">currentSubWindow</span> <span class="o">=</span> <span class="n">gridNumber</span> <span class="o">*</span> <span class="n">subWindowSize</span><span class="o">;</span> <span class="c1">// Sub-window start time</span>

        <span class="c1">// Remove expired sub-windows (older than window size)</span>
        <span class="n">windows</span><span class="o">.</span><span class="na">entrySet</span><span class="o">().</span><span class="na">removeIf</span><span class="o">(</span><span class="n">entry</span> <span class="o">-&gt;</span> <span class="n">now</span> <span class="o">-</span> <span class="n">entry</span><span class="o">.</span><span class="na">getKey</span><span class="o">()</span> <span class="o">*</span> <span class="n">subWindowSize</span> <span class="o">&gt;</span> <span class="n">windowSize</span><span class="o">);</span>

        <span class="c1">// Calculate total requests in sliding window (weighted estimation)</span>
        <span class="kt">double</span> <span class="n">total</span> <span class="o">=</span> <span class="mi">0</span><span class="o">;</span>
        <span class="k">for</span> <span class="o">(</span><span class="nc">Map</span><span class="o">.</span><span class="na">Entry</span><span class="o">&lt;</span><span class="nc">Long</span><span class="o">,</span> <span class="nc">Long</span><span class="o">&gt;</span> <span class="n">entry</span> <span class="o">:</span> <span class="n">windows</span><span class="o">.</span><span class="na">entrySet</span><span class="o">())</span> <span class="o">{</span>
            <span class="kt">long</span> <span class="n">subWindowStart</span> <span class="o">=</span> <span class="n">entry</span><span class="o">.</span><span class="na">getKey</span><span class="o">()</span> <span class="o">*</span> <span class="n">subWindowSize</span><span class="o">;</span> <span class="c1">// Sub-window start time</span>
            <span class="kt">long</span> <span class="n">count</span> <span class="o">=</span> <span class="n">entry</span><span class="o">.</span><span class="na">getValue</span><span class="o">();</span> <span class="c1">// Sub-window request count</span>
            <span class="c1">// Calculate weight: proportion of sub-window within the window</span>
            <span class="kt">double</span> <span class="n">weight</span> <span class="o">=</span> <span class="nc">Math</span><span class="o">.</span><span class="na">min</span><span class="o">(</span><span class="mf">1.0</span><span class="o">,</span> <span class="o">(</span><span class="kt">double</span><span class="o">)</span> <span class="o">(</span><span class="n">windowSize</span> <span class="o">-</span> <span class="o">(</span><span class="n">now</span> <span class="o">-</span> <span class="n">subWindowStart</span><span class="o">))</span> <span class="o">/</span> <span class="n">windowSize</span><span class="o">);</span>
            <span class="n">total</span> <span class="o">+=</span> <span class="n">count</span> <span class="o">*</span> <span class="n">weight</span><span class="o">;</span> <span class="c1">// Weighted count</span>
        <span class="o">}</span>

        <span class="k">if</span> <span class="o">(</span><span class="n">total</span> <span class="o">&lt;</span> <span class="n">limit</span><span class="o">)</span> <span class="o">{</span> <span class="c1">// Within limit</span>
            <span class="c1">// Increment current sub-window count</span>
            <span class="n">windows</span><span class="o">.</span><span class="na">merge</span><span class="o">(</span><span class="n">currentSubWindow</span><span class="o">,</span> <span class="mi">1L</span><span class="o">,</span> <span class="nl">Long:</span><span class="o">:</span><span class="n">sum</span><span class="o">);</span>
            <span class="k">return</span> <span class="kc">true</span><span class="o">;</span> <span class="c1">// Allow request</span>
        <span class="o">}</span>
        <span class="k">return</span> <span class="kc">false</span><span class="o">;</span> <span class="c1">// Exceeds limit, deny request</span>
    <span class="o">}</span>
<span class="o">}</span>
</code></pre></div></div> <p><strong>Usage Example</strong>:</p> <div class="language-java highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nc">SlidingWindowCounter</span> <span class="n">counter</span> <span class="o">=</span> <span class="k">new</span> <span class="nc">SlidingWindowCounter</span><span class="o">(</span><span class="mi">60</span><span class="o">,</span> <span class="mi">10</span><span class="o">,</span> <span class="mi">6</span><span class="o">);</span> <span class="c1">// 60 seconds, 10 requests, 6 sub-windows</span>
<span class="k">for</span> <span class="o">(</span><span class="kt">int</span> <span class="n">i</span> <span class="o">=</span> <span class="mi">0</span><span class="o">;</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="mi">15</span><span class="o">;</span> <span class="n">i</span><span class="o">++)</span> <span class="o">{</span>
    <span class="k">if</span> <span class="o">(</span><span class="n">counter</span><span class="o">.</span><span class="na">allowRequest</span><span class="o">())</span> <span class="o">{</span>
        <span class="nc">System</span><span class="o">.</span><span class="na">out</span><span class="o">.</span><span class="na">println</span><span class="o">(</span><span class="s">"Request "</span> <span class="o">+</span> <span class="n">i</span> <span class="o">+</span> <span class="s">" allowed"</span><span class="o">);</span>
    <span class="o">}</span> <span class="k">else</span> <span class="o">{</span>
        <span class="nc">System</span><span class="o">.</span><span class="na">out</span><span class="o">.</span><span class="na">println</span><span class="o">(</span><span class="s">"Request "</span> <span class="o">+</span> <span class="n">i</span> <span class="o">+</span> <span class="s">" rejected"</span><span class="o">);</span>
    <span class="o">}</span>
<span class="o">}</span>
</code></pre></div></div> <p><strong>Parameter Tuning</strong>:</p> <ul> <li> <p><strong>Window Size</strong>: Typically 1–60 seconds, 60 seconds in the example.</p> </li> <li> <p><strong>Granularity</strong>: Smaller granularity (e.g., 6 or 10) improves precision, 6 in the example (10 seconds/sub-window).</p> </li> <li> <p><strong>Limit</strong>: Set based on business needs (e.g., 10 requests/minute).</p> </li> </ul> <h2 id="summary">Summary</h2> <ul> <li><strong>Selection Guide</strong>: <ul> <li><strong>Bursty Traffic</strong>: Token Bucket (handles high concurrency), Sliding Window Counter (smooths peaks).</li> <li><strong>Stable Rates</strong>: Leaky Bucket (ensures consistent output).</li> <li><strong>High Precision</strong>: Sliding Window Log (strict limiting).</li> <li><strong>Simple Scenarios</strong>: Fixed Window Counter (quick implementation).</li> </ul> </li> <li><strong>Key Considerations</strong>: <ul> <li>Token Bucket: Balances burst support with tuning challenges.</li> <li>Leaky Bucket: Prioritizes stability but struggles with bursts and latency.</li> <li>Fixed Window Counter: Efficient but prone to boundary issues.</li> <li>Sliding Window Log: Precise yet resource-intensive, ideal for critical applications.</li> <li>Sliding Window Counter: Efficient with moderate precision, suitable for balanced needs.</li> </ul> </li> <li><strong>Practical Recommendations</strong>: <ul> <li>Use Redis for distributed environments (e.g., Token Bucket, Fixed Window).</li> <li>Test under high concurrency to validate rate-limiting effectiveness.</li> <li>Monitor request rates and adjust parameters dynamically.</li> </ul> </li> </ul>]]></content><author><name></name></author><category term="System Design Other"/><summary type="html"><![CDATA[Introduction to Rate Limiting]]></summary></entry><entry><title type="html">Best Practices for Incident Response</title><link href="https://zhengstar94.github.io//blog/2025/BestPracticesForIncidentResponse/" rel="alternate" type="text/html" title="Best Practices for Incident Response"/><published>2025-05-05T00:00:00+00:00</published><updated>2025-05-05T00:00:00+00:00</updated><id>https://zhengstar94.github.io//blog/2025/BestPracticesForIncidentResponse</id><content type="html" xml:base="https://zhengstar94.github.io//blog/2025/BestPracticesForIncidentResponse/"><![CDATA[<p>In complex products and systems, failures are inevitable. When incidents occur, we must not only act swiftly to restore business continuity but also continually improve and extract lessons to prevent recurrence. This article summarizes a practical “best response strategy” aimed at providing actionable emergency handling and post-mortem frameworks for development teams.</p> <h2 id="1-golden-rules-of-incident-handling">1. Golden Rules of Incident Handling</h2> <h3 id="11-stopping-the-bleeding-takes-top-priority">1.1 Stopping the Bleeding Takes Top Priority</h3> <p>In emergency response, the primary goal is to restore product functionality as quickly as possible—similar to the “stop the bleeding” principle in first aid. Root cause analysis can wait; the priority is immediate recovery.</p> <h3 id="12-identify-the-triggering-variables">1.2 Identify the Triggering Variables</h3> <p>Response measures must <strong>support phased rollouts</strong> to avoid expanding the scope of the problem. The execution of the plan should be <strong>efficient yet cautious</strong>, ensuring no additional risks are introduced.</p> <ul> <li><strong>Variables are often the trigger point of failures</strong>: These are typically the first suspects and relatively easy to spot.</li> <li><strong>Analyze variables for quick containment</strong>: Focus your investigation on the variables to locate the issue and take immediate action.</li> </ul> <h3 id="13-careful-and-efficient-execution-of-containment-plans">1.3 Careful and Efficient Execution of Containment Plans</h3> <p>While executing containment measures, avoid making the situation worse. Balance speed with thoroughness.</p> <h2 id="2-strengthening-incident-response-capabilities">2. Strengthening Incident Response Capabilities</h2> <h3 id="21-effective-communication">2.1 Effective Communication</h3> <p>During emergency handling, the <strong>product owner should oversee the entire situation</strong>, while team members must quickly synchronize their findings and <strong>divide responsibilities to narrow down the problem scope</strong>.</p> <h3 id="22-sharpen-the-basics">2.2 Sharpen the Basics</h3> <ul> <li>Improve familiarity with business logic</li> <li>Build a toolkit of handy scripts and utilities</li> <li>Establish streamlined troubleshooting processes</li> </ul> <h3 id="23-proactive-measures-in-feature-development">2.3 Proactive Measures in Feature Development</h3> <p>It’s essential to enforce the following during development:</p> <ul> <li><strong>Gray release support</strong></li> <li><strong>Monitoring capability</strong></li> <li><strong>Rollback readiness</strong></li> </ul> <p>Avoid “wishful thinking” and “low-value tasks”; even if it requires extra effort, product quality and safety must not be compromised.</p> <h3 id="24-learn-from-excellent-postmortems">2.4 Learn from Excellent Postmortems</h3> <p>Study <strong>postmortems from leading companies like Cloudflare</strong>, to inspire fresh thinking and continuous improvement.</p> <h3 id="25-mindset-adjustment">2.5 Mindset Adjustment</h3> <p>Incident response <strong>is not an exam</strong>. Teams should maintain a constructive mindset, focusing on problem-solving and learning valuable lessons from each event.</p> <h2 id="3-postmortem-analysis">3. Postmortem Analysis</h2> <h3 id="31-core-objectives">3.1 Core Objectives</h3> <ul> <li>Prevent recurrence of the incident</li> </ul> <h3 id="32-key-considerations">3.2 Key Considerations</h3> <ul> <li>Ensure thorough resolution of the issue</li> <li>Document the incident timeline and root causes</li> <li>Implement targeted improvement actions</li> <li>Establish guidelines and systems to guard against similar problems</li> <li>Maintain a holistic view</li> <li>Ensure high-quality execution of action items</li> <li>Integrate temporary fixes into long-term improvements</li> </ul> <h2 id="4-accountability">4. Accountability</h2> <h3 id="41-attending-the-incident-review-meeting">4.1 Attending the Incident Review Meeting</h3> <p>The purpose of the review is to acknowledge issues and extract lessons—not simply to assign blame. <strong>Taking responsibility is both a duty and a growth opportunity</strong>.</p> <h3 id="42-mindset-adjustment">4.2 Mindset Adjustment</h3> <p>The team should maintain a proactive attitude, learn from mistakes, and avoid repeating them. And if worst comes to worst and the issue proves unsolvable—well, sometimes you have to “grab your bucket and leave” (just kidding!).</p> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2025/05/FaultResponse-480.webp 480w,/assets/img/2025/05/FaultResponse-800.webp 800w,/assets/img/2025/05/FaultResponse-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/2025/05/FaultResponse.png" class="img-fluid rounded z-depth-1" width="50%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure>]]></content><author><name></name></author><category term="Work"/><summary type="html"><![CDATA[In complex products and systems, failures are inevitable. When incidents occur, we must not only act swiftly to restore business continuity but also continually improve and extract lessons to prevent recurrence. This article summarizes a practical “best response strategy” aimed at providing actionable emergency handling and post-mortem frameworks for development teams.]]></summary></entry><entry><title type="html">Group cycle</title><link href="https://zhengstar94.github.io//blog/2025/GroupCycle/" rel="alternate" type="text/html" title="Group cycle"/><published>2025-04-07T00:00:00+00:00</published><updated>2025-04-07T00:00:00+00:00</updated><id>https://zhengstar94.github.io//blog/2025/GroupCycle</id><content type="html" xml:base="https://zhengstar94.github.io//blog/2025/GroupCycle/"><![CDATA[<h2 id="group-cycle">Group cycle</h2> <h3 id="core-concept">Core Concept</h3> <p>Group cycle is a powerful algorithmic technique specifically designed for handling problems that require dividing arrays or sequences into several groups and applying the same logical processing to each group. This pattern is particularly effective when dealing with data that has segmented characteristics, significantly simplifying code structure and improving readability.</p> <p>When we face problems that require dividing continuous elements into different groups according to specific conditions, the group cycle pattern provides a clear solution. Unlike traditional single-layer loops, group cycle uses a double-layer loop structure, with outer and inner loops each having their own responsibilities:</p> <ol> <li><strong>Outer Loop</strong>: Responsible for two key tasks <ul> <li>Inter-group preparation: Recording the starting position of each group</li> <li>Post-group statistics: Updating global results after processing a group (e.g., maximum values, counts, etc.)</li> </ul> </li> <li><strong>Inner Loop</strong>: Focuses on single group processing <ul> <li>Determining the current group’s boundary: Finding where the group ends</li> <li>Applying intra-group processing logic: Executing required operations on the elements of the current group</li> </ul> </li> </ol> <p>The key advantage of this structure lies in its clear logic and well-defined boundaries, especially that it doesn’t require special processing for the last group of data, which is often a common source of errors in coding.</p> <h3 id="example-problem">Example Problem</h3> <h4 id="problem-description">Problem Description</h4> <p>Given an integer array <code class="language-plaintext highlighter-rouge">nums</code> and an integer <code class="language-plaintext highlighter-rouge">threshold</code>, we need to find the longest subarray that satisfies the following conditions:</p> <ol> <li>The first element of the subarray must be even</li> <li>The parity of adjacent elements in the subarray must alternate (one odd, one even)</li> <li>All elements in the subarray must not exceed the threshold We need to return the length of the longest subarray that satisfies these conditions.</li> </ol> <p><strong>Example:</strong></p> <ul> <li><strong>Input:</strong> nums = [3,2,5,4], threshold = 5</li> <li><strong>Output:</strong> 3</li> <li><strong>Explanation:</strong> The longest subarray that satisfies the conditions is [2,5,4], with a length of 3.</li> </ul> <h4 id="algorithm-implementation">Algorithm Implementation</h4> <p>Using group cycle to solve this problem, we implement the following:</p> <div class="language-java highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kd">public</span> <span class="kt">int</span> <span class="nf">longestAlternatingSubarray</span><span class="o">(</span><span class="kt">int</span><span class="o">[]</span> <span class="n">nums</span><span class="o">,</span> <span class="kt">int</span> <span class="n">threshold</span><span class="o">)</span> <span class="o">{</span>
    <span class="kt">int</span> <span class="n">n</span> <span class="o">=</span> <span class="n">nums</span><span class="o">.</span><span class="na">length</span><span class="o">;</span>
    <span class="kt">int</span> <span class="n">ans</span> <span class="o">=</span> <span class="mi">0</span><span class="o">,</span> <span class="n">i</span> <span class="o">=</span> <span class="mi">0</span><span class="o">;</span>
    <span class="k">while</span> <span class="o">(</span><span class="n">i</span> <span class="o">&lt;</span> <span class="n">n</span><span class="o">)</span> <span class="o">{</span>
        <span class="k">if</span> <span class="o">(</span><span class="n">nums</span><span class="o">[</span><span class="n">i</span><span class="o">]</span> <span class="o">&gt;</span> <span class="n">threshold</span> <span class="o">||</span> <span class="n">nums</span><span class="o">[</span><span class="n">i</span><span class="o">]</span> <span class="o">%</span> <span class="mi">2</span> <span class="o">!=</span> <span class="mi">0</span><span class="o">)</span> <span class="o">{</span>
            <span class="n">i</span><span class="o">++;</span> <span class="c1">// Skip elements that don't meet the initial conditions</span>
            <span class="k">continue</span><span class="o">;</span>
        <span class="o">}</span>
        <span class="kt">int</span> <span class="n">start</span> <span class="o">=</span> <span class="n">i</span><span class="o">;</span> <span class="c1">// Record the starting position of this group</span>
        <span class="n">i</span><span class="o">++;</span> <span class="c1">// Starting position already meets requirements, start judging from next position</span>
        <span class="k">while</span> <span class="o">(</span><span class="n">i</span> <span class="o">&lt;</span> <span class="n">n</span> <span class="o">&amp;&amp;</span> <span class="n">nums</span><span class="o">[</span><span class="n">i</span><span class="o">]</span> <span class="o">&lt;=</span> <span class="n">threshold</span> <span class="o">&amp;&amp;</span> <span class="n">nums</span><span class="o">[</span><span class="n">i</span><span class="o">]</span> <span class="o">%</span> <span class="mi">2</span> <span class="o">!=</span> <span class="n">nums</span><span class="o">[</span><span class="n">i</span> <span class="o">-</span> <span class="mi">1</span><span class="o">]</span> <span class="o">%</span> <span class="mi">2</span><span class="o">)</span> <span class="o">{</span>
            <span class="n">i</span><span class="o">++;</span>
        <span class="o">}</span>
        <span class="c1">// From start to i-1 is a subarray that meets the requirements (and cannot be extended further)</span>
        <span class="n">ans</span> <span class="o">=</span> <span class="nc">Math</span><span class="o">.</span><span class="na">max</span><span class="o">(</span><span class="n">ans</span><span class="o">,</span> <span class="n">i</span> <span class="o">-</span> <span class="n">start</span><span class="o">);</span>
    <span class="o">}</span>
    <span class="k">return</span> <span class="n">ans</span><span class="o">;</span>
<span class="o">}</span>
</code></pre></div></div> <h4 id="execution-step-analysis">Execution Step Analysis</h4> <p>Using the example input nums = [3,2,5,4], threshold = 5, the execution process is as follows:</p> <ol> <li><strong>Initialization</strong>: n = 4, ans = 0, i = 0</li> <li><strong>First Outer Loop</strong>: <ul> <li>nums[0] = 3, is odd, doesn’t meet initial condition (must be even)</li> <li>i++ → i = 1, continue to next iteration</li> </ul> </li> <li><strong>Second Outer Loop</strong>: <ul> <li>nums[1] = 2, is even and ≤ threshold, meets initial condition</li> <li>Record start = 1</li> <li>i++ → i = 2, enter inner loop</li> <li>Inner loop: <ul> <li>Check nums[2] = 5: ≤ threshold and has different parity from nums[1] (5 is odd, 2 is even)</li> <li>Meets condition, i++ → i = 3</li> <li>Check nums[3] = 4: ≤ threshold and has different parity from nums[2] (4 is even, 5 is odd)</li> <li>Meets condition, i++ → i = 4</li> <li>i = 4 is beyond array range, inner loop ends</li> </ul> </li> <li>Calculate subarray length: i - start = 4 - 1 = 3</li> <li>Update ans = max(0, 3) = 3</li> </ul> </li> <li><strong>Loop End</strong>: i = 4 ≥ n = 4, outer loop ends</li> <li><strong>Return Result</strong>: ans = 3</li> </ol> <h3 id="complexity-analysis">Complexity Analysis</h3> <ol> <li><strong>Time Complexity: O(n)</strong> <ul> <li>Although the code has nested loops, each element is visited at most once</li> <li>The outer loop variable i doesn’t simply increment, but jumps based on inner loop results</li> <li>All elements are processed only once in total, so the time complexity is O(n)</li> </ul> </li> <li><strong>Space Complexity: O(1)</strong> <ul> <li>Only uses a few variables (ans, i, start) to track state</li> <li>No additional data structures related to input size are used</li> </ul> </li> </ol> <h3 id="key-advantages">Key Advantages</h3> <ol> <li><strong>Clear Logic</strong> <ul> <li>Outer loop is responsible for finding suitable subarray starting points</li> <li>Inner loop is responsible for extending the subarray until it can’t be extended further</li> <li>Maximum length is updated immediately after group processing is complete</li> </ul> </li> <li><strong>Concise Code</strong> <ul> <li>No need for additional markers or complex condition judgments</li> <li>Naturally handles subarray boundaries through the concept of groups</li> </ul> </li> <li><strong>Avoids Common Errors</strong> <ul> <li>No need to specially process the last group of elements</li> <li>Boundary conditions are built into the loop structure</li> </ul> </li> <li><strong>Completed in One Pass</strong> <ul> <li>A single scan can find the answer, no need for repeated processing</li> <li>Ensures algorithm efficiency</li> </ul> </li> </ol> <h3 id="universal-pattern-of-group-cycle">Universal Pattern of Group Cycle</h3> <div class="language-java highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kt">void</span> <span class="nf">groupCycle</span><span class="o">(</span><span class="kt">int</span><span class="o">[]</span> <span class="n">nums</span><span class="o">)</span> <span class="o">{</span>
    <span class="kt">int</span> <span class="n">n</span> <span class="o">=</span> <span class="n">nums</span><span class="o">.</span><span class="na">length</span><span class="o">;</span>
    <span class="kt">int</span> <span class="n">i</span> <span class="o">=</span> <span class="mi">0</span><span class="o">;</span>
    
    <span class="k">while</span> <span class="o">(</span><span class="n">i</span> <span class="o">&lt;</span> <span class="n">n</span><span class="o">)</span> <span class="o">{</span>
        <span class="kt">int</span> <span class="n">start</span> <span class="o">=</span> <span class="n">i</span><span class="o">;</span>
        
        <span class="c1">// Inner loop: determine how far the current group can extend</span>
        <span class="k">while</span> <span class="o">(</span><span class="n">i</span> <span class="o">&lt;</span> <span class="n">n</span> <span class="o">&amp;&amp;</span> <span class="cm">/* condition for continuing current group */</span><span class="o">)</span> <span class="o">{</span>
            <span class="n">i</span><span class="o">++;</span>
        <span class="o">}</span>
        
        <span class="c1">// Elements from index 'start' to 'i - 1' form one group</span>
        <span class="c1">// You can process the group here, for example:</span>
        <span class="c1">// int groupLength = i - start;</span>
        
        <span class="c1">// No need to do i++ here — the index has already been advanced inside the inner loop</span>
    <span class="o">}</span>
<span class="o">}</span>
</code></pre></div></div> <p>The beauty of this pattern lies in the fact that the outer loop doesn’t simply increment the index step by step—instead, it jumps forward based on the result of the inner loop. This ensures that each element is processed exactly once, while maintaining both clarity and efficiency in the code.</p> <h3 id="best-practices">Best Practices</h3> <ol> <li><strong>Clearly Define Group Boundary Conditions</strong> <ul> <li>Clearly specify under what circumstances a new group starts</li> <li>Clearly specify under what circumstances the current group ends</li> </ul> </li> <li><strong>Skip Elements That Don’t Meet Conditions Early</strong> <ul> <li>Check and skip elements that can’t be group starting points in the outer loop</li> <li>Reduce unnecessary calculations and checks</li> </ul> </li> <li><strong>Correctly Increment Loop Variables</strong> <ul> <li>Distinguish between direct incrementation (i++) and condition-based incrementation</li> <li>Increment loop variables at appropriate times to avoid missing or duplicate processing</li> </ul> </li> <li><strong>Correctly Calculate Group Length</strong> <ul> <li>Group length is the end position minus the start position</li> <li>Update the answer immediately after group processing is complete</li> </ul> </li> <li><strong>Reasonably Use the Continue Statement</strong> <ul> <li>Use continue to skip conditions that don’t meet requirements</li> <li>Maintain the clarity of loop logic</li> </ul> </li> </ol> <h3 id="application-scenarios">Application Scenarios</h3> <p>The group cycle technique is applicable to various algorithmic problems, especially those involving data with segmented characteristics:</p> <ol> <li><strong>Processing Consecutive Identical Elements</strong> <ul> <li>Calculate the longest sequence of consecutive identical characters</li> <li>Compress consecutive repeated elements (e.g., AAABBC → 3A2B1C)</li> </ul> </li> <li><strong>Peak-Valley Analysis</strong> <ul> <li>Find peaks and valleys in arrays</li> <li>Analyze trend changes in time series data such as stock prices</li> </ul> </li> <li><strong>Interval Property Problems</strong> <ul> <li>Find the longest/shortest intervals that satisfy specific conditions</li> <li>Process sequences with alternating characteristics (such as odd-even alternating, up-down alternating)</li> </ul> </li> <li><strong>Pattern Recognition</strong> <ul> <li>Identify specific patterns or regularities in sequences</li> <li>Find substrings that satisfy specific rules in strings</li> </ul> </li> <li><strong>Sequence Segmentation Processing</strong> <ul> <li>Divide sequences into multiple segments with similar properties</li> <li>Apply different processing logic to different segments</li> </ul> </li> </ol> <h3 id="key-considerations">Key Considerations</h3> <p>When applying the group cycle technique, consider the following key factors:</p> <ol> <li><strong>Group Definition</strong> <ul> <li>Clearly define group start conditions: What kind of elements can serve as starting points for groups?</li> <li>Clearly define group end conditions: Under what circumstances does the current group end?</li> <li>These definitions directly determine the conditions and structure of the loop</li> </ul> </li> <li><strong>Handling Boundary Cases</strong> <ul> <li>Empty array processing: The algorithm needs to correctly handle cases where the input is empty</li> <li>Single element processing: Determine whether a valid group can be formed when the array has only one element</li> <li>No satisfying groups exist: Ensure the algorithm returns an appropriate default value (such as 0)</li> </ul> </li> <li><strong>Index Management</strong> <ul> <li>Index updates for inner and outer loops need to be correct, avoiding skipping elements or processing duplicates</li> <li>Pay special attention to index handling after the group’s starting position is confirmed</li> </ul> </li> <li><strong>Condition Optimization</strong> <ul> <li>The order of condition judgments may affect performance, especially the application of short-circuit logic</li> <li>In the inner loop, check conditions that are easier to fail first to end unnecessary calculations early</li> </ul> </li> <li><strong>Scalability</strong> <ul> <li>Consider whether the algorithm is easy to extend to similar problems or more complex variants</li> <li>Analysis of the universality and specificity of grouping conditions</li> </ul> </li> </ol> <h3 id="summary">Summary</h3> <p>Group cycle is an efficient algorithmic technique for handling sequence segmentation problems. Its core idea is to divide sequences into multiple continuous groups through clearly defined inter-group and intra-group logic, and apply unified processing to each group. The main features of this technique include:</p> <ol> <li><strong>Clear Structure</strong>: The outer loop is responsible for inter-group management and result updates, while the inner loop focuses on single group processing and boundary determination, with clear responsibilities.</li> <li><strong>High Efficiency</strong>: Despite using nested loops, each element is processed at most once, ensuring linear time complexity.</li> <li><strong>Concise Boundary Handling</strong>: Naturally handles boundary conditions through the loop structure, avoiding common boundary errors.</li> <li><strong>Wide Application Range</strong>: From simple processing of consecutive identical elements to complex pattern recognition, group cycle provides elegant solutions.</li> </ol>]]></content><author><name></name></author><category term="Data Structure"/><summary type="html"><![CDATA[Group cycle]]></summary></entry><entry><title type="html">Sliding Window Techniques</title><link href="https://zhengstar94.github.io//blog/2025/DynamicLengthSlidingWindow/" rel="alternate" type="text/html" title="Sliding Window Techniques"/><published>2025-01-12T00:00:00+00:00</published><updated>2025-01-12T00:00:00+00:00</updated><id>https://zhengstar94.github.io//blog/2025/DynamicLengthSlidingWindow</id><content type="html" xml:base="https://zhengstar94.github.io//blog/2025/DynamicLengthSlidingWindow/"><![CDATA[<h2 id="comparison-of-fixed-length-and-dynamic-length-windows">Comparison of Fixed-Length and Dynamic-Length Windows</h2> <table> <thead> <tr> <th style="text-align: left">Type</th> <th>Window Length</th> <th>Typical Problems</th> <th style="text-align: right">Core Operations</th> </tr> </thead> <tbody> <tr> <td style="text-align: left">Fixed</td> <td>Constant</td> <td>Fixed-length substring statistics, K-size subarray calculations</td> <td style="text-align: right">Element enters and exits immediately to maintain fixed size</td> </tr> <tr> <td style="text-align: left">Dynamic</td> <td>Variable</td> <td>Longest/shortest substring search, Condition-based subarray finding</td> <td style="text-align: right">Window contracts only when conditions are violated</td> </tr> </tbody> </table> <hr/> <h2 id="part-1-master-fixed-length-sliding-window---a-universal-approach">Part 1: Master Fixed-Length Sliding Window - A Universal Approach</h2> <h3 id="core-concept">Core Concept</h3> <p>We aim to calculate the maximum number of vowels in any substring with a length of exactly k. While brute-forcing all substrings results in a time complexity of O(nk), this approach is too slow. Can we achieve O(1) substring property calculations? Yes!</p> <p>For instance, in the string “abci”, if we already know the vowel count in substring “abc”, then to compute it for “bci”:</p> <ol> <li>Check if the leaving character (‘a’) is a vowel</li> <li>Check if the entering character (‘i’) is a vowel</li> </ol> <p>This works because the middle characters (‘b’ and ‘c’) remain unchanged in both substrings.</p> <h3 id="example-walkthrough">Example Walkthrough</h3> <p><strong>Input:</strong> s = “abciiidef”, k = 3</p> <p><strong>Step-by-step:</strong></p> <ol> <li>Traverse s from left to right</li> <li>Count vowels in the first k-1 = 2 characters. Initially, there is 1 vowel</li> <li>Start processing the sliding window: <ul> <li>s[2] = ‘c’ enters window, forming “abc” (1 vowel). Update max count. Then s[0] = ‘a’ exits window, reducing count to 0</li> <li>s[3] = ‘i’ enters window, forming “bci” (1 vowel). Update max count. Then s[1] = ‘b’ exits, keeping count at 1</li> <li>s[4] = ‘i’ enters window, forming “cii” (2 vowels). Update max count. Then s[2] = ‘c’ exits, keeping count at 2</li> <li>s[5] = ‘i’ enters window, forming “iii” (3 vowels). Update max count. Then s[3] = ‘i’ exits, reducing count to 2</li> <li>s[6] = ‘d’ enters window, forming “iid” (2 vowels). Update max count. Then s[4] = ‘i’ exits, reducing count to 1</li> <li>s[7] = ‘e’ enters window, forming “ide” (2 vowels). Update max count. Then s[5] = ‘i’ exits, reducing count to 1</li> <li>s[8] = ‘f’ enters window, forming “def” (1 vowel). Update max count. Traversal complete</li> </ul> </li> </ol> <h3 id="fixed-length-sliding-window-pattern">Fixed-Length Sliding Window Pattern</h3> <p>This pattern follows three simple steps: <strong>Enter-Update-Exit</strong></p> <ol> <li><strong>Enter</strong>: Element at index i enters the window; update statistics. Repeat if i &lt; k-1</li> <li><strong>Update</strong>: Update the answer (usually max/min value)</li> <li><strong>Exit</strong>: Element at index i-k+1 exits the window; update statistics</li> </ol> <p>This pattern is universally applicable to all fixed-length sliding window problems.</p> <h3 id="implementation">Implementation</h3> <div class="language-java highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kd">class</span> <span class="nc">Solution</span> <span class="o">{</span>
    <span class="kd">public</span> <span class="kt">int</span> <span class="nf">maxVowels</span><span class="o">(</span><span class="nc">String</span> <span class="no">S</span><span class="o">,</span> <span class="kt">int</span> <span class="n">k</span><span class="o">)</span> <span class="o">{</span>
        <span class="kt">char</span><span class="o">[]</span> <span class="n">s</span> <span class="o">=</span> <span class="no">S</span><span class="o">.</span><span class="na">toCharArray</span><span class="o">();</span>
        <span class="kt">int</span> <span class="n">ans</span> <span class="o">=</span> <span class="mi">0</span><span class="o">;</span>
        <span class="kt">int</span> <span class="n">vowel</span> <span class="o">=</span> <span class="mi">0</span><span class="o">;</span>
        <span class="k">for</span> <span class="o">(</span><span class="kt">int</span> <span class="n">i</span> <span class="o">=</span> <span class="mi">0</span><span class="o">;</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="n">s</span><span class="o">.</span><span class="na">length</span><span class="o">;</span> <span class="n">i</span><span class="o">++)</span> <span class="o">{</span>
            <span class="c1">// 1. Enter window</span>
            <span class="k">if</span> <span class="o">(</span><span class="n">s</span><span class="o">[</span><span class="n">i</span><span class="o">]</span> <span class="o">==</span> <span class="sc">'a'</span> <span class="o">||</span> <span class="n">s</span><span class="o">[</span><span class="n">i</span><span class="o">]</span> <span class="o">==</span> <span class="sc">'e'</span> <span class="o">||</span> <span class="n">s</span><span class="o">[</span><span class="n">i</span><span class="o">]</span> <span class="o">==</span> <span class="sc">'i'</span> <span class="o">||</span>
                <span class="n">s</span><span class="o">[</span><span class="n">i</span><span class="o">]</span> <span class="o">==</span> <span class="sc">'o'</span> <span class="o">||</span> <span class="n">s</span><span class="o">[</span><span class="n">i</span><span class="o">]</span> <span class="o">==</span> <span class="sc">'u'</span><span class="o">)</span> <span class="o">{</span>
                <span class="n">vowel</span><span class="o">++;</span>
            <span class="o">}</span>
            <span class="k">if</span> <span class="o">(</span><span class="n">i</span> <span class="o">&lt;</span> <span class="n">k</span> <span class="o">-</span> <span class="mi">1</span><span class="o">)</span> <span class="o">{</span> <span class="c1">// Window size less than k</span>
                <span class="k">continue</span><span class="o">;</span>
            <span class="o">}</span>
            <span class="c1">// 2. Update answer</span>
            <span class="n">ans</span> <span class="o">=</span> <span class="nc">Math</span><span class="o">.</span><span class="na">max</span><span class="o">(</span><span class="n">ans</span><span class="o">,</span> <span class="n">vowel</span><span class="o">);</span>
            <span class="c1">// 3. Exit window</span>
            <span class="kt">char</span> <span class="n">out</span> <span class="o">=</span> <span class="n">s</span><span class="o">[</span><span class="n">i</span> <span class="o">-</span> <span class="n">k</span> <span class="o">+</span> <span class="mi">1</span><span class="o">];</span>
            <span class="k">if</span> <span class="o">(</span><span class="n">out</span> <span class="o">==</span> <span class="sc">'a'</span> <span class="o">||</span> <span class="n">out</span> <span class="o">==</span> <span class="sc">'e'</span> <span class="o">||</span> <span class="n">out</span> <span class="o">==</span> <span class="sc">'i'</span> <span class="o">||</span>
                <span class="n">out</span> <span class="o">==</span> <span class="sc">'o'</span> <span class="o">||</span> <span class="n">out</span> <span class="o">==</span> <span class="sc">'u'</span><span class="o">)</span> <span class="o">{</span>
                <span class="n">vowel</span><span class="o">--;</span>
            <span class="o">}</span>
        <span class="o">}</span>
        <span class="k">return</span> <span class="n">ans</span><span class="o">;</span>
    <span class="o">}</span>
<span class="o">}</span>
</code></pre></div></div> <h3 id="complexity-analysis">Complexity Analysis</h3> <ul> <li><strong>Time Complexity:</strong> O(n), where n is the length of s</li> <li><strong>Space Complexity:</strong> O(1), using only a few extra variables</li> </ul> <h3 id="key-benefits">Key Benefits</h3> <ol> <li>Universal applicability to fixed-length sliding window problems</li> <li>Simple and easy-to-remember three-step process: <strong>Enter-Update-Exit</strong></li> <li>Efficient O(n) time complexity</li> <li>Minimal space usage (O(1))</li> </ol> <h3 id="best-practices">Best Practices</h3> <ol> <li>Initialize your window with the first k-1 elements</li> <li>Update the answer after forming the complete window</li> <li>Update statistics for both entering and exiting elements</li> <li>Handle boundary conditions carefully</li> </ol> <h3 id="applications">Applications</h3> <p>This pattern can be adapted for various fixed-length sliding window problems, such as:</p> <ul> <li>Finding the maximum/minimum sum of k consecutive elements</li> <li>Finding the maximum/minimum average of k consecutive elements</li> <li>Counting occurrences of specific patterns in k-length windows</li> <li>Calculating statistics over k-length sliding windows</li> </ul> <hr/> <h2 id="part-2-dynamic-length-sliding-window">Part 2: Dynamic-Length Sliding Window</h2> <h3 id="core-concept-1">Core Concept</h3> <p>The sliding window is a powerful and efficient algorithmic technique for solving problems involving subarrays or substrings. It is particularly useful for problems requiring dynamic adjustments to window size. With sliding window techniques, we reduce time complexity from O(n²) to O(n) by avoiding unnecessary recalculations.</p> <p>This technique helps efficiently compute subarray properties by dynamically adjusting window boundaries (start and end points). The general process involves three key steps:</p> <ol> <li><strong>Window Expansion</strong>: Expand the window by moving the right boundary while updating required properties</li> <li><strong>Condition Validation</strong>: After every expansion, check whether the current window satisfies the required conditions</li> <li><strong>Window Contraction</strong>: If the condition is violated, shrink the window from the left while recalculating the required properties</li> </ol> <h3 id="example-problem">Example Problem</h3> <p><strong>Problem:</strong> Given a binary array nums containing only 0 and 1, delete exactly one element, and return the length of the longest subarray that consists only of 1.</p> <p><strong>Input</strong>: nums = [1, 1, 0, 1] <strong>Output</strong>: 3</p> <h3 id="dynamic-sliding-window-steps">Dynamic Sliding Window Steps</h3> <p>For this problem, we apply the sliding window pattern as follows:</p> <ol> <li><strong>Enter Window</strong>: Track the count of zeros as we expand the window</li> <li><strong>Validate Condition</strong>: Ensure we don’t have more than one zero in our window</li> <li><strong>Exit Window</strong>: Shrink the window when we exceed our zero limit</li> </ol> <h3 id="implementation-1">Implementation</h3> <div class="language-java highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kd">class</span> <span class="nc">Solution</span> <span class="o">{</span>
    <span class="kd">public</span> <span class="kt">int</span> <span class="nf">longestSubarray</span><span class="o">(</span><span class="kt">int</span><span class="o">[]</span> <span class="n">nums</span><span class="o">)</span> <span class="o">{</span>
        <span class="kt">int</span> <span class="n">zeroCount</span> <span class="o">=</span> <span class="mi">0</span><span class="o">;</span>
        <span class="kt">int</span> <span class="n">maxLength</span> <span class="o">=</span> <span class="mi">0</span><span class="o">;</span>
        <span class="kt">int</span> <span class="n">start</span> <span class="o">=</span> <span class="mi">0</span><span class="o">;</span>

        <span class="k">for</span> <span class="o">(</span><span class="kt">int</span> <span class="n">end</span> <span class="o">=</span> <span class="mi">0</span><span class="o">;</span> <span class="n">end</span> <span class="o">&lt;</span> <span class="n">nums</span><span class="o">.</span><span class="na">length</span><span class="o">;</span> <span class="n">end</span><span class="o">++)</span> <span class="o">{</span>
            <span class="c1">// 1. Expand window</span>
            <span class="k">if</span> <span class="o">(</span><span class="n">nums</span><span class="o">[</span><span class="n">end</span><span class="o">]</span> <span class="o">==</span> <span class="mi">0</span><span class="o">)</span> <span class="o">{</span>
                <span class="n">zeroCount</span><span class="o">++;</span>
            <span class="o">}</span>

            <span class="c1">// 2. Contract window</span>
            <span class="k">while</span> <span class="o">(</span><span class="n">zeroCount</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="o">)</span> <span class="o">{</span>
                <span class="k">if</span> <span class="o">(</span><span class="n">nums</span><span class="o">[</span><span class="n">start</span><span class="o">]</span> <span class="o">==</span> <span class="mi">0</span><span class="o">)</span> <span class="o">{</span>
                    <span class="n">zeroCount</span><span class="o">--;</span>
                <span class="o">}</span>
                <span class="n">start</span><span class="o">++;</span>
            <span class="o">}</span>

            <span class="c1">// 3. Update result</span>
            <span class="n">maxLength</span> <span class="o">=</span> <span class="nc">Math</span><span class="o">.</span><span class="na">max</span><span class="o">(</span><span class="n">maxLength</span><span class="o">,</span> <span class="n">end</span> <span class="o">-</span> <span class="n">start</span><span class="o">);</span>
        <span class="o">}</span>

        <span class="c1">// Handle edge case: all ones array</span>
        <span class="k">return</span> <span class="n">maxLength</span> <span class="o">==</span> <span class="n">nums</span><span class="o">.</span><span class="na">length</span> <span class="o">?</span> <span class="n">maxLength</span> <span class="o">-</span> <span class="mi">1</span> <span class="o">:</span> <span class="n">maxLength</span><span class="o">;</span>
    <span class="o">}</span>
<span class="o">}</span>
</code></pre></div></div> <h3 id="explanation-of-key-steps">Explanation of Key Steps</h3> <ol> <li><strong>Window Expansion</strong>: Add the current element to the window and update zero count</li> <li><strong>Window Contraction</strong>: When zero count exceeds 1, shrink window from left while reducing zero count</li> <li><strong>Update Result</strong>: Continuously calculate valid window size and track maximum length</li> </ol> <h3 id="complexity-analysis-1">Complexity Analysis</h3> <ol> <li><strong>Time Complexity</strong>: <ul> <li>O(n): Each element is processed at most twice—once when entering the window and once when exiting</li> </ul> </li> <li><strong>Space Complexity</strong>: <ul> <li>O(1): Only a few extra variables are used to track the window’s start and end, with no additional data structures</li> </ul> </li> </ol> <h3 id="applications-and-scenarios">Applications and Scenarios</h3> <p>Dynamic sliding windows are highly versatile and applicable across various scenarios:</p> <ol> <li><strong>Longest Subarray Problems</strong>: <ul> <li>Example: Finding the longest substring with at most K distinct characters</li> </ul> </li> <li><strong>Frequency or Condition Checks</strong>: <ul> <li>Example: Tracking the frequency of a specific element within a window</li> </ul> </li> <li><strong>Subarray/Substring Property Calculation</strong>: <ul> <li>Example: Dynamically calculating sums, products, or maximum/minimum values</li> </ul> </li> <li><strong>Pattern Matching</strong>: <ul> <li>Example: Detecting valid substrings that meet complex pattern requirements</li> </ul> </li> </ol> <h3 id="edge-cases">Edge Cases</h3> <p>When utilizing the sliding window technique, it’s essential to consider edge cases to avoid errors in extreme scenarios. Key edge cases for this problem include:</p> <ol> <li><strong>All Ones</strong>: <ul> <li>Input: [1, 1, 1]</li> <li>Output: Must subtract one, resulting in length len(nums) - 1</li> </ul> </li> <li><strong>All Zeros</strong>: <ul> <li>Input: [0, 0, 0]</li> <li>Output: No valid subarrays exist, resulting in output 0</li> </ul> </li> <li><strong>Empty Input</strong>: <ul> <li>Input: []</li> <li>Output: Should return 0 as there are no valid subarrays</li> </ul> </li> <li><strong>Single Element</strong>: <ul> <li>Input: [1] or [0]</li> <li>Output: Results in 0 due to the removal leaving no elements</li> </ul> </li> </ol> <h3 id="summary">Summary</h3> <p>By mastering the dynamic sliding window approach, you can efficiently solve a wide variety of problems that require handling variable-sized subarrays or substrings. Its flexibility and high efficiency make it a crucial technique for algorithmic problem-solving.</p> <hr/> <h2 id="part-3-exact-count-dynamic-sliding-window">Part 3: Exact Count Dynamic Sliding Window</h2> <h3 id="core-concept-2">Core Concept</h3> <p>The Exact Count Sliding Window is a specialized variant of the dynamic sliding window technique, designed to solve subarray problems that require “exactly meeting” certain conditions. This type of problem typically employs a “dual-pointer control group” approach, using two sliding windows to calculate differences.</p> <h3 id="key-features">Key Features</h3> <ol> <li><strong>Dual Window Technique</strong>: <ul> <li>Window 1: Tracks counts greater than or equal to the target value</li> <li>Window 2: Tracks counts greater than or equal to the target value + 1</li> <li>Final Result: Count from Window 1 - Count from Window 2</li> </ul> </li> <li><strong>Application Scenarios</strong>: <ul> <li>Finding the number of subarrays with sum exactly equal to K</li> <li>Finding subarrays containing exactly K specific elements</li> <li>Scenarios requiring exact counting rather than finding max/min values</li> </ul> </li> </ol> <h3 id="universal-template">Universal Template</h3> <p>Below is a universal template for solving exact count sliding window problems:</p> <div class="language-java highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="cm">/**
 * Universal template for exact count sliding window
 * Suitable for problems requiring counting subarrays that exactly meet certain conditions
 * @param nums input array
 * @param target target value
 * @return count of subarrays meeting the condition
 */</span>
<span class="kd">public</span> <span class="kd">static</span> <span class="kt">int</span> <span class="nf">countExactWindow</span><span class="o">(</span><span class="kt">int</span><span class="o">[]</span> <span class="n">nums</span><span class="o">,</span> <span class="kt">int</span> <span class="n">target</span><span class="o">)</span> <span class="o">{</span>
    <span class="kt">int</span> <span class="n">result</span> <span class="o">=</span> <span class="mi">0</span><span class="o">;</span>
    <span class="kt">int</span> <span class="n">value1</span> <span class="o">=</span> <span class="mi">0</span><span class="o">;</span>  <span class="c1">// value for first window (&gt;= target)</span>
    <span class="kt">int</span> <span class="n">value2</span> <span class="o">=</span> <span class="mi">0</span><span class="o">;</span>  <span class="c1">// value for second window (&gt;= target + 1)</span>

    <span class="c1">// l1: left boundary of first window</span>
    <span class="c1">// l2: left boundary of second window</span>
    <span class="c1">// r: shared right boundary for both windows</span>
    <span class="k">for</span> <span class="o">(</span><span class="kt">int</span> <span class="n">l1</span> <span class="o">=</span> <span class="mi">0</span><span class="o">,</span> <span class="n">l2</span> <span class="o">=</span> <span class="mi">0</span><span class="o">,</span> <span class="n">r</span> <span class="o">=</span> <span class="mi">0</span><span class="o">;</span> <span class="n">r</span> <span class="o">&lt;</span> <span class="n">nums</span><span class="o">.</span><span class="na">length</span><span class="o">;</span> <span class="n">r</span><span class="o">++)</span> <span class="o">{</span>
        <span class="c1">// 1. Expand windows</span>
        <span class="n">value1</span> <span class="o">+=</span> <span class="n">nums</span><span class="o">[</span><span class="n">r</span><span class="o">];</span>
        <span class="n">value2</span> <span class="o">+=</span> <span class="n">nums</span><span class="o">[</span><span class="n">r</span><span class="o">];</span>

        <span class="c1">// 2. Contract first window</span>
        <span class="k">while</span> <span class="o">(</span><span class="n">l1</span> <span class="o">&lt;=</span> <span class="n">r</span> <span class="o">&amp;&amp;</span> <span class="n">value1</span> <span class="o">&gt;=</span> <span class="n">target</span><span class="o">)</span> <span class="o">{</span>
            <span class="n">value1</span> <span class="o">-=</span> <span class="n">nums</span><span class="o">[</span><span class="n">l1</span><span class="o">];</span>
            <span class="n">l1</span><span class="o">++;</span>
        <span class="o">}</span>

        <span class="c1">// 3. Contract second window</span>
        <span class="k">while</span> <span class="o">(</span><span class="n">l2</span> <span class="o">&lt;=</span> <span class="n">r</span> <span class="o">&amp;&amp;</span> <span class="n">value2</span> <span class="o">&gt;=</span> <span class="n">target</span> <span class="o">+</span> <span class="mi">1</span><span class="o">)</span> <span class="o">{</span>
            <span class="n">value2</span> <span class="o">-=</span> <span class="n">nums</span><span class="o">[</span><span class="n">l2</span><span class="o">];</span>
            <span class="n">l2</span><span class="o">++;</span>
        <span class="o">}</span>

        <span class="c1">// 4. Calculate result at current position: difference between windows</span>
        <span class="n">result</span> <span class="o">+=</span> <span class="n">l1</span> <span class="o">-</span> <span class="n">l2</span><span class="o">;</span>
    <span class="o">}</span>
    
    <span class="k">return</span> <span class="n">result</span><span class="o">;</span>
<span class="o">}</span>
</code></pre></div></div> <h3 id="technical-points">Technical Points</h3> <ol> <li><strong>Dual Window Maintenance</strong>: <ul> <li>Maintain two windows, each with its own left pointer</li> <li>Share the right pointer to ensure synchronized expansion</li> <li>Window values must be updated synchronously</li> </ul> </li> <li><strong>Window Contraction Conditions</strong>: <ul> <li>First Window: Contract when value &gt;= target</li> <li>Second Window: Contract when value &gt;= target + 1</li> <li>Update corresponding window values during contraction</li> </ul> </li> <li><strong>Result Calculation</strong>: <ul> <li>Use l1 - l2 to calculate valid subarray count at each position</li> <li>Accumulate counts at each position for final result</li> </ul> </li> </ol> <h3 id="implementation-details">Implementation Details</h3> <ol> <li><strong>Variable Design</strong>: <ul> <li>result: stores the final count</li> <li>value1, value2: store current values for both windows</li> <li>l1, l2: represent left boundaries of both windows</li> <li>r: shared right boundary</li> </ul> </li> <li><strong>Loop Structure</strong>: <ul> <li>Outer Loop: traverse array, expand windows</li> <li>Inner Loops: contract windows based on conditions</li> </ul> </li> <li><strong>Boundary Handling</strong>: <ul> <li>Ensure l1, l2 don’t exceed r</li> <li>Carefully update values during window contraction</li> </ul> </li> </ol> <h3 id="complexity-analysis-2">Complexity Analysis</h3> <ul> <li><strong>Time Complexity</strong>: O(n) <ul> <li>Each element is added and removed at most once</li> <li>Operations for both windows are linear</li> </ul> </li> <li><strong>Space Complexity</strong>: O(1) <ul> <li>Uses only constant extra space</li> <li>No additional data structures required</li> </ul> </li> </ul> <h3 id="use-cases">Use Cases</h3> <ol> <li><strong>Counting Problems</strong>: <ul> <li>Subarrays with specific sum</li> <li>Subarrays containing specific number of elements</li> <li>Subsequences meeting exact conditions</li> </ul> </li> <li><strong>Pattern Matching</strong>: <ul> <li>Subarrays with fixed number of features</li> <li>Exact pattern matching requirements</li> </ul> </li> <li><strong>Statistical Analysis</strong>: <ul> <li>Interval sum statistics</li> <li>Frequency counting</li> <li>Exact property statistics</li> </ul> </li> </ol> <h3 id="key-considerations">Key Considerations</h3> <ol> <li><strong>Initialization</strong>: <ul> <li>Ensure correct initialization of window values</li> <li>Set proper initial positions for boundary pointers</li> </ul> </li> <li><strong>Update Logic</strong>: <ul> <li>Maintain synchronized window expansion</li> <li>Properly update window values</li> </ul> </li> <li><strong>Result Accumulation</strong>: <ul> <li>Understand the meaning of l1 - l2</li> <li>Update result at correct timing</li> </ul> </li> </ol> <h3 id="summary-1">Summary</h3> <p>The Exact Count Sliding Window is an elegant solution particularly suited for subarray problems requiring precise counting. By maintaining the difference between two windows, we can efficiently find all subarrays meeting exact conditions. The key aspects are:</p> <ol> <li>Understanding the relationship between dual windows</li> <li>Correctly maintaining window expansion and contraction</li> <li>Accurately calculating result accumulation</li> <li>Handling boundary conditions</li> </ol> <p>Mastering this technique enables solving various subarray problems requiring exact counting, especially when finding subarrays that “exactly meet” certain conditions.</p>]]></content><author><name></name></author><category term="Data Structure"/><summary type="html"><![CDATA[Comparison of Fixed-Length and Dynamic-Length Windows]]></summary></entry><entry><title type="html">Todo List</title><link href="https://zhengstar94.github.io//blog/2024/TodoList/" rel="alternate" type="text/html" title="Todo List"/><published>2024-10-28T00:00:00+00:00</published><updated>2024-10-28T00:00:00+00:00</updated><id>https://zhengstar94.github.io//blog/2024/TodoList</id><content type="html" xml:base="https://zhengstar94.github.io//blog/2024/TodoList/"><![CDATA[<h2 id="graphs">Graphs</h2> <p>210.Course Schedule II</p> <p><strong>934. Shortest Bridge</strong> - Medium (<strong>Graphs</strong>)</p> <p><strong>269. Alien Dictionary</strong> - Hard (<strong>Graphs</strong>)</p> <p><strong>1778. Shortest Path in a Hidden Grid</strong> - Hard (<strong>Graphs</strong>)</p> <p><strong>127. Word Ladder</strong> - Hard (<strong>Graphs</strong>)</p> <p><strong>934. Shortest Bridge</strong> - Medium (<strong>Graphs</strong>)</p> <p><strong>721. Accounts Merge</strong> - Medium (<strong>Graphs</strong>)</p> <p><strong>827. Making A Large Island</strong> - Hard (<strong>Graphs</strong>)</p> <p><strong>1514. Path with Maximum Probability</strong> - Medium (<strong>Graphs</strong>)</p> <p><strong>752. Open the Lock</strong> - Medium (<strong>Graphs</strong>)</p> <p><strong>1091. Shortest Path in Binary Matrix</strong> - Medium (<strong>Graphs</strong>)</p> <p><strong>317. Shortest Distance from All Buildings</strong> - Hard (<strong>Graphs</strong>)</p> <p><strong>332. Reconstruct Itinerary</strong> - Hard (<strong>Graphs</strong>)</p> <p><strong>499. The Maze III</strong> - Hard (<strong>Graphs</strong>)</p> <p><strong>959. Regions Cut By Slashes</strong> - Medium (<strong>UnionFind</strong>)</p> <h2 id="hashlable">Hashlable</h2> <p>249.Group Shifted Strings</p> <p><strong>380. Insert Delete GetRandom O(1)</strong> - Medium (<strong>HashTable</strong>)</p> <p><strong>146. LRU Cache</strong> - Medium (<strong>HashTable</strong>)</p> <h2 id="trees">Trees</h2> <p>173.Binary Search Tree Iterator</p> <p>199.Binary Tree Right Side View - 变种(变成左边视角从下往上打印，右边视角从上往下打印)</p> <p>536.Construct Binary Tree from String</p> <p><strong>938. Range Sum of BST</strong> - Easy (<strong>Trees</strong>)</p> <p><strong>426. Convert Binary Search Tree to Sorted Doubly Linked List</strong> - Medium (<strong>Trees</strong>)</p> <p><strong>314. Binary Tree Vertical Order Traversal</strong> - Medium (<strong>Trees</strong>)</p> <p><strong>543. Diameter of Binary Tree</strong> - Easy (<strong>Trees</strong>)</p> <p><strong>116. Populating Next Right Pointers in Each Node</strong> - Medium (<strong>Trees</strong>)</p> <p><strong>129. Sum Root to Leaf Numbers</strong> - Medium (<strong>Trees</strong>)</p> <p><strong>1123. Lowest Common Ancestor of Deepest Leaves</strong> - Medium (<strong>Trees</strong>)</p> <p><strong>1644. Lowest Common Ancestor of a Binary Tree II</strong> - Medium (<strong>Trees</strong>)</p> <p><strong>1650. Lowest Common Ancestor of a Binary Tree III</strong> - Medium (<strong>Trees</strong>)</p> <p><strong>437. Path Sum III</strong> - Medium (<strong>Trees</strong>)</p> <p><strong>1161. Maximum Level Sum of a Binary Tree</strong> - Medium (<strong>Trees</strong>)</p> <p><strong>1382. Balance a Binary Search Tree</strong> - Medium (<strong>Trees</strong>)</p> <p><strong>987. Vertical Order Traversal of a Binary Tree</strong> - Hard (<strong>Trees</strong>)</p> <h2 id="slidewindow">SlideWindow</h2> <p><strong>1004. Max Consecutive Ones III</strong> - Medium (<strong>SlideWindow</strong>)</p> <p><strong>1031. Maximum Sum of Two Non-Overlapping Subarrays</strong> - Medium (<strong>SlideWindow</strong>)</p> <p><strong>340. Longest Substring with At Most K Distinct Characters</strong> - Hard (<strong>SlideWindow</strong>)</p> <p><strong>438. Find All Anagrams in a String</strong> - Medium (<strong>SlideWindow</strong>)</p> <h2 id="mathgeometry">MathGeometry</h2> <p><strong>384. Shuffle an Array</strong> - Medium (<strong>MathGeometry</strong>)</p> <p><strong>1104. Path In Zigzag Labelled Binary Tree</strong> - Medium (<strong>MathGeometry</strong>)</p> <p><strong>43. Multiply Strings</strong> - Medium (<strong>MathGeometry</strong>)</p> <p><strong>60. Permutation Sequence</strong> - Hard (<strong>MathGeometry</strong>)</p> <h2 id="heap">Heap</h2> <p><strong>295. Find Median from Data Stream</strong> - Hard (<strong>Heap</strong>)</p> <p><strong>23. Merge k Sorted Lists</strong> - Hard (<strong>Heap</strong>)</p> <p><strong>23. Merge k Sorted Lists</strong> - Hard (<strong>Heap</strong>)</p> <h2 id="array">Array</h2> <p><strong>1570. Dot Product of Two Sparse Vectors</strong> - Medium (<strong>Array</strong>)</p> <p><strong>1424. Diagonal Traverse II</strong> - Medium (<strong>Array</strong>)</p> <h2 id="dynamicprogramming">DynamicProgramming</h2> <p><strong>140. Word Break II</strong> - Hard (<strong>DynamicProgramming</strong>)</p> <p><strong>1216. Valid Palindrome III</strong> - Hard (<strong>DynamicProgramming</strong>)</p> <p><strong>63. Unique Paths II</strong> - Medium (<strong>DynamicProgramming</strong>)</p> <p><strong>494. Target Sum</strong> - Medium (<strong>DynamicProgramming</strong>)</p> <p><strong>10. Regular Expression Matching</strong> - Hard (<strong>DynamicProgramming</strong>)</p> <h2 id="backtracking">Backtracking</h2> <p><strong>17. Letter Combinations of a Phone Number</strong> - Medium (<strong>Backtracking</strong>)</p> <p><strong>301. Remove Invalid Parentheses</strong> - Hard (<strong>Backtracking</strong>)</p> <p><strong>282. Expression Add Operators</strong> - Hard (<strong>Backtracking</strong>)</p> <p><strong>40. Combination Sum II</strong> - Medium (<strong>Backtracking</strong>)</p> <p><strong>78. Subsets</strong> - Medium (<strong>Backtracking</strong>)</p>]]></content><author><name></name></author><category term="Todo List"/><category term="TodoList"/><summary type="html"><![CDATA[Graphs]]></summary></entry><entry><title type="html">Floyd’s Algorithm for Finding Duplicate Number</title><link href="https://zhengstar94.github.io//blog/2024/FloydAlgorithmForFindingDuplicateNumber/" rel="alternate" type="text/html" title="Floyd’s Algorithm for Finding Duplicate Number"/><published>2024-10-09T00:00:00+00:00</published><updated>2024-10-09T00:00:00+00:00</updated><id>https://zhengstar94.github.io//blog/2024/FloydAlgorithmForFindingDuplicateNumber</id><content type="html" xml:base="https://zhengstar94.github.io//blog/2024/FloydAlgorithmForFindingDuplicateNumber/"><![CDATA[<h2 id="1-introduction">1. Introduction</h2> <p>Floyd’s Cycle-Finding Algorithm, also known as the “Tortoise and Hare” algorithm, is a pointer algorithm that uses only two pointers, moving through the sequence at different speeds. This algorithm is particularly useful for detecting cycles in sequences and has an interesting application in solving the “Find the Duplicate Number” problem.</p> <h2 id="2-problem-statement">2. Problem Statement</h2> <p>Given an array <code class="language-plaintext highlighter-rouge">nums</code> containing <code class="language-plaintext highlighter-rouge">n + 1</code> integers where each integer is in the range <code class="language-plaintext highlighter-rouge">[1, n]</code> inclusive, prove that at least one duplicate number must exist. Assume that there is only one duplicate number, but it may be repeated more than once.</p> <p>The task is to find the duplicate number without modifying the array <code class="language-plaintext highlighter-rouge">nums</code> and using only constant extra space.</p> <h2 id="3-algorithm-description">3. Algorithm Description</h2> <p>Floyd’s algorithm can be adapted to solve this problem by treating the array as a linked list where <code class="language-plaintext highlighter-rouge">nums[i]</code> is treated as a pointer to index <code class="language-plaintext highlighter-rouge">nums[i]</code>.</p> <p>The algorithm consists of two phases:</p> <h3 id="phase-1-detecting-the-intersection-point-of-two-runners">Phase 1: Detecting the intersection point of two runners</h3> <ol> <li>Initialize two pointers, <code class="language-plaintext highlighter-rouge">tortoise</code> and <code class="language-plaintext highlighter-rouge">hare</code>, to the first element of the array.</li> <li>Move <code class="language-plaintext highlighter-rouge">tortoise</code> one step at a time: <code class="language-plaintext highlighter-rouge">tortoise = nums[tortoise]</code></li> <li>Move <code class="language-plaintext highlighter-rouge">hare</code> two steps at a time: <code class="language-plaintext highlighter-rouge">hare = nums[nums[hare]]</code></li> <li>Repeat steps 2 and 3 until <code class="language-plaintext highlighter-rouge">tortoise</code> and <code class="language-plaintext highlighter-rouge">hare</code> meet at the same element.</li> </ol> <h3 id="phase-2-finding-the-entrance-to-the-cycle-the-duplicate-number">Phase 2: Finding the entrance to the cycle (the duplicate number)</h3> <ol> <li>Reset the <code class="language-plaintext highlighter-rouge">tortoise</code> to the first element of the array.</li> <li>Move both <code class="language-plaintext highlighter-rouge">tortoise</code> and <code class="language-plaintext highlighter-rouge">hare</code> one step at a time.</li> <li>The point at which they meet is the entrance to the cycle, which is the duplicate number.</li> </ol> <h2 id="4-implementation">4. Implementation</h2> <div class="language-java highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kd">public</span> <span class="kd">class</span> <span class="nc">Solution</span> <span class="o">{</span>
  <span class="kd">public</span> <span class="kt">int</span> <span class="nf">findDuplicate</span><span class="o">(</span><span class="kt">int</span><span class="o">[]</span> <span class="n">nums</span><span class="o">)</span> <span class="o">{</span>
    <span class="c1">// Phase 1: Detecting the cycle</span>
    <span class="kt">int</span> <span class="n">tortoise</span> <span class="o">=</span> <span class="n">nums</span><span class="o">[</span><span class="mi">0</span><span class="o">];</span>  <span class="c1">// Initialize the slow pointer (tortoise)</span>
    <span class="kt">int</span> <span class="n">hare</span> <span class="o">=</span> <span class="n">nums</span><span class="o">[</span><span class="mi">0</span><span class="o">];</span>      <span class="c1">// Initialize the fast pointer (hare)</span>

    <span class="k">do</span> <span class="o">{</span>
      <span class="c1">// Move the tortoise one step forward</span>
      <span class="n">tortoise</span> <span class="o">=</span> <span class="n">nums</span><span class="o">[</span><span class="n">tortoise</span><span class="o">];</span>

      <span class="c1">// Move the hare two steps forward</span>
      <span class="n">hare</span> <span class="o">=</span> <span class="n">nums</span><span class="o">[</span><span class="n">nums</span><span class="o">[</span><span class="n">hare</span><span class="o">]];</span>

      <span class="c1">// Continue until the tortoise and hare meet</span>
      <span class="c1">// This meeting point is guaranteed to be inside the cycle</span>
    <span class="o">}</span> <span class="k">while</span> <span class="o">(</span><span class="n">tortoise</span> <span class="o">!=</span> <span class="n">hare</span><span class="o">);</span>

    <span class="c1">// Phase 2: Finding the entrance to the cycle (the duplicate number)</span>
    <span class="n">tortoise</span> <span class="o">=</span> <span class="n">nums</span><span class="o">[</span><span class="mi">0</span><span class="o">];</span>  <span class="c1">// Reset the tortoise to the start of the array</span>

    <span class="c1">// Move both pointers at the same speed until they meet again</span>
    <span class="k">while</span> <span class="o">(</span><span class="n">tortoise</span> <span class="o">!=</span> <span class="n">hare</span><span class="o">)</span> <span class="o">{</span>
      <span class="c1">// Move both pointers one step at a time</span>
      <span class="n">tortoise</span> <span class="o">=</span> <span class="n">nums</span><span class="o">[</span><span class="n">tortoise</span><span class="o">];</span>
      <span class="n">hare</span> <span class="o">=</span> <span class="n">nums</span><span class="o">[</span><span class="n">hare</span><span class="o">];</span>

      <span class="c1">// The point where they meet is the entrance to the cycle,</span>
      <span class="c1">// which is the duplicate number</span>
    <span class="o">}</span>

    <span class="c1">// Both pointers now point to the duplicate number</span>
    <span class="k">return</span> <span class="n">hare</span><span class="o">;</span>  <span class="c1">// We could return tortoise as well, they're the same at this point</span>
  <span class="o">}</span>
<span class="o">}</span>
</code></pre></div></div> <h2 id="5-proof-of-correctness">5. Proof of Correctness</h2> <p>The correctness of this algorithm relies on the following properties:</p> <ol> <li>If there is a cycle, the <code class="language-plaintext highlighter-rouge">tortoise</code> and <code class="language-plaintext highlighter-rouge">hare</code> will eventually meet.</li> <li>The meeting point is not necessarily the duplicate number, but it is guaranteed to be part of the cycle.</li> <li>The distance from the start of the array to the entrance of the cycle (duplicate number) is equal to the distance from the meeting point to the entrance of the cycle.</li> </ol> <h2 id="6-complexity-analysis">6. Complexity Analysis</h2> <ul> <li>Time Complexity: O(n), where n is the length of the array. The worst case occurs when the duplicate element is at the end of the array.</li> <li>Space Complexity: O(1), as only two pointers are used regardless of the input size.</li> </ul> <h2 id="7-advantages-and-disadvantages">7. Advantages and Disadvantages</h2> <h3 id="advantages">Advantages:</h3> <ul> <li>Meets the problem constraints of O(1) space complexity.</li> <li>Does not modify the original array.</li> <li>Has optimal time complexity of O(n).</li> </ul> <h3 id="disadvantages">Disadvantages:</h3> <ul> <li>Not intuitive and can be difficult to understand at first glance.</li> <li>Doesn’t provide information about all duplicates if multiple exist.</li> </ul> <h2 id="8-conclusion">8. Conclusion</h2> <p>Floyd’s Cycle-Finding Algorithm provides an elegant and efficient solution to the “Find the Duplicate Number” problem. While it may not be the most intuitive approach, it showcases how algorithmic thinking can lead to optimal solutions that satisfy strict constraints. Understanding this algorithm and its application can provide valuable insights into problem-solving techniques in computer science.</p> <h2 id="example-of-leetode">Example of Leetode</h2> <ol> <li>LeetCode 142 - Linked List Cycle II</li> </ol> <p>Problem: Given a linked list, return the node where the cycle begins. If there is no cycle, return <code class="language-plaintext highlighter-rouge">null</code>.</p> <div class="language-java highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kd">class</span> <span class="nc">ListNode</span> <span class="o">{</span>
    <span class="kt">int</span> <span class="n">val</span><span class="o">;</span>
    <span class="nc">ListNode</span> <span class="n">next</span><span class="o">;</span>
    <span class="nc">ListNode</span><span class="o">(</span><span class="kt">int</span> <span class="n">x</span><span class="o">)</span> <span class="o">{</span>
        <span class="n">val</span> <span class="o">=</span> <span class="n">x</span><span class="o">;</span>
        <span class="n">next</span> <span class="o">=</span> <span class="kc">null</span><span class="o">;</span>
    <span class="o">}</span>
<span class="o">}</span>

<span class="kd">public</span> <span class="kd">class</span> <span class="nc">Solution</span> <span class="o">{</span>
    <span class="kd">public</span> <span class="nc">ListNode</span> <span class="nf">detectCycle</span><span class="o">(</span><span class="nc">ListNode</span> <span class="n">head</span><span class="o">)</span> <span class="o">{</span>
        <span class="k">if</span> <span class="o">(</span><span class="n">head</span> <span class="o">==</span> <span class="kc">null</span> <span class="o">||</span> <span class="n">head</span><span class="o">.</span><span class="na">next</span> <span class="o">==</span> <span class="kc">null</span><span class="o">)</span> <span class="k">return</span> <span class="kc">null</span><span class="o">;</span>
        
        <span class="nc">ListNode</span> <span class="n">slow</span> <span class="o">=</span> <span class="n">head</span><span class="o">;</span>
        <span class="nc">ListNode</span> <span class="n">fast</span> <span class="o">=</span> <span class="n">head</span><span class="o">;</span>

        <span class="c1">// Phase 1: Detect the intersection point</span>
        <span class="k">while</span> <span class="o">(</span><span class="n">fast</span> <span class="o">!=</span> <span class="kc">null</span> <span class="o">&amp;&amp;</span> <span class="n">fast</span><span class="o">.</span><span class="na">next</span> <span class="o">!=</span> <span class="kc">null</span><span class="o">)</span> <span class="o">{</span>
            <span class="n">slow</span> <span class="o">=</span> <span class="n">slow</span><span class="o">.</span><span class="na">next</span><span class="o">;</span>            <span class="c1">// Move slow pointer one step</span>
            <span class="n">fast</span> <span class="o">=</span> <span class="n">fast</span><span class="o">.</span><span class="na">next</span><span class="o">.</span><span class="na">next</span><span class="o">;</span>       <span class="c1">// Move fast pointer two steps</span>
            <span class="k">if</span> <span class="o">(</span><span class="n">slow</span> <span class="o">==</span> <span class="n">fast</span><span class="o">)</span> <span class="k">break</span><span class="o">;</span>     <span class="c1">// They meet at the cycle</span>
        <span class="o">}</span>

        <span class="c1">// If fast reaches null, there is no cycle</span>
        <span class="k">if</span> <span class="o">(</span><span class="n">fast</span> <span class="o">==</span> <span class="kc">null</span> <span class="o">||</span> <span class="n">fast</span><span class="o">.</span><span class="na">next</span> <span class="o">==</span> <span class="kc">null</span><span class="o">)</span> <span class="k">return</span> <span class="kc">null</span><span class="o">;</span>

        <span class="c1">// Phase 2: Find the entrance to the cycle</span>
        <span class="n">slow</span> <span class="o">=</span> <span class="n">head</span><span class="o">;</span>
        <span class="k">while</span> <span class="o">(</span><span class="n">slow</span> <span class="o">!=</span> <span class="n">fast</span><span class="o">)</span> <span class="o">{</span>
            <span class="n">slow</span> <span class="o">=</span> <span class="n">slow</span><span class="o">.</span><span class="na">next</span><span class="o">;</span>
            <span class="n">fast</span> <span class="o">=</span> <span class="n">fast</span><span class="o">.</span><span class="na">next</span><span class="o">;</span>
        <span class="o">}</span>

        <span class="k">return</span> <span class="n">slow</span><span class="o">;</span>  <span class="c1">// This is the entrance to the cycle</span>
    <span class="o">}</span>
<span class="o">}</span>

</code></pre></div></div> <ol> <li>LeetCode 202 - Happy Number</li> </ol> <p>Problem: Write an algorithm to determine if a number <code class="language-plaintext highlighter-rouge">n</code> is a “happy number.” A happy number is one where you repeatedly replace the number by the sum of the squares of its digits until it either equals <code class="language-plaintext highlighter-rouge">1</code> (which means it’s happy) or loops endlessly in a cycle.</p> <div class="language-java highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kd">public</span> <span class="kd">class</span> <span class="nc">Solution</span> <span class="o">{</span>
    <span class="kd">public</span> <span class="kt">boolean</span> <span class="nf">isHappy</span><span class="o">(</span><span class="kt">int</span> <span class="n">n</span><span class="o">)</span> <span class="o">{</span>
        <span class="kt">int</span> <span class="n">slow</span> <span class="o">=</span> <span class="n">n</span><span class="o">;</span>
        <span class="kt">int</span> <span class="n">fast</span> <span class="o">=</span> <span class="n">getNext</span><span class="o">(</span><span class="n">n</span><span class="o">);</span>

        <span class="c1">// Phase 1: Detect cycle</span>
        <span class="k">while</span> <span class="o">(</span><span class="n">fast</span> <span class="o">!=</span> <span class="mi">1</span> <span class="o">&amp;&amp;</span> <span class="n">slow</span> <span class="o">!=</span> <span class="n">fast</span><span class="o">)</span> <span class="o">{</span>
            <span class="n">slow</span> <span class="o">=</span> <span class="n">getNext</span><span class="o">(</span><span class="n">slow</span><span class="o">);</span>             <span class="c1">// Slow pointer moves one step</span>
            <span class="n">fast</span> <span class="o">=</span> <span class="n">getNext</span><span class="o">(</span><span class="n">getNext</span><span class="o">(</span><span class="n">fast</span><span class="o">));</span>    <span class="c1">// Fast pointer moves two steps</span>
        <span class="o">}</span>

        <span class="c1">// If fast reaches 1, it's a happy number</span>
        <span class="k">return</span> <span class="n">fast</span> <span class="o">==</span> <span class="mi">1</span><span class="o">;</span>
    <span class="o">}</span>

    <span class="kd">private</span> <span class="kt">int</span> <span class="nf">getNext</span><span class="o">(</span><span class="kt">int</span> <span class="n">n</span><span class="o">)</span> <span class="o">{</span>
        <span class="kt">int</span> <span class="n">totalSum</span> <span class="o">=</span> <span class="mi">0</span><span class="o">;</span>
        <span class="k">while</span> <span class="o">(</span><span class="n">n</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="o">)</span> <span class="o">{</span>
            <span class="kt">int</span> <span class="n">d</span> <span class="o">=</span> <span class="n">n</span> <span class="o">%</span> <span class="mi">10</span><span class="o">;</span>
            <span class="n">n</span> <span class="o">=</span> <span class="n">n</span> <span class="o">/</span> <span class="mi">10</span><span class="o">;</span>
            <span class="n">totalSum</span> <span class="o">+=</span> <span class="n">d</span> <span class="o">*</span> <span class="n">d</span><span class="o">;</span>
        <span class="o">}</span>
        <span class="k">return</span> <span class="n">totalSum</span><span class="o">;</span>
    <span class="o">}</span>
<span class="o">}</span>

</code></pre></div></div> <ol> <li>LeetCode 41 - First Missing Positive</li> </ol> <p>Problem: Given an unsorted integer array, find the smallest missing positive integer. Although this problem doesn’t directly use Floyd’s algorithm, you can solve it by rearranging the array to simulate the cyclic behavior.</p> <div class="language-java highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kd">public</span> <span class="kd">class</span> <span class="nc">Solution</span> <span class="o">{</span>
    <span class="kd">public</span> <span class="kt">int</span> <span class="nf">firstMissingPositive</span><span class="o">(</span><span class="kt">int</span><span class="o">[]</span> <span class="n">nums</span><span class="o">)</span> <span class="o">{</span>
        <span class="kt">int</span> <span class="n">n</span> <span class="o">=</span> <span class="n">nums</span><span class="o">.</span><span class="na">length</span><span class="o">;</span>

        <span class="c1">// Place each number at its correct index (e.g., 1 goes to index 0, 2 goes to index 1)</span>
        <span class="k">for</span> <span class="o">(</span><span class="kt">int</span> <span class="n">i</span> <span class="o">=</span> <span class="mi">0</span><span class="o">;</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="n">n</span><span class="o">;</span> <span class="n">i</span><span class="o">++)</span> <span class="o">{</span>
            <span class="k">while</span> <span class="o">(</span><span class="n">nums</span><span class="o">[</span><span class="n">i</span><span class="o">]</span> <span class="o">&gt;</span> <span class="mi">0</span> <span class="o">&amp;&amp;</span> <span class="n">nums</span><span class="o">[</span><span class="n">i</span><span class="o">]</span> <span class="o">&lt;=</span> <span class="n">n</span> <span class="o">&amp;&amp;</span> <span class="n">nums</span><span class="o">[</span><span class="n">nums</span><span class="o">[</span><span class="n">i</span><span class="o">]</span> <span class="o">-</span> <span class="mi">1</span><span class="o">]</span> <span class="o">!=</span> <span class="n">nums</span><span class="o">[</span><span class="n">i</span><span class="o">])</span> <span class="o">{</span>
                <span class="c1">// Swap nums[i] with nums[nums[i] - 1]</span>
                <span class="n">swap</span><span class="o">(</span><span class="n">nums</span><span class="o">,</span> <span class="n">i</span><span class="o">,</span> <span class="n">nums</span><span class="o">[</span><span class="n">i</span><span class="o">]</span> <span class="o">-</span> <span class="mi">1</span><span class="o">);</span>
            <span class="o">}</span>
        <span class="o">}</span>

        <span class="c1">// Find the first missing positive number</span>
        <span class="k">for</span> <span class="o">(</span><span class="kt">int</span> <span class="n">i</span> <span class="o">=</span> <span class="mi">0</span><span class="o">;</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="n">n</span><span class="o">;</span> <span class="n">i</span><span class="o">++)</span> <span class="o">{</span>
            <span class="k">if</span> <span class="o">(</span><span class="n">nums</span><span class="o">[</span><span class="n">i</span><span class="o">]</span> <span class="o">!=</span> <span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="o">)</span> <span class="o">{</span>
                <span class="k">return</span> <span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="o">;</span>
            <span class="o">}</span>
        <span class="o">}</span>

        <span class="k">return</span> <span class="n">n</span> <span class="o">+</span> <span class="mi">1</span><span class="o">;</span>  <span class="c1">// If all numbers are in the correct place, return n+1</span>
    <span class="o">}</span>

    <span class="kd">private</span> <span class="kt">void</span> <span class="nf">swap</span><span class="o">(</span><span class="kt">int</span><span class="o">[]</span> <span class="n">nums</span><span class="o">,</span> <span class="kt">int</span> <span class="n">i</span><span class="o">,</span> <span class="kt">int</span> <span class="n">j</span><span class="o">)</span> <span class="o">{</span>
        <span class="kt">int</span> <span class="n">temp</span> <span class="o">=</span> <span class="n">nums</span><span class="o">[</span><span class="n">i</span><span class="o">];</span>
        <span class="n">nums</span><span class="o">[</span><span class="n">i</span><span class="o">]</span> <span class="o">=</span> <span class="n">nums</span><span class="o">[</span><span class="n">j</span><span class="o">];</span>
        <span class="n">nums</span><span class="o">[</span><span class="n">j</span><span class="o">]</span> <span class="o">=</span> <span class="n">temp</span><span class="o">;</span>
    <span class="o">}</span>
<span class="o">}</span>

</code></pre></div></div> <ol> <li>Cycle Detection in Function Iteration</li> </ol> <p>In function iteration, we want to detect if a function eventually enters a cycle. You can apply Floyd’s algorithm here as well. Below is an example:</p> <div class="language-java highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kd">public</span> <span class="kd">class</span> <span class="nc">Solution</span> <span class="o">{</span>
    <span class="kd">public</span> <span class="kt">int</span> <span class="nf">detectCycleInFunction</span><span class="o">(</span><span class="kt">int</span> <span class="n">x</span><span class="o">)</span> <span class="o">{</span>
        <span class="kt">int</span> <span class="n">slow</span> <span class="o">=</span> <span class="n">f</span><span class="o">(</span><span class="n">x</span><span class="o">);</span>
        <span class="kt">int</span> <span class="n">fast</span> <span class="o">=</span> <span class="n">f</span><span class="o">(</span><span class="n">f</span><span class="o">(</span><span class="n">x</span><span class="o">));</span>

        <span class="c1">// Phase 1: Detect cycle</span>
        <span class="k">while</span> <span class="o">(</span><span class="n">slow</span> <span class="o">!=</span> <span class="n">fast</span><span class="o">)</span> <span class="o">{</span>
            <span class="n">slow</span> <span class="o">=</span> <span class="n">f</span><span class="o">(</span><span class="n">slow</span><span class="o">);</span>           <span class="c1">// Slow pointer moves one step</span>
            <span class="n">fast</span> <span class="o">=</span> <span class="n">f</span><span class="o">(</span><span class="n">f</span><span class="o">(</span><span class="n">fast</span><span class="o">));</span>        <span class="c1">// Fast pointer moves two steps</span>
        <span class="o">}</span>

        <span class="c1">// Phase 2: Find the entrance of the cycle</span>
        <span class="n">slow</span> <span class="o">=</span> <span class="n">x</span><span class="o">;</span>
        <span class="k">while</span> <span class="o">(</span><span class="n">slow</span> <span class="o">!=</span> <span class="n">fast</span><span class="o">)</span> <span class="o">{</span>
            <span class="n">slow</span> <span class="o">=</span> <span class="n">f</span><span class="o">(</span><span class="n">slow</span><span class="o">);</span>
            <span class="n">fast</span> <span class="o">=</span> <span class="n">f</span><span class="o">(</span><span class="n">fast</span><span class="o">);</span>
        <span class="o">}</span>

        <span class="k">return</span> <span class="n">slow</span><span class="o">;</span>  <span class="c1">// Return the entrance of the cycle</span>
    <span class="o">}</span>

    <span class="kd">private</span> <span class="kt">int</span> <span class="nf">f</span><span class="o">(</span><span class="kt">int</span> <span class="n">x</span><span class="o">)</span> <span class="o">{</span>
        <span class="c1">// Example of a function f</span>
        <span class="k">return</span> <span class="o">(</span><span class="n">x</span> <span class="o">*</span> <span class="n">x</span> <span class="o">+</span> <span class="mi">1</span><span class="o">)</span> <span class="o">%</span> <span class="mi">10</span><span class="o">;</span>  <span class="c1">// For instance, square the number and add 1</span>
    <span class="o">}</span>
<span class="o">}</span>

</code></pre></div></div> <ol> <li>Cycle Detection in Finite State Machines</li> </ol> <p>You can also use Floyd’s algorithm to detect cycles in state transitions of a finite state machine (FSM).</p> <div class="language-java highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kd">public</span> <span class="kd">class</span> <span class="nc">Solution</span> <span class="o">{</span>
    <span class="kd">public</span> <span class="kt">int</span> <span class="nf">detectCycleInFSM</span><span class="o">(</span><span class="kt">int</span> <span class="n">state</span><span class="o">,</span> <span class="kt">int</span><span class="o">[][]</span> <span class="n">transitions</span><span class="o">)</span> <span class="o">{</span>
        <span class="kt">int</span> <span class="n">slow</span> <span class="o">=</span> <span class="n">transitions</span><span class="o">[</span><span class="n">state</span><span class="o">][</span><span class="mi">0</span><span class="o">];</span>
        <span class="kt">int</span> <span class="n">fast</span> <span class="o">=</span> <span class="n">transitions</span><span class="o">[</span><span class="n">transitions</span><span class="o">[</span><span class="n">state</span><span class="o">][</span><span class="mi">0</span><span class="o">]][</span><span class="mi">0</span><span class="o">];</span>

        <span class="c1">// Phase 1: Detect cycle</span>
        <span class="k">while</span> <span class="o">(</span><span class="n">slow</span> <span class="o">!=</span> <span class="n">fast</span><span class="o">)</span> <span class="o">{</span>
            <span class="n">slow</span> <span class="o">=</span> <span class="n">transitions</span><span class="o">[</span><span class="n">slow</span><span class="o">][</span><span class="mi">0</span><span class="o">];</span>               <span class="c1">// Slow pointer moves one step</span>
            <span class="n">fast</span> <span class="o">=</span> <span class="n">transitions</span><span class="o">[</span><span class="n">transitions</span><span class="o">[</span><span class="n">fast</span><span class="o">][</span><span class="mi">0</span><span class="o">]][</span><span class="mi">0</span><span class="o">];</span>  <span class="c1">// Fast pointer moves two steps</span>
        <span class="o">}</span>

        <span class="c1">// Phase 2: Find the entrance of the cycle</span>
        <span class="n">slow</span> <span class="o">=</span> <span class="n">state</span><span class="o">;</span>
        <span class="k">while</span> <span class="o">(</span><span class="n">slow</span> <span class="o">!=</span> <span class="n">fast</span><span class="o">)</span> <span class="o">{</span>
            <span class="n">slow</span> <span class="o">=</span> <span class="n">transitions</span><span class="o">[</span><span class="n">slow</span><span class="o">][</span><span class="mi">0</span><span class="o">];</span>
            <span class="n">fast</span> <span class="o">=</span> <span class="n">transitions</span><span class="o">[</span><span class="n">fast</span><span class="o">][</span><span class="mi">0</span><span class="o">];</span>
        <span class="o">}</span>

        <span class="k">return</span> <span class="n">slow</span><span class="o">;</span>  <span class="c1">// Return the state where the cycle starts</span>
    <span class="o">}</span>
<span class="o">}</span>

</code></pre></div></div>]]></content><author><name></name></author><category term="Data Structure"/><summary type="html"><![CDATA[1. Introduction]]></summary></entry></feed>